[06/27 17:58:19] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[06/27 17:58:19] cvalgorithms INFO: pretrained checkpoint is loaded.
[06/27 17:58:25] cvalgorithms INFO: Starting training from iteration 0
[06/27 17:58:29] cvalgorithms INFO:  iter: 0  total_loss: 118.6  decode.loss_seg: -5.333e-06  aux_0.loss: 1.415e-06  cnt.cnt_loss: 59.3  loss: 59.3  data_time: 0.0816  lr: N/A  max_mem: 3221M
[06/27 17:58:30] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 345, in _get_eta
    eta_seconds = storage.history("time").median(1000) * (self._max_iter - iteration - 1)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 207, in history
    raise KeyError("No history metric available for {}!".format(name))
KeyError: 'No history metric available for time!'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 122, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 144, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 301, in after_step
    writer.write()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 378, in write
    eta_string = self._get_eta(storage)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 353, in _get_eta
    iteration - self._last_write[0]
ZeroDivisionError: float division by zero
[06/27 18:56:52] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[06/27 18:56:52] cvalgorithms INFO: pretrained checkpoint is loaded.
[06/27 18:57:13] cvalgorithms INFO: Starting training from iteration 0
[06/28 18:41:40] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[06/28 18:41:41] cvalgorithms INFO: pretrained checkpoint is loaded.
[06/30 17:43:03] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[06/30 17:43:03] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 14:44:14] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/01 14:44:14] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 14:49:39] cvalgorithms INFO: Starting training from iteration 0
[07/01 16:18:02] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/01 16:18:02] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 16:18:46] cvalgorithms INFO: Starting training from iteration 0
[07/01 16:19:06] cvalgorithms INFO: Starting training from iteration 0
[07/01 16:40:45] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/01 16:40:45] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 16:40:55] cvalgorithms INFO: Starting training from iteration 0
[07/01 17:01:10] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/01 17:01:10] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 17:04:01] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/01 17:04:01] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 17:04:02] cvalgorithms INFO: Starting training from iteration 0
[07/01 17:04:06] cvalgorithms INFO:  iter: 0  total_loss: 259.1  decode.loss_seg: 8.504e-06  aux_0.loss: -6.991e-06  cnt.cnt_loss: 129.6  loss: 129.6  data_time: 0.0964  lr: N/A  max_mem: 3221M
[07/01 17:04:06] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 345, in _get_eta
    eta_seconds = storage.history("time").median(1000) * (self._max_iter - iteration - 1)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 207, in history
    raise KeyError("No history metric available for {}!".format(name))
KeyError: 'No history metric available for time!'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 122, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 144, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 301, in after_step
    writer.write()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 378, in write
    eta_string = self._get_eta(storage)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 353, in _get_eta
    iteration - self._last_write[0]
ZeroDivisionError: float division by zero
[07/01 17:05:09] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/01 17:05:09] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 17:05:10] cvalgorithms INFO: Starting training from iteration 0
[07/01 17:08:07] cvalgorithms INFO:  iter: 0  total_loss: 337.1  decode.loss_seg: -0.001191  aux_0.loss: 4.829e-06  cnt.cnt_loss: 168.6  loss: 168.6  data_time: 0.0845  lr: N/A  max_mem: 3221M
[07/05 10:26:48] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 10:26:48] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 10:26:50] cvalgorithms INFO: Starting training from iteration 0
[07/05 10:27:49] cvalgorithms INFO:  iter: 0  total_loss: 151.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 75.9  loss: 75.9  data_time: 0.0901  lr: N/A  max_mem: 3221M
[07/05 10:36:53] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 10:36:53] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 10:36:54] cvalgorithms INFO: Starting training from iteration 0
[07/05 10:39:40] cvalgorithms INFO:  iter: 0  total_loss: 311  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 155.5  loss: 155.5  data_time: 0.0870  lr: N/A  max_mem: 3221M
[07/05 10:39:41] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 345, in _get_eta
    eta_seconds = storage.history("time").median(1000) * (self._max_iter - iteration - 1)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 207, in history
    raise KeyError("No history metric available for {}!".format(name))
KeyError: 'No history metric available for time!'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 122, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 144, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 303, in after_step
    writer.write()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 378, in write
    eta_string = self._get_eta(storage)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 353, in _get_eta
    iteration - self._last_write[0]
ZeroDivisionError: float division by zero
[07/05 10:46:03] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 10:46:03] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 11:05:42] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 11:05:42] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 11:05:42] cvalgorithms INFO: Starting training from iteration 0
[07/05 11:05:45] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 118, in train
    self.before_train()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 132, in before_train
    h.before_train()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 319, in before_train
    self._optimizer = self._optimizer or self.trainer.optimizer
AttributeError: 'TrainerContainer' object has no attribute 'optimizer'
[07/05 11:05:45] cvalgorithms INFO:  iter: 0    lr: N/A  max_mem: 0M
[07/05 11:07:46] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 11:07:47] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 11:07:47] cvalgorithms INFO: Starting training from iteration 0
[07/05 11:07:51] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 121, in train
    self.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 133, in run_step
    self._trainer.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 208, in run_step
    loss_dict = self.model(_img, ground_truth=_ground_truth, return_metrics=True)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 305, in forward
    metrics = self.forward_train(inputs, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 211, in forward_train
    x = self.extract_feat(inputs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 57, in extract_feat
    features_n, features_g = self.backbone(inputs_switch), self.backbone(inputs_g)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\base\backbone\convnext.py", line 83, in forward
    x = self.downsample_layers[i](x)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\container.py", line 119, in forward
    input = module(input)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\conv.py", line 399, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\conv.py", line 396, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same
[07/05 11:07:51] cvalgorithms INFO:  iter: 0    lr: N/A  max_mem: 17M
[07/05 11:09:03] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 11:09:03] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 11:09:04] cvalgorithms INFO: Starting training from iteration 0
[07/05 11:09:10] cvalgorithms INFO:  iter: 0  total_loss: 135.5  decode.loss_seg: -0.002456  aux_0.loss: -1.628e-05  cnt.cnt_loss: 67.74  loss: 67.73  data_time: 0.0854  lr: 0.00090451  max_mem: 3221M
[07/05 11:09:11] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 345, in _get_eta
    eta_seconds = storage.history("time").median(1000) * (self._max_iter - iteration - 1)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 207, in history
    raise KeyError("No history metric available for {}!".format(name))
KeyError: 'No history metric available for time!'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 122, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 144, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 303, in after_step
    writer.write()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 378, in write
    eta_string = self._get_eta(storage)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 353, in _get_eta
    iteration - self._last_write[0]
ZeroDivisionError: float division by zero
[07/05 11:14:09] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 11:14:09] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 11:14:10] cvalgorithms INFO: Starting training from iteration 0
[07/05 11:43:56] cvalgorithms INFO:  iter: 0  total_loss: 486.3  decode.loss_seg: 0.0006568  aux_0.loss: 1.233e-06  cnt.cnt_loss: 243.1  loss: 243.1  data_time: 0.1017  lr: 0.00090451  max_mem: 3221M
[07/05 11:44:11] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 345, in _get_eta
    eta_seconds = storage.history("time").median(1000) * (self._max_iter - iteration - 1)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 207, in history
    raise KeyError("No history metric available for {}!".format(name))
KeyError: 'No history metric available for time!'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 122, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 144, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 303, in after_step
    writer.write()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 378, in write
    eta_string = self._get_eta(storage)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 353, in _get_eta
    iteration - self._last_write[0]
ZeroDivisionError: float division by zero
[07/05 12:19:02] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 12:19:02] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 12:19:03] cvalgorithms INFO: Starting training from iteration 0
[07/05 13:15:18] cvalgorithms INFO:  iter: 0  total_loss: 238.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 119.3  loss: 119.3  data_time: 0.1068  lr: 0.00090451  max_mem: 3221M
[07/05 13:22:25] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 13:22:25] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 13:22:26] cvalgorithms INFO: Starting training from iteration 0
[07/05 13:23:44] cvalgorithms INFO:  iter: 0  total_loss: 220.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 110.1  loss: 110.1  data_time: 0.0851  lr: 0.00090451  max_mem: 3221M
[07/05 13:23:51] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 345, in _get_eta
    eta_seconds = storage.history("time").median(1000) * (self._max_iter - iteration - 1)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 207, in history
    raise KeyError("No history metric available for {}!".format(name))
KeyError: 'No history metric available for time!'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 122, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 144, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 303, in after_step
    writer.write()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 378, in write
    eta_string = self._get_eta(storage)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 353, in _get_eta
    iteration - self._last_write[0]
ZeroDivisionError: float division by zero
[07/05 13:35:37] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 13:35:37] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 13:35:38] cvalgorithms INFO: Starting training from iteration 0
[07/05 13:40:17] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 13:40:17] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 13:40:18] cvalgorithms INFO: Starting training from iteration 0
[07/05 13:40:47] cvalgorithms INFO:  iter: 1  total_loss: 459.5  decode.loss_seg: 0.0008303  aux_0.loss: 4.342e-06  cnt.cnt_loss: 229.7  loss: 229.8  data_time: 0.1050  lr: 0.00090451  max_mem: 3221M
[07/05 13:40:52] cvalgorithms INFO:  eta: 0:01:01  iter: 3  total_loss: 284.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 142.1  loss: 142.1  time: 0.6388  data_time: 0.0899  lr: 0.00034549  max_mem: 3221M
[07/05 13:40:53] cvalgorithms INFO:  eta: 0:00:49  iter: 5  total_loss: 145.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.76  loss: 72.76  time: 0.5316  data_time: 0.0832  lr: 0.001  max_mem: 3221M
[07/05 13:40:53] cvalgorithms INFO:  eta: 0:00:39  iter: 7  total_loss: 111.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 55.7  loss: 55.7  time: 0.4963  data_time: 0.0804  lr: 0.00065451  max_mem: 3221M
[07/05 13:40:54] cvalgorithms INFO:  eta: 0:00:38  iter: 9  total_loss: 88.96  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 44.48  loss: 44.48  time: 0.4782  data_time: 0.0791  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:40:55] cvalgorithms INFO:  eta: 0:00:37  iter: 11  total_loss: 88.96  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 44.48  loss: 44.48  time: 0.4650  data_time: 0.0767  lr: 0.00090451  max_mem: 3221M
[07/05 13:40:56] cvalgorithms INFO:  eta: 0:00:36  iter: 13  total_loss: 71.86  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.93  loss: 35.93  time: 0.4566  data_time: 0.0751  lr: 0.00034549  max_mem: 3221M
[07/05 13:40:57] cvalgorithms INFO:  eta: 0:00:35  iter: 15  total_loss: 70.47  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.24  loss: 35.24  time: 0.4500  data_time: 0.0736  lr: 0.001  max_mem: 3221M
[07/05 13:40:58] cvalgorithms INFO:  eta: 0:00:34  iter: 17  total_loss: 66.16  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.08  loss: 33.08  time: 0.4455  data_time: 0.0728  lr: 0.00065451  max_mem: 3221M
[07/05 13:40:58] cvalgorithms INFO:  eta: 0:00:33  iter: 19  total_loss: 65.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.92  loss: 32.92  time: 0.4440  data_time: 0.0736  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:40:59] cvalgorithms INFO:  eta: 0:00:32  iter: 21  total_loss: 53.66  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 26.83  loss: 26.83  time: 0.4411  data_time: 0.0698  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:00] cvalgorithms INFO:  eta: 0:00:31  iter: 23  total_loss: 38.56  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 19.28  loss: 19.28  time: 0.4401  data_time: 0.0703  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:01] cvalgorithms INFO:  eta: 0:00:30  iter: 25  total_loss: 35.45  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.73  loss: 17.73  time: 0.4382  data_time: 0.0701  lr: 0.001  max_mem: 3221M
[07/05 13:41:02] cvalgorithms INFO:  eta: 0:00:29  iter: 27  total_loss: 30.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 15.15  loss: 15.15  time: 0.4369  data_time: 0.0702  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:03] cvalgorithms INFO:  eta: 0:00:29  iter: 29  total_loss: 27.34  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 13.67  loss: 13.67  time: 0.4359  data_time: 0.0699  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:03] cvalgorithms INFO:  eta: 0:00:28  iter: 31  total_loss: 24.31  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.16  loss: 12.16  time: 0.4347  data_time: 0.0702  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:04] cvalgorithms INFO:  eta: 0:00:27  iter: 33  total_loss: 22.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 11.1  loss: 11.1  time: 0.4341  data_time: 0.0712  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:05] cvalgorithms INFO:  eta: 0:00:26  iter: 35  total_loss: 18.89  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 9.447  loss: 9.447  time: 0.4330  data_time: 0.0714  lr: 0.001  max_mem: 3221M
[07/05 13:41:06] cvalgorithms INFO:  eta: 0:00:25  iter: 37  total_loss: 15.22  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.611  loss: 7.611  time: 0.4322  data_time: 0.0715  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:07] cvalgorithms INFO:  eta: 0:00:25  iter: 39  total_loss: 14.29  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.143  loss: 7.143  time: 0.4320  data_time: 0.0707  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:08] cvalgorithms INFO:  eta: 0:00:24  iter: 41  total_loss: 11.99  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.995  loss: 5.995  time: 0.4320  data_time: 0.0719  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:09] cvalgorithms INFO:  eta: 0:00:23  iter: 43  total_loss: 11.13  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.566  loss: 5.566  time: 0.4315  data_time: 0.0708  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:09] cvalgorithms INFO:  eta: 0:00:22  iter: 45  total_loss: 8.259  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.13  loss: 4.13  time: 0.4314  data_time: 0.0709  lr: 0.001  max_mem: 3221M
[07/05 13:41:10] cvalgorithms INFO:  eta: 0:00:21  iter: 47  total_loss: 6.297  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.148  loss: 3.148  time: 0.4313  data_time: 0.0707  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:11] cvalgorithms INFO:  eta: 0:00:20  iter: 49  total_loss: 5.63  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.815  loss: 2.815  time: 0.4312  data_time: 0.0710  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:12] cvalgorithms INFO:  eta: 0:00:20  iter: 51  total_loss: 4.95  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.475  loss: 2.475  time: 0.4309  data_time: 0.0714  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:13] cvalgorithms INFO:  eta: 0:00:19  iter: 53  total_loss: 4.61  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.305  loss: 2.305  time: 0.4309  data_time: 0.0715  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:14] cvalgorithms INFO:  eta: 0:00:18  iter: 55  total_loss: 4.215  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.108  loss: 2.108  time: 0.4311  data_time: 0.0729  lr: 0.001  max_mem: 3221M
[07/05 13:41:15] cvalgorithms INFO:  eta: 0:00:17  iter: 57  total_loss: 4.214  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.107  loss: 2.107  time: 0.4309  data_time: 0.0734  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:16] cvalgorithms INFO:  eta: 0:00:16  iter: 59  total_loss: 3.629  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.814  loss: 1.814  time: 0.4313  data_time: 0.0733  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:16] cvalgorithms INFO:  eta: 0:00:15  iter: 61  total_loss: 3.466  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.733  loss: 1.733  time: 0.4320  data_time: 0.0734  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:17] cvalgorithms INFO:  eta: 0:00:15  iter: 63  total_loss: 3.26  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.63  loss: 1.63  time: 0.4333  data_time: 0.0752  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:18] cvalgorithms INFO:  eta: 0:00:14  iter: 65  total_loss: 2.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.415  loss: 1.415  time: 0.4332  data_time: 0.0754  lr: 0.001  max_mem: 3221M
[07/05 13:41:19] cvalgorithms INFO:  eta: 0:00:13  iter: 67  total_loss: 2.461  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.231  loss: 1.231  time: 0.4331  data_time: 0.0749  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:20] cvalgorithms INFO:  eta: 0:00:12  iter: 69  total_loss: 2.461  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.231  loss: 1.231  time: 0.4330  data_time: 0.0745  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:21] cvalgorithms INFO:  eta: 0:00:11  iter: 71  total_loss: 1.452  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.726  loss: 0.726  time: 0.4329  data_time: 0.0742  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:22] cvalgorithms INFO:  eta: 0:00:11  iter: 73  total_loss: 1.43  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7149  loss: 0.7149  time: 0.4332  data_time: 0.0749  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:23] cvalgorithms INFO:  eta: 0:00:10  iter: 75  total_loss: 1.187  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5937  loss: 0.5937  time: 0.4331  data_time: 0.0740  lr: 0.001  max_mem: 3221M
[07/05 13:41:24] cvalgorithms INFO:  eta: 0:00:09  iter: 77  total_loss: 1.187  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5937  loss: 0.5937  time: 0.4334  data_time: 0.0748  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:24] cvalgorithms INFO:  eta: 0:00:08  iter: 79  total_loss: 2.12  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.06  loss: 1.06  time: 0.4334  data_time: 0.0748  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:25] cvalgorithms INFO:  eta: 0:00:07  iter: 81  total_loss: 2.12  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.06  loss: 1.06  time: 0.4336  data_time: 0.0739  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:26] cvalgorithms INFO:  eta: 0:00:06  iter: 83  total_loss: 1.43  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7149  loss: 0.7149  time: 0.4338  data_time: 0.0722  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:27] cvalgorithms INFO:  eta: 0:00:05  iter: 85  total_loss: 1.187  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5937  loss: 0.5937  time: 0.4341  data_time: 0.0726  lr: 0.001  max_mem: 3221M
[07/05 13:41:28] cvalgorithms INFO:  eta: 0:00:05  iter: 87  total_loss: 1.187  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5937  loss: 0.5937  time: 0.4345  data_time: 0.0732  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:29] cvalgorithms INFO:  eta: 0:00:04  iter: 89  total_loss: 1.121  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5606  loss: 0.5606  time: 0.4347  data_time: 0.0732  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:30] cvalgorithms INFO:  eta: 0:00:03  iter: 91  total_loss: 1.367  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6835  loss: 0.6835  time: 0.4351  data_time: 0.0736  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:31] cvalgorithms INFO:  eta: 0:00:02  iter: 93  total_loss: 1.703  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8517  loss: 0.8517  time: 0.4362  data_time: 0.0747  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:32] cvalgorithms INFO:  eta: 0:00:01  iter: 95  total_loss: 1.703  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8517  loss: 0.8517  time: 0.4370  data_time: 0.0767  lr: 0.001  max_mem: 3221M
[07/05 13:41:33] cvalgorithms INFO:  eta: 0:00:00  iter: 97  total_loss: 1.611  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8055  loss: 0.8055  time: 0.4375  data_time: 0.0759  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:34] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.09  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5449  loss: 0.5449  time: 0.4379  data_time: 0.0767  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:34] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.09  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5449  loss: 0.5449  time: 0.4379  data_time: 0.0767  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:12] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 13:43:12] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 13:43:13] cvalgorithms INFO: Starting training from iteration 0
[07/05 13:43:16] cvalgorithms INFO:  iter: 1  total_loss: 442  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 221  loss: 221  data_time: 0.0733  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:17] cvalgorithms INFO:  eta: 0:00:40  iter: 3  total_loss: 264.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 132.3  loss: 132.3  time: 0.4224  data_time: 0.0703  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:18] cvalgorithms INFO:  eta: 0:00:39  iter: 5  total_loss: 192.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 96.25  loss: 96.25  time: 0.4211  data_time: 0.0680  lr: 0.001  max_mem: 3221M
[07/05 13:43:19] cvalgorithms INFO:  eta: 0:00:38  iter: 7  total_loss: 177  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 88.49  loss: 88.49  time: 0.4222  data_time: 0.0681  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:20] cvalgorithms INFO:  eta: 0:00:37  iter: 9  total_loss: 160.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 80.45  loss: 80.45  time: 0.4210  data_time: 0.0673  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:20] cvalgorithms INFO:  eta: 0:00:37  iter: 11  total_loss: 160.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 80.45  loss: 80.45  time: 0.4222  data_time: 0.0682  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:21] cvalgorithms INFO:  eta: 0:00:35  iter: 13  total_loss: 152.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.1  loss: 76.1  time: 0.4209  data_time: 0.0669  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:22] cvalgorithms INFO:  eta: 0:00:35  iter: 15  total_loss: 144.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.4  loss: 72.4  time: 0.4215  data_time: 0.0655  lr: 0.001  max_mem: 3221M
[07/05 13:43:23] cvalgorithms INFO:  eta: 0:00:34  iter: 17  total_loss: 140.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 70.38  loss: 70.38  time: 0.4220  data_time: 0.0652  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:24] cvalgorithms INFO:  eta: 0:00:33  iter: 19  total_loss: 137  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 68.51  loss: 68.51  time: 0.4228  data_time: 0.0658  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:25] cvalgorithms INFO:  eta: 0:00:32  iter: 21  total_loss: 71.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.92  loss: 35.92  time: 0.4228  data_time: 0.0641  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:26] cvalgorithms INFO:  eta: 0:00:32  iter: 23  total_loss: 60.87  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 30.44  loss: 30.44  time: 0.4253  data_time: 0.0645  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:26] cvalgorithms INFO:  eta: 0:00:31  iter: 25  total_loss: 56.48  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.24  loss: 28.24  time: 0.4264  data_time: 0.0645  lr: 0.001  max_mem: 3221M
[07/05 13:43:27] cvalgorithms INFO:  eta: 0:00:30  iter: 27  total_loss: 44.49  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 22.24  loss: 22.24  time: 0.4281  data_time: 0.0649  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:28] cvalgorithms INFO:  eta: 0:00:29  iter: 29  total_loss: 33.24  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.62  loss: 16.62  time: 0.4296  data_time: 0.0657  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:29] cvalgorithms INFO:  eta: 0:00:29  iter: 31  total_loss: 24.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.15  loss: 12.15  time: 0.4310  data_time: 0.0652  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:30] cvalgorithms INFO:  eta: 0:00:28  iter: 33  total_loss: 20.39  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 10.19  loss: 10.19  time: 0.4323  data_time: 0.0661  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:31] cvalgorithms INFO:  eta: 0:00:27  iter: 35  total_loss: 17.71  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 8.853  loss: 8.853  time: 0.4348  data_time: 0.0685  lr: 0.001  max_mem: 3221M
[07/05 13:43:32] cvalgorithms INFO:  eta: 0:00:26  iter: 37  total_loss: 15.56  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.779  loss: 7.779  time: 0.4355  data_time: 0.0693  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:33] cvalgorithms INFO:  eta: 0:00:26  iter: 39  total_loss: 13.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.605  loss: 6.605  time: 0.4362  data_time: 0.0686  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:34] cvalgorithms INFO:  eta: 0:00:25  iter: 41  total_loss: 10.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.406  loss: 5.406  time: 0.4366  data_time: 0.0693  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:35] cvalgorithms INFO:  eta: 0:00:24  iter: 43  total_loss: 9.898  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.949  loss: 4.949  time: 0.4381  data_time: 0.0703  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:36] cvalgorithms INFO:  eta: 0:00:23  iter: 45  total_loss: 7.13  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.565  loss: 3.565  time: 0.4388  data_time: 0.0710  lr: 0.001  max_mem: 3221M
[07/05 13:43:37] cvalgorithms INFO:  eta: 0:00:22  iter: 47  total_loss: 5.412  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.706  loss: 2.706  time: 0.4396  data_time: 0.0706  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:37] cvalgorithms INFO:  eta: 0:00:22  iter: 49  total_loss: 4.628  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.314  loss: 2.314  time: 0.4403  data_time: 0.0705  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:38] cvalgorithms INFO:  eta: 0:00:21  iter: 51  total_loss: 4.048  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.024  loss: 2.024  time: 0.4411  data_time: 0.0710  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:39] cvalgorithms INFO:  eta: 0:00:20  iter: 53  total_loss: 3.775  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.887  loss: 1.887  time: 0.4419  data_time: 0.0710  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:40] cvalgorithms INFO:  eta: 0:00:19  iter: 55  total_loss: 3.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.8  loss: 1.8  time: 0.4423  data_time: 0.0693  lr: 0.001  max_mem: 3221M
[07/05 13:43:41] cvalgorithms INFO:  eta: 0:00:18  iter: 57  total_loss: 3.161  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.581  loss: 1.581  time: 0.4427  data_time: 0.0692  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:42] cvalgorithms INFO:  eta: 0:00:17  iter: 59  total_loss: 3.419  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.71  loss: 1.71  time: 0.4434  data_time: 0.0703  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:43] cvalgorithms INFO:  eta: 0:00:16  iter: 61  total_loss: 2.944  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.472  loss: 1.472  time: 0.4435  data_time: 0.0710  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:44] cvalgorithms INFO:  eta: 0:00:16  iter: 63  total_loss: 2.754  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.377  loss: 1.377  time: 0.4441  data_time: 0.0707  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:45] cvalgorithms INFO:  eta: 0:00:15  iter: 65  total_loss: 2.05  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.025  loss: 1.025  time: 0.4451  data_time: 0.0717  lr: 0.001  max_mem: 3221M
[07/05 13:43:46] cvalgorithms INFO:  eta: 0:00:14  iter: 67  total_loss: 1.675  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8376  loss: 0.8376  time: 0.4461  data_time: 0.0736  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:47] cvalgorithms INFO:  eta: 0:00:13  iter: 69  total_loss: 1.675  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8376  loss: 0.8376  time: 0.4471  data_time: 0.0755  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:48] cvalgorithms INFO:  eta: 0:00:12  iter: 71  total_loss: 1.413  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7065  loss: 0.7065  time: 0.4474  data_time: 0.0754  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:49] cvalgorithms INFO:  eta: 0:00:11  iter: 73  total_loss: 2.085  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.043  loss: 1.043  time: 0.4482  data_time: 0.0769  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:50] cvalgorithms INFO:  eta: 0:00:10  iter: 75  total_loss: 2.862  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.431  loss: 1.431  time: 0.4487  data_time: 0.0781  lr: 0.001  max_mem: 3221M
[07/05 13:43:51] cvalgorithms INFO:  eta: 0:00:09  iter: 77  total_loss: 3.105  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.553  loss: 1.553  time: 0.4491  data_time: 0.0784  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:51] cvalgorithms INFO:  eta: 0:00:09  iter: 79  total_loss: 2.231  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.115  loss: 1.115  time: 0.4495  data_time: 0.0782  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:52] cvalgorithms INFO:  eta: 0:00:08  iter: 81  total_loss: 2.22  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.11  loss: 1.11  time: 0.4497  data_time: 0.0781  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:53] cvalgorithms INFO:  eta: 0:00:07  iter: 83  total_loss: 2.45  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.225  loss: 1.225  time: 0.4507  data_time: 0.0797  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:54] cvalgorithms INFO:  eta: 0:00:06  iter: 85  total_loss: 3.105  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.553  loss: 1.553  time: 0.4511  data_time: 0.0799  lr: 0.001  max_mem: 3221M
[07/05 13:43:55] cvalgorithms INFO:  eta: 0:00:05  iter: 87  total_loss: 3.116  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.558  loss: 1.558  time: 0.4516  data_time: 0.0792  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:56] cvalgorithms INFO:  eta: 0:00:04  iter: 89  total_loss: 2.45  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.225  loss: 1.225  time: 0.4526  data_time: 0.0794  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:57] cvalgorithms INFO:  eta: 0:00:03  iter: 91  total_loss: 2.45  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.225  loss: 1.225  time: 0.4527  data_time: 0.0794  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:58] cvalgorithms INFO:  eta: 0:00:02  iter: 93  total_loss: 1.504  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7518  loss: 0.7518  time: 0.4531  data_time: 0.0784  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:59] cvalgorithms INFO:  eta: 0:00:01  iter: 95  total_loss: 1.504  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7518  loss: 0.7518  time: 0.4537  data_time: 0.0787  lr: 0.001  max_mem: 3221M
[07/05 13:44:00] cvalgorithms INFO:  eta: 0:00:00  iter: 97  total_loss: 1.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9152  loss: 0.9152  time: 0.4541  data_time: 0.0799  lr: 0.00065451  max_mem: 3221M
[07/05 13:44:01] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9152  loss: 0.9152  time: 0.4543  data_time: 0.0805  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:44:01] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9152  loss: 0.9152  time: 0.4543  data_time: 0.0805  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:48:03] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 13:48:03] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 13:48:04] cvalgorithms INFO: Starting training from iteration 0
[07/05 14:00:06] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 14:00:06] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 14:00:08] cvalgorithms INFO: Starting training from iteration 0
[07/05 14:04:21] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 14:04:21] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 14:04:23] cvalgorithms INFO: Starting training from iteration 0
[07/05 14:12:58] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 14:12:58] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 14:13:00] cvalgorithms INFO: Starting training from iteration 0
[07/05 14:13:26] cvalgorithms INFO:  iter: 1  total_loss: 200.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 100.2  loss: 100.2  data_time: 0.0677  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:27] cvalgorithms INFO:  eta: 22:14:18  iter: 3  total_loss: 158.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 79.23  loss: 79.23  time: 0.4003  data_time: 0.0597  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:28] cvalgorithms INFO:  eta: 22:29:54  iter: 5  total_loss: 161.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 80.82  loss: 80.82  time: 0.4059  data_time: 0.0609  lr: 0.001  max_mem: 3221M
[07/05 14:13:29] cvalgorithms INFO:  eta: 22:29:24  iter: 7  total_loss: 146.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 73.16  loss: 73.16  time: 0.4042  data_time: 0.0594  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:30] cvalgorithms INFO:  eta: 22:29:23  iter: 9  total_loss: 110  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 54.99  loss: 54.99  time: 0.4032  data_time: 0.0579  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:31] cvalgorithms INFO:  eta: 22:34:41  iter: 11  total_loss: 64.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.41  loss: 32.41  time: 0.4052  data_time: 0.0591  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:31] cvalgorithms INFO:  eta: 22:30:02  iter: 13  total_loss: 79.92  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.96  loss: 39.96  time: 0.4042  data_time: 0.0582  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:32] cvalgorithms INFO:  eta: 22:33:37  iter: 15  total_loss: 64.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.41  loss: 32.41  time: 0.4056  data_time: 0.0591  lr: 0.001  max_mem: 3221M
[07/05 14:13:33] cvalgorithms INFO:  eta: 22:33:37  iter: 17  total_loss: 52.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 26.35  loss: 26.35  time: 0.4064  data_time: 0.0589  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:34] cvalgorithms INFO:  eta: 22:34:38  iter: 19  total_loss: 47.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.87  loss: 23.87  time: 0.4098  data_time: 0.0606  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:35] cvalgorithms INFO:  eta: 22:37:13  iter: 21  total_loss: 37.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 18.55  loss: 18.55  time: 0.4121  data_time: 0.0609  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:36] cvalgorithms INFO:  eta: 22:43:48  iter: 23  total_loss: 24.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.37  loss: 12.37  time: 0.4129  data_time: 0.0616  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:36] cvalgorithms INFO:  eta: 22:54:13  iter: 25  total_loss: 21.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 10.6  loss: 10.6  time: 0.4132  data_time: 0.0614  lr: 0.001  max_mem: 3221M
[07/05 14:13:37] cvalgorithms INFO:  eta: 22:58:51  iter: 27  total_loss: 19.15  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 9.574  loss: 9.574  time: 0.4132  data_time: 0.0622  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:38] cvalgorithms INFO:  eta: 23:00:18  iter: 29  total_loss: 16.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 8.201  loss: 8.201  time: 0.4136  data_time: 0.0632  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:39] cvalgorithms INFO:  eta: 22:58:49  iter: 31  total_loss: 16.15  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 8.076  loss: 8.076  time: 0.4125  data_time: 0.0613  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:40] cvalgorithms INFO:  eta: 22:54:00  iter: 33  total_loss: 15.45  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.728  loss: 7.727  time: 0.4122  data_time: 0.0614  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:41] cvalgorithms INFO:  eta: 22:55:48  iter: 35  total_loss: 13.17  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.586  loss: 6.586  time: 0.4123  data_time: 0.0605  lr: 0.001  max_mem: 3221M
[07/05 14:13:41] cvalgorithms INFO:  eta: 22:58:47  iter: 37  total_loss: 12.02  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.012  loss: 6.012  time: 0.4126  data_time: 0.0610  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:42] cvalgorithms INFO:  eta: 23:00:13  iter: 39  total_loss: 11.79  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.897  loss: 5.897  time: 0.4140  data_time: 0.0616  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:43] cvalgorithms INFO:  eta: 23:03:12  iter: 41  total_loss: 8.557  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.278  loss: 4.278  time: 0.4145  data_time: 0.0601  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:44] cvalgorithms INFO:  eta: 23:06:30  iter: 43  total_loss: 8.097  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.048  loss: 4.048  time: 0.4152  data_time: 0.0610  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:45] cvalgorithms INFO:  eta: 23:07:12  iter: 45  total_loss: 7.98  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.99  loss: 3.99  time: 0.4165  data_time: 0.0631  lr: 0.001  max_mem: 3221M
[07/05 14:13:46] cvalgorithms INFO:  eta: 23:07:44  iter: 47  total_loss: 7.158  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.579  loss: 3.579  time: 0.4174  data_time: 0.0645  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:47] cvalgorithms INFO:  eta: 23:08:41  iter: 49  total_loss: 5.558  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.779  loss: 2.779  time: 0.4178  data_time: 0.0648  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:48] cvalgorithms INFO:  eta: 23:09:47  iter: 51  total_loss: 4.833  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.416  loss: 2.416  time: 0.4181  data_time: 0.0663  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:48] cvalgorithms INFO:  eta: 23:10:23  iter: 53  total_loss: 4.691  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.345  loss: 2.345  time: 0.4187  data_time: 0.0681  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:49] cvalgorithms INFO:  eta: 23:10:22  iter: 55  total_loss: 4.178  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.089  loss: 2.089  time: 0.4185  data_time: 0.0684  lr: 0.001  max_mem: 3221M
[07/05 14:13:50] cvalgorithms INFO:  eta: 23:09:44  iter: 57  total_loss: 2.736  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.368  loss: 1.368  time: 0.4182  data_time: 0.0679  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:51] cvalgorithms INFO:  eta: 23:08:37  iter: 59  total_loss: 2.552  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.276  loss: 1.276  time: 0.4181  data_time: 0.0656  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:52] cvalgorithms INFO:  eta: 23:09:42  iter: 61  total_loss: 2.426  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.213  loss: 1.213  time: 0.4187  data_time: 0.0683  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:53] cvalgorithms INFO:  eta: 23:10:19  iter: 63  total_loss: 2.254  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.127  loss: 1.127  time: 0.4189  data_time: 0.0677  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:53] cvalgorithms INFO:  eta: 23:09:41  iter: 65  total_loss: 1.953  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9767  loss: 0.9767  time: 0.4184  data_time: 0.0645  lr: 0.001  max_mem: 3221M
[07/05 14:13:54] cvalgorithms INFO:  eta: 23:10:17  iter: 67  total_loss: 2.254  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.127  loss: 1.127  time: 0.4185  data_time: 0.0633  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:55] cvalgorithms INFO:  eta: 23:10:17  iter: 69  total_loss: 2.297  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.148  loss: 1.148  time: 0.4185  data_time: 0.0624  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:56] cvalgorithms INFO:  eta: 23:11:08  iter: 71  total_loss: 1.802  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9009  loss: 0.9009  time: 0.4187  data_time: 0.0625  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:57] cvalgorithms INFO:  eta: 23:10:15  iter: 73  total_loss: 1.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6052  loss: 0.6052  time: 0.4184  data_time: 0.0604  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:58] cvalgorithms INFO:  eta: 23:10:14  iter: 75  total_loss: 1.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6052  loss: 0.6052  time: 0.4184  data_time: 0.0602  lr: 0.001  max_mem: 3221M
[07/05 14:13:58] cvalgorithms INFO:  eta: 23:11:05  iter: 77  total_loss: 1.568  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.784  loss: 0.784  time: 0.4186  data_time: 0.0611  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:59] cvalgorithms INFO:  eta: 23:12:53  iter: 79  total_loss: 1.987  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9934  loss: 0.9934  time: 0.4188  data_time: 0.0616  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:00] cvalgorithms INFO:  eta: 23:12:53  iter: 81  total_loss: 2.136  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.068  loss: 1.068  time: 0.4187  data_time: 0.0590  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:01] cvalgorithms INFO:  eta: 23:14:00  iter: 83  total_loss: 1.757  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8786  loss: 0.8786  time: 0.4189  data_time: 0.0588  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:02] cvalgorithms INFO:  eta: 23:13:59  iter: 85  total_loss: 1.917  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9583  loss: 0.9583  time: 0.4190  data_time: 0.0596  lr: 0.001  max_mem: 3221M
[07/05 14:14:03] cvalgorithms INFO:  eta: 23:13:58  iter: 87  total_loss: 1.741  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8706  loss: 0.8706  time: 0.4190  data_time: 0.0585  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:04] cvalgorithms INFO:  eta: 23:13:57  iter: 89  total_loss: 1.552  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7761  loss: 0.7761  time: 0.4191  data_time: 0.0592  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:04] cvalgorithms INFO:  eta: 23:13:56  iter: 91  total_loss: 1.757  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8786  loss: 0.8786  time: 0.4193  data_time: 0.0593  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:05] cvalgorithms INFO:  eta: 23:14:03  iter: 93  total_loss: 2.136  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.068  loss: 1.068  time: 0.4200  data_time: 0.0633  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:06] cvalgorithms INFO:  eta: 23:15:20  iter: 95  total_loss: 2.136  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.068  loss: 1.068  time: 0.4202  data_time: 0.0637  lr: 0.001  max_mem: 3221M
[07/05 14:14:07] cvalgorithms INFO:  eta: 23:16:52  iter: 97  total_loss: 2.099  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.05  loss: 1.05  time: 0.4206  data_time: 0.0638  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:08] cvalgorithms INFO:  eta: 23:16:51  iter: 99  total_loss: 1.906  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.953  loss: 0.953  time: 0.4206  data_time: 0.0632  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:09] cvalgorithms INFO:  eta: 23:19:21  iter: 101  total_loss: 1.741  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8706  loss: 0.8706  time: 0.4211  data_time: 0.0651  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:10] cvalgorithms INFO:  eta: 23:19:20  iter: 103  total_loss: 1.923  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9613  loss: 0.9613  time: 0.4212  data_time: 0.0647  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:11] cvalgorithms INFO:  eta: 23:22:55  iter: 105  total_loss: 1.923  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9613  loss: 0.9613  time: 0.4216  data_time: 0.0649  lr: 0.001  max_mem: 3221M
[07/05 14:14:11] cvalgorithms INFO:  eta: 23:24:22  iter: 107  total_loss: 2.028  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.014  loss: 1.014  time: 0.4218  data_time: 0.0664  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:12] cvalgorithms INFO:  eta: 23:24:31  iter: 109  total_loss: 2.028  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.014  loss: 1.014  time: 0.4220  data_time: 0.0662  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:13] cvalgorithms INFO:  eta: 23:24:38  iter: 111  total_loss: 1.897  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9486  loss: 0.9486  time: 0.4221  data_time: 0.0651  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:14] cvalgorithms INFO:  eta: 23:24:50  iter: 113  total_loss: 1.897  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9486  loss: 0.9486  time: 0.4224  data_time: 0.0626  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:15] cvalgorithms INFO:  eta: 23:25:16  iter: 115  total_loss: 1.897  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9486  loss: 0.9486  time: 0.4226  data_time: 0.0621  lr: 0.001  max_mem: 3221M
[07/05 14:14:16] cvalgorithms INFO:  eta: 23:25:31  iter: 117  total_loss: 1.897  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9486  loss: 0.9486  time: 0.4232  data_time: 0.0632  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:17] cvalgorithms INFO:  eta: 23:25:37  iter: 119  total_loss: 2.07  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.035  loss: 1.035  time: 0.4233  data_time: 0.0631  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:18] cvalgorithms INFO:  eta: 23:25:51  iter: 121  total_loss: 2.07  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.035  loss: 1.035  time: 0.4235  data_time: 0.0621  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:19] cvalgorithms INFO:  eta: 23:26:40  iter: 123  total_loss: 2.41  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.205  loss: 1.205  time: 0.4241  data_time: 0.0642  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:19] cvalgorithms INFO:  eta: 23:27:49  iter: 125  total_loss: 2.41  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.205  loss: 1.205  time: 0.4246  data_time: 0.0646  lr: 0.001  max_mem: 3221M
[07/05 14:14:20] cvalgorithms INFO:  eta: 23:30:30  iter: 127  total_loss: 2.704  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.352  loss: 1.352  time: 0.4256  data_time: 0.0654  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:21] cvalgorithms INFO:  eta: 23:32:55  iter: 129  total_loss: 2.952  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.476  loss: 1.476  time: 0.4267  data_time: 0.0680  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:22] cvalgorithms INFO:  eta: 23:33:11  iter: 131  total_loss: 2.733  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.367  loss: 1.367  time: 0.4274  data_time: 0.0703  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:23] cvalgorithms INFO:  eta: 23:33:36  iter: 133  total_loss: 2.504  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.252  loss: 1.252  time: 0.4280  data_time: 0.0698  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:24] cvalgorithms INFO:  eta: 23:33:57  iter: 135  total_loss: 2.504  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.252  loss: 1.252  time: 0.4288  data_time: 0.0710  lr: 0.001  max_mem: 3221M
[07/05 14:14:25] cvalgorithms INFO:  eta: 23:35:04  iter: 137  total_loss: 2.619  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.31  loss: 1.31  time: 0.4298  data_time: 0.0717  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:26] cvalgorithms INFO:  eta: 23:36:31  iter: 139  total_loss: 2.296  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.148  loss: 1.148  time: 0.4304  data_time: 0.0729  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:27] cvalgorithms INFO:  eta: 23:37:15  iter: 141  total_loss: 2.296  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.148  loss: 1.148  time: 0.4308  data_time: 0.0736  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:28] cvalgorithms INFO:  eta: 23:37:53  iter: 143  total_loss: 2.07  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.035  loss: 1.035  time: 0.4314  data_time: 0.0740  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:29] cvalgorithms INFO:  eta: 23:38:23  iter: 145  total_loss: 2.07  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.035  loss: 1.035  time: 0.4321  data_time: 0.0753  lr: 0.001  max_mem: 3221M
[07/05 14:14:30] cvalgorithms INFO:  eta: 23:39:03  iter: 147  total_loss: 1.789  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8943  loss: 0.8943  time: 0.4325  data_time: 0.0748  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:31] cvalgorithms INFO:  eta: 23:39:33  iter: 149  total_loss: 1.665  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8324  loss: 0.8324  time: 0.4330  data_time: 0.0729  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:32] cvalgorithms INFO:  eta: 23:39:57  iter: 151  total_loss: 1.358  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6791  loss: 0.6791  time: 0.4335  data_time: 0.0728  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:33] cvalgorithms INFO:  eta: 23:40:22  iter: 153  total_loss: 1.358  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6791  loss: 0.6791  time: 0.4343  data_time: 0.0753  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:34] cvalgorithms INFO:  eta: 23:41:03  iter: 155  total_loss: 1.358  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6791  loss: 0.6791  time: 0.4352  data_time: 0.0778  lr: 0.001  max_mem: 3221M
[07/05 14:14:35] cvalgorithms INFO:  eta: 23:42:25  iter: 157  total_loss: 1.355  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6773  loss: 0.6773  time: 0.4357  data_time: 0.0779  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:36] cvalgorithms INFO:  eta: 23:44:19  iter: 159  total_loss: 1.034  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5172  loss: 0.5172  time: 0.4362  data_time: 0.0788  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:37] cvalgorithms INFO:  eta: 23:47:06  iter: 161  total_loss: 0.8461  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.423  loss: 0.423  time: 0.4371  data_time: 0.0801  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:38] cvalgorithms INFO:  eta: 23:48:50  iter: 163  total_loss: 0.9006  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4503  loss: 0.4503  time: 0.4379  data_time: 0.0820  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:39] cvalgorithms INFO:  eta: 23:49:50  iter: 165  total_loss: 0.8461  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.423  loss: 0.423  time: 0.4382  data_time: 0.0817  lr: 0.001  max_mem: 3221M
[07/05 14:14:40] cvalgorithms INFO:  eta: 23:51:04  iter: 167  total_loss: 0.8443  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4221  loss: 0.4221  time: 0.4384  data_time: 0.0815  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:41] cvalgorithms INFO:  eta: 23:51:42  iter: 169  total_loss: 0.9809  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4904  loss: 0.4904  time: 0.4390  data_time: 0.0813  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:42] cvalgorithms INFO:  eta: 23:52:56  iter: 171  total_loss: 1.376  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6878  loss: 0.6878  time: 0.4393  data_time: 0.0816  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:43] cvalgorithms INFO:  eta: 23:55:26  iter: 173  total_loss: 1.376  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6878  loss: 0.6878  time: 0.4396  data_time: 0.0803  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:44] cvalgorithms INFO:  eta: 23:58:23  iter: 175  total_loss: 0.8669  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4334  loss: 0.4334  time: 0.4403  data_time: 0.0786  lr: 0.001  max_mem: 3221M
[07/05 14:14:45] cvalgorithms INFO:  eta: 1 day, 0:01:40  iter: 177  total_loss: 0.9472  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4736  loss: 0.4736  time: 0.4414  data_time: 0.0802  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:46] cvalgorithms INFO:  eta: 1 day, 0:04:50  iter: 179  total_loss: 1.145  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5724  loss: 0.5724  time: 0.4419  data_time: 0.0812  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:47] cvalgorithms INFO:  eta: 1 day, 0:06:21  iter: 181  total_loss: 1.512  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7562  loss: 0.7562  time: 0.4420  data_time: 0.0789  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:47] cvalgorithms INFO:  eta: 1 day, 0:06:58  iter: 183  total_loss: 1.17  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.585  loss: 0.585  time: 0.4424  data_time: 0.0763  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:48] cvalgorithms INFO:  eta: 1 day, 0:08:53  iter: 185  total_loss: 1.401  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7003  loss: 0.7003  time: 0.4429  data_time: 0.0763  lr: 0.001  max_mem: 3221M
[07/05 14:14:49] cvalgorithms INFO:  eta: 1 day, 0:10:43  iter: 187  total_loss: 1.17  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.585  loss: 0.585  time: 0.4430  data_time: 0.0761  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:50] cvalgorithms INFO:  eta: 1 day, 0:11:08  iter: 189  total_loss: 1.04  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5198  loss: 0.5198  time: 0.4432  data_time: 0.0770  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:51] cvalgorithms INFO:  eta: 1 day, 0:11:29  iter: 191  total_loss: 1.17  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.585  loss: 0.585  time: 0.4434  data_time: 0.0765  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:52] cvalgorithms INFO:  eta: 1 day, 0:12:35  iter: 193  total_loss: 1.17  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.585  loss: 0.585  time: 0.4437  data_time: 0.0777  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:53] cvalgorithms INFO:  eta: 1 day, 0:14:19  iter: 195  total_loss: 1.739  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8695  loss: 0.8695  time: 0.4440  data_time: 0.0765  lr: 0.001  max_mem: 3221M
[07/05 14:14:54] cvalgorithms INFO:  eta: 1 day, 0:15:19  iter: 197  total_loss: 1.623  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8117  loss: 0.8117  time: 0.4442  data_time: 0.0731  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:55] cvalgorithms INFO:  eta: 1 day, 0:17:44  iter: 199  total_loss: 1.623  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8117  loss: 0.8117  time: 0.4446  data_time: 0.0718  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:56] cvalgorithms INFO:  eta: 1 day, 0:20:07  iter: 201  total_loss: 1.79  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8951  loss: 0.8951  time: 0.4449  data_time: 0.0738  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:57] cvalgorithms INFO:  eta: 1 day, 0:22:41  iter: 203  total_loss: 1.79  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8951  loss: 0.8951  time: 0.4450  data_time: 0.0734  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:58] cvalgorithms INFO:  eta: 1 day, 0:25:16  iter: 205  total_loss: 1.791  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8953  loss: 0.8953  time: 0.4456  data_time: 0.0748  lr: 0.001  max_mem: 3221M
[07/05 14:14:59] cvalgorithms INFO:  eta: 1 day, 0:26:01  iter: 207  total_loss: 1.791  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8953  loss: 0.8953  time: 0.4458  data_time: 0.0759  lr: 0.00065451  max_mem: 3221M
[07/05 14:15:00] cvalgorithms INFO:  eta: 1 day, 0:26:38  iter: 209  total_loss: 1.791  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8953  loss: 0.8953  time: 0.4460  data_time: 0.0755  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:15:01] cvalgorithms INFO:  eta: 1 day, 0:27:39  iter: 211  total_loss: 1.727  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8637  loss: 0.8637  time: 0.4465  data_time: 0.0771  lr: 0.00090451  max_mem: 3221M
[07/05 14:15:02] cvalgorithms INFO:  eta: 1 day, 0:28:35  iter: 213  total_loss: 1.727  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8637  loss: 0.8637  time: 0.4467  data_time: 0.0760  lr: 0.00034549  max_mem: 3221M
[07/05 14:15:03] cvalgorithms INFO:  eta: 1 day, 0:30:02  iter: 215  total_loss: 1.727  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8637  loss: 0.8637  time: 0.4467  data_time: 0.0762  lr: 0.001  max_mem: 3221M
[07/05 14:15:04] cvalgorithms INFO:  eta: 1 day, 0:31:38  iter: 217  total_loss: 1.697  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8484  loss: 0.8484  time: 0.4468  data_time: 0.0759  lr: 0.00065451  max_mem: 3221M
[07/05 14:15:05] cvalgorithms INFO:  eta: 1 day, 0:33:38  iter: 219  total_loss: 1.565  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7826  loss: 0.7826  time: 0.4469  data_time: 0.0761  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:15:05] cvalgorithms INFO:  eta: 1 day, 0:36:10  iter: 221  total_loss: 1.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.605  loss: 0.605  time: 0.4471  data_time: 0.0759  lr: 0.00090451  max_mem: 3221M
[07/05 14:15:06] cvalgorithms INFO:  eta: 1 day, 0:36:10  iter: 223  total_loss: 1.351  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6757  loss: 0.6757  time: 0.4473  data_time: 0.0772  lr: 0.00034549  max_mem: 3221M
[07/05 14:15:07] cvalgorithms INFO:  eta: 1 day, 0:38:34  iter: 225  total_loss: 1.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.605  loss: 0.605  time: 0.4474  data_time: 0.0745  lr: 0.001  max_mem: 3221M
[07/05 14:15:08] cvalgorithms INFO:  eta: 1 day, 0:40:36  iter: 227  total_loss: 1.118  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.559  loss: 0.559  time: 0.4476  data_time: 0.0738  lr: 0.00065451  max_mem: 3221M
[07/05 14:15:09] cvalgorithms INFO:  eta: 1 day, 0:41:20  iter: 229  total_loss: 1.118  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.559  loss: 0.559  time: 0.4478  data_time: 0.0753  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:15:10] cvalgorithms INFO:  eta: 1 day, 0:43:22  iter: 231  total_loss: 0.9972  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4986  loss: 0.4986  time: 0.4479  data_time: 0.0729  lr: 0.00090451  max_mem: 3221M
[07/05 14:15:11] cvalgorithms INFO:  eta: 1 day, 0:45:27  iter: 233  total_loss: 1.045  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5223  loss: 0.5223  time: 0.4480  data_time: 0.0727  lr: 0.00034549  max_mem: 3221M
[07/05 14:15:12] cvalgorithms INFO:  eta: 1 day, 0:46:23  iter: 235  total_loss: 0.9972  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4986  loss: 0.4986  time: 0.4480  data_time: 0.0725  lr: 0.001  max_mem: 3221M
[07/05 14:15:13] cvalgorithms INFO:  eta: 1 day, 0:47:11  iter: 237  total_loss: 0.9705  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4852  loss: 0.4852  time: 0.4482  data_time: 0.0736  lr: 0.00065451  max_mem: 3221M
[07/05 14:15:14] cvalgorithms INFO:  eta: 1 day, 0:48:25  iter: 239  total_loss: 1.116  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5582  loss: 0.5582  time: 0.4484  data_time: 0.0736  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:15:15] cvalgorithms INFO:  eta: 1 day, 0:48:24  iter: 241  total_loss: 1.116  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5582  loss: 0.5582  time: 0.4484  data_time: 0.0723  lr: 0.00090451  max_mem: 3221M
[07/05 14:15:16] cvalgorithms INFO:  eta: 1 day, 0:49:28  iter: 243  total_loss: 1.116  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5582  loss: 0.5582  time: 0.4485  data_time: 0.0718  lr: 0.00034549  max_mem: 3221M
[07/05 14:15:17] cvalgorithms INFO:  eta: 1 day, 0:49:27  iter: 245  total_loss: 1.08  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5398  loss: 0.5398  time: 0.4485  data_time: 0.0717  lr: 0.001  max_mem: 3221M
[07/05 14:15:18] cvalgorithms INFO:  eta: 1 day, 0:50:02  iter: 247  total_loss: 1.417  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7083  loss: 0.7083  time: 0.4489  data_time: 0.0724  lr: 0.00065451  max_mem: 3221M
[07/05 14:15:19] cvalgorithms INFO:  eta: 1 day, 0:50:44  iter: 249  total_loss: 1.417  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7083  loss: 0.7083  time: 0.4493  data_time: 0.0735  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:15:20] cvalgorithms INFO:  eta: 1 day, 0:51:21  iter: 251  total_loss: 1.711  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8556  loss: 0.8556  time: 0.4496  data_time: 0.0752  lr: 0.00090451  max_mem: 3221M
[07/05 14:15:21] cvalgorithms INFO:  eta: 1 day, 0:52:01  iter: 253  total_loss: 1.473  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7364  loss: 0.7364  time: 0.4498  data_time: 0.0762  lr: 0.00034549  max_mem: 3221M
[07/05 14:15:21] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 123, in train
    self.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 133, in run_step
    self._trainer.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 204, in run_step
    data = next(self._data_loader_iter)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\utils\data\dataloader.py", line 517, in __next__
    data = self._next_data()
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\utils\data\dataloader.py", line 556, in _next_data
    index = self._next_index()  # may raise StopIteration
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\utils\data\dataloader.py", line 508, in _next_index
    return next(self._sampler_iter)  # may raise StopIteration
StopIteration
[07/05 14:15:21] cvalgorithms INFO:  eta: 1 day, 0:52:00  iter: 254  total_loss: 1.473  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7364  loss: 0.7364  time: 0.4498  data_time: 0.0762  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:06] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 14:56:07] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 14:56:08] cvalgorithms INFO: Starting training from iteration 0
[07/05 14:56:11] cvalgorithms INFO:  iter: 1  total_loss: 34.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.1  loss: 17.1  data_time: 0.0554  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:12] cvalgorithms INFO:  eta: 22:53:32  iter: 3  total_loss: 35.38  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.69  loss: 17.69  time: 0.4121  data_time: 0.0606  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:13] cvalgorithms INFO:  eta: 22:24:58  iter: 5  total_loss: 35.44  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.72  loss: 17.72  time: 0.4060  data_time: 0.0581  lr: 0.001  max_mem: 3221M
[07/05 14:56:13] cvalgorithms INFO:  eta: 22:24:57  iter: 7  total_loss: 35.44  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.72  loss: 17.72  time: 0.4045  data_time: 0.0575  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:14] cvalgorithms INFO:  eta: 22:15:45  iter: 9  total_loss: 35.44  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.72  loss: 17.72  time: 0.4028  data_time: 0.0560  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:15] cvalgorithms INFO:  eta: 22:15:44  iter: 11  total_loss: 34.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.4  loss: 17.4  time: 0.4028  data_time: 0.0559  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:16] cvalgorithms INFO:  eta: 22:15:43  iter: 13  total_loss: 35.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.55  loss: 17.55  time: 0.4028  data_time: 0.0556  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:17] cvalgorithms INFO:  eta: 22:15:42  iter: 15  total_loss: 35.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.55  loss: 17.55  time: 0.4028  data_time: 0.0556  lr: 0.001  max_mem: 3221M
[07/05 14:56:18] cvalgorithms INFO:  eta: 22:11:37  iter: 17  total_loss: 35.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.55  loss: 17.55  time: 0.4022  data_time: 0.0547  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:18] cvalgorithms INFO:  eta: 22:10:19  iter: 19  total_loss: 34.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.4  loss: 17.4  time: 0.4015  data_time: 0.0541  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:19] cvalgorithms INFO:  eta: 22:10:18  iter: 21  total_loss: 33.63  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.81  loss: 16.81  time: 0.4018  data_time: 0.0539  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:20] cvalgorithms INFO:  eta: 22:11:34  iter: 23  total_loss: 28.61  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 14.31  loss: 14.31  time: 0.4032  data_time: 0.0543  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:21] cvalgorithms INFO:  eta: 22:10:16  iter: 25  total_loss: 24.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.05  loss: 12.05  time: 0.4028  data_time: 0.0540  lr: 0.001  max_mem: 3221M
[07/05 14:56:22] cvalgorithms INFO:  eta: 22:11:33  iter: 27  total_loss: 19.57  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 9.786  loss: 9.786  time: 0.4032  data_time: 0.0544  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:22] cvalgorithms INFO:  eta: 22:10:15  iter: 29  total_loss: 13.59  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.797  loss: 6.797  time: 0.4028  data_time: 0.0544  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:23] cvalgorithms INFO:  eta: 22:11:31  iter: 31  total_loss: 11.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.919  loss: 5.919  time: 0.4032  data_time: 0.0545  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:24] cvalgorithms INFO:  eta: 22:13:33  iter: 33  total_loss: 9.939  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.97  loss: 4.97  time: 0.4032  data_time: 0.0538  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:25] cvalgorithms INFO:  eta: 22:16:46  iter: 35  total_loss: 7.695  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.848  loss: 3.848  time: 0.4034  data_time: 0.0537  lr: 0.001  max_mem: 3221M
[07/05 14:56:26] cvalgorithms INFO:  eta: 22:16:45  iter: 37  total_loss: 6.557  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.279  loss: 3.279  time: 0.4033  data_time: 0.0541  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:26] cvalgorithms INFO:  eta: 22:18:46  iter: 39  total_loss: 5.221  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.61  loss: 2.61  time: 0.4036  data_time: 0.0549  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:27] cvalgorithms INFO:  eta: 22:19:53  iter: 41  total_loss: 4.31  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.155  loss: 2.155  time: 0.4039  data_time: 0.0554  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:28] cvalgorithms INFO:  eta: 22:21:58  iter: 43  total_loss: 2.69  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.345  loss: 1.345  time: 0.4042  data_time: 0.0542  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:29] cvalgorithms INFO:  eta: 22:23:00  iter: 45  total_loss: 2.672  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.336  loss: 1.336  time: 0.4044  data_time: 0.0549  lr: 0.001  max_mem: 3221M
[07/05 14:56:30] cvalgorithms INFO:  eta: 22:22:59  iter: 47  total_loss: 2.451  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.226  loss: 1.226  time: 0.4044  data_time: 0.0541  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:31] cvalgorithms INFO:  eta: 22:24:34  iter: 49  total_loss: 2.277  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.139  loss: 1.139  time: 0.4050  data_time: 0.0558  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:31] cvalgorithms INFO:  eta: 22:24:34  iter: 51  total_loss: 2.277  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.139  loss: 1.139  time: 0.4054  data_time: 0.0559  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:32] cvalgorithms INFO:  eta: 22:26:09  iter: 53  total_loss: 2.277  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.139  loss: 1.139  time: 0.4056  data_time: 0.0566  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:33] cvalgorithms INFO:  eta: 22:26:45  iter: 55  total_loss: 2.137  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.069  loss: 1.069  time: 0.4056  data_time: 0.0565  lr: 0.001  max_mem: 3221M
[07/05 14:56:34] cvalgorithms INFO:  eta: 22:28:33  iter: 57  total_loss: 1.885  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9427  loss: 0.9427  time: 0.4060  data_time: 0.0571  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:35] cvalgorithms INFO:  eta: 22:28:32  iter: 59  total_loss: 1.64  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8199  loss: 0.8199  time: 0.4059  data_time: 0.0567  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:36] cvalgorithms INFO:  eta: 22:29:51  iter: 61  total_loss: 2.128  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.064  loss: 1.064  time: 0.4067  data_time: 0.0583  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:36] cvalgorithms INFO:  eta: 22:30:13  iter: 63  total_loss: 2.128  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.064  loss: 1.064  time: 0.4069  data_time: 0.0585  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:37] cvalgorithms INFO:  eta: 22:31:01  iter: 65  total_loss: 1.64  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8199  loss: 0.8199  time: 0.4074  data_time: 0.0598  lr: 0.001  max_mem: 3221M
[07/05 14:56:38] cvalgorithms INFO:  eta: 22:31:45  iter: 67  total_loss: 1.64  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8199  loss: 0.8199  time: 0.4083  data_time: 0.0607  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:39] cvalgorithms INFO:  eta: 22:33:10  iter: 69  total_loss: 1.794  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.897  loss: 0.897  time: 0.4086  data_time: 0.0600  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:40] cvalgorithms INFO:  eta: 22:34:31  iter: 71  total_loss: 1.508  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7539  loss: 0.7539  time: 0.4097  data_time: 0.0600  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:41] cvalgorithms INFO:  eta: 22:36:18  iter: 73  total_loss: 1.508  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7539  loss: 0.7539  time: 0.4110  data_time: 0.0624  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:42] cvalgorithms INFO:  eta: 22:37:58  iter: 75  total_loss: 1.794  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.897  loss: 0.897  time: 0.4118  data_time: 0.0637  lr: 0.001  max_mem: 3221M
[07/05 14:56:43] cvalgorithms INFO:  eta: 22:38:09  iter: 77  total_loss: 1.794  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.897  loss: 0.897  time: 0.4122  data_time: 0.0641  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:43] cvalgorithms INFO:  eta: 22:38:44  iter: 79  total_loss: 1.662  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.831  loss: 0.831  time: 0.4129  data_time: 0.0651  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:44] cvalgorithms INFO:  eta: 22:39:23  iter: 81  total_loss: 1.662  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.831  loss: 0.831  time: 0.4133  data_time: 0.0640  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:45] cvalgorithms INFO:  eta: 22:40:46  iter: 83  total_loss: 1.662  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.831  loss: 0.831  time: 0.4136  data_time: 0.0640  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:46] cvalgorithms INFO:  eta: 22:43:46  iter: 85  total_loss: 1.662  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.831  loss: 0.831  time: 0.4146  data_time: 0.0641  lr: 0.001  max_mem: 3221M
[07/05 14:56:47] cvalgorithms INFO:  eta: 22:46:06  iter: 87  total_loss: 1.662  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.831  loss: 0.831  time: 0.4151  data_time: 0.0636  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:48] cvalgorithms INFO:  eta: 22:47:42  iter: 89  total_loss: 1.822  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9111  loss: 0.9111  time: 0.4154  data_time: 0.0638  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:49] cvalgorithms INFO:  eta: 22:50:45  iter: 91  total_loss: 1.961  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9803  loss: 0.9803  time: 0.4161  data_time: 0.0649  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:50] cvalgorithms INFO:  eta: 22:54:05  iter: 93  total_loss: 1.822  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9111  loss: 0.9111  time: 0.4167  data_time: 0.0634  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:50] cvalgorithms INFO:  eta: 22:57:05  iter: 95  total_loss: 1.649  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8244  loss: 0.8244  time: 0.4172  data_time: 0.0630  lr: 0.001  max_mem: 3221M
[07/05 14:56:51] cvalgorithms INFO:  eta: 22:58:55  iter: 97  total_loss: 1.649  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8244  loss: 0.8244  time: 0.4179  data_time: 0.0633  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:52] cvalgorithms INFO:  eta: 22:59:32  iter: 99  total_loss: 1.822  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9111  loss: 0.9111  time: 0.4187  data_time: 0.0639  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:53] cvalgorithms INFO:  eta: 23:00:03  iter: 101  total_loss: 1.649  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8244  loss: 0.8244  time: 0.4194  data_time: 0.0635  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:54] cvalgorithms INFO:  eta: 23:01:48  iter: 103  total_loss: 1.822  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9111  loss: 0.9111  time: 0.4200  data_time: 0.0646  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:55] cvalgorithms INFO:  eta: 23:05:00  iter: 105  total_loss: 1.717  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8583  loss: 0.8583  time: 0.4205  data_time: 0.0634  lr: 0.001  max_mem: 3221M
[07/05 14:56:56] cvalgorithms INFO:  eta: 23:06:34  iter: 107  total_loss: 1.649  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8244  loss: 0.8244  time: 0.4211  data_time: 0.0645  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:57] cvalgorithms INFO:  eta: 23:08:57  iter: 109  total_loss: 1.532  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7659  loss: 0.7659  time: 0.4215  data_time: 0.0648  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:58] cvalgorithms INFO:  eta: 23:11:45  iter: 111  total_loss: 1.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7998  loss: 0.7998  time: 0.4222  data_time: 0.0648  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:59] cvalgorithms INFO:  eta: 23:13:57  iter: 113  total_loss: 1.803  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9013  loss: 0.9013  time: 0.4229  data_time: 0.0654  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:00] cvalgorithms INFO:  eta: 23:15:50  iter: 115  total_loss: 1.931  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9653  loss: 0.9653  time: 0.4235  data_time: 0.0658  lr: 0.001  max_mem: 3221M
[07/05 14:57:01] cvalgorithms INFO:  eta: 23:15:59  iter: 117  total_loss: 1.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9851  loss: 0.9851  time: 0.4238  data_time: 0.0653  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:01] cvalgorithms INFO:  eta: 23:19:41  iter: 119  total_loss: 1.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9851  loss: 0.9851  time: 0.4243  data_time: 0.0648  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:02] cvalgorithms INFO:  eta: 23:23:26  iter: 121  total_loss: 1.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9851  loss: 0.9851  time: 0.4247  data_time: 0.0655  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:03] cvalgorithms INFO:  eta: 23:23:39  iter: 123  total_loss: 1.803  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9013  loss: 0.9013  time: 0.4252  data_time: 0.0650  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:04] cvalgorithms INFO:  eta: 23:23:58  iter: 125  total_loss: 1.912  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9559  loss: 0.9559  time: 0.4258  data_time: 0.0667  lr: 0.001  max_mem: 3221M
[07/05 14:57:05] cvalgorithms INFO:  eta: 23:24:17  iter: 127  total_loss: 1.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9851  loss: 0.9851  time: 0.4263  data_time: 0.0669  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:06] cvalgorithms INFO:  eta: 23:24:33  iter: 129  total_loss: 2.184  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.092  loss: 1.092  time: 0.4267  data_time: 0.0674  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:07] cvalgorithms INFO:  eta: 23:25:53  iter: 131  total_loss: 1.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9851  loss: 0.9851  time: 0.4272  data_time: 0.0681  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:08] cvalgorithms INFO:  eta: 23:31:23  iter: 133  total_loss: 2.071  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.035  loss: 1.035  time: 0.4277  data_time: 0.0680  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:09] cvalgorithms INFO:  eta: 23:36:49  iter: 135  total_loss: 1.422  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7109  loss: 0.7109  time: 0.4282  data_time: 0.0684  lr: 0.001  max_mem: 3221M
[07/05 14:57:10] cvalgorithms INFO:  eta: 23:39:44  iter: 137  total_loss: 0.8319  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.416  loss: 0.416  time: 0.4286  data_time: 0.0693  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:11] cvalgorithms INFO:  eta: 23:47:20  iter: 139  total_loss: 0.7416  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.3708  loss: 0.3708  time: 0.4288  data_time: 0.0694  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:11] cvalgorithms INFO:  eta: 23:53:26  iter: 141  total_loss: 0.7416  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.3708  loss: 0.3708  time: 0.4292  data_time: 0.0689  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:12] cvalgorithms INFO:  eta: 23:57:25  iter: 143  total_loss: 0.9877  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4938  loss: 0.4938  time: 0.4297  data_time: 0.0701  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:13] cvalgorithms INFO:  eta: 1 day, 0:02:11  iter: 145  total_loss: 0.9877  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4938  loss: 0.4938  time: 0.4300  data_time: 0.0688  lr: 0.001  max_mem: 3221M
[07/05 14:57:14] cvalgorithms INFO:  eta: 1 day, 0:03:44  iter: 147  total_loss: 0.7543  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.3772  loss: 0.3772  time: 0.4304  data_time: 0.0684  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:15] cvalgorithms INFO:  eta: 1 day, 0:04:37  iter: 149  total_loss: 0.6161  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.308  loss: 0.308  time: 0.4308  data_time: 0.0682  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:16] cvalgorithms INFO:  eta: 1 day, 0:05:44  iter: 151  total_loss: 0.772  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.386  loss: 0.386  time: 0.4311  data_time: 0.0674  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:17] cvalgorithms INFO:  eta: 1 day, 0:07:14  iter: 153  total_loss: 0.9041  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4521  loss: 0.4521  time: 0.4317  data_time: 0.0688  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:18] cvalgorithms INFO:  eta: 1 day, 0:08:33  iter: 155  total_loss: 0.9041  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4521  loss: 0.4521  time: 0.4321  data_time: 0.0689  lr: 0.001  max_mem: 3221M
[07/05 14:57:19] cvalgorithms INFO:  eta: 1 day, 0:09:26  iter: 157  total_loss: 0.976  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.488  loss: 0.488  time: 0.4325  data_time: 0.0700  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:20] cvalgorithms INFO:  eta: 1 day, 0:10:11  iter: 159  total_loss: 0.9812  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4906  loss: 0.4906  time: 0.4328  data_time: 0.0705  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:21] cvalgorithms INFO:  eta: 1 day, 0:11:24  iter: 161  total_loss: 0.9283  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4641  loss: 0.4641  time: 0.4331  data_time: 0.0705  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:22] cvalgorithms INFO:  eta: 1 day, 0:15:27  iter: 163  total_loss: 0.9088  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4544  loss: 0.4544  time: 0.4333  data_time: 0.0699  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:23] cvalgorithms INFO:  eta: 1 day, 0:19:21  iter: 165  total_loss: 0.9088  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4544  loss: 0.4544  time: 0.4337  data_time: 0.0713  lr: 0.001  max_mem: 3221M
[07/05 14:57:24] cvalgorithms INFO:  eta: 1 day, 0:20:51  iter: 167  total_loss: 0.9812  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4906  loss: 0.4906  time: 0.4340  data_time: 0.0719  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:24] cvalgorithms INFO:  eta: 1 day, 0:22:34  iter: 169  total_loss: 1.262  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6311  loss: 0.6311  time: 0.4343  data_time: 0.0719  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:25] cvalgorithms INFO:  eta: 1 day, 0:23:35  iter: 171  total_loss: 1.262  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6311  loss: 0.6311  time: 0.4345  data_time: 0.0717  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:26] cvalgorithms INFO:  eta: 1 day, 0:25:04  iter: 173  total_loss: 1.013  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5063  loss: 0.5063  time: 0.4347  data_time: 0.0698  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:27] cvalgorithms INFO:  eta: 1 day, 0:27:51  iter: 175  total_loss: 0.914  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.457  loss: 0.457  time: 0.4349  data_time: 0.0693  lr: 0.001  max_mem: 3221M
[07/05 14:57:28] cvalgorithms INFO:  eta: 1 day, 0:30:18  iter: 177  total_loss: 0.8884  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4442  loss: 0.4442  time: 0.4351  data_time: 0.0678  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:29] cvalgorithms INFO:  eta: 1 day, 0:31:17  iter: 179  total_loss: 0.7602  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.3801  loss: 0.3801  time: 0.4354  data_time: 0.0682  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:30] cvalgorithms INFO:  eta: 1 day, 0:32:10  iter: 181  total_loss: 0.5918  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.2959  loss: 0.2959  time: 0.4357  data_time: 0.0683  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:31] cvalgorithms INFO:  eta: 1 day, 0:33:40  iter: 183  total_loss: 0.5797  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.2898  loss: 0.2898  time: 0.4360  data_time: 0.0684  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:32] cvalgorithms INFO:  eta: 1 day, 0:34:56  iter: 185  total_loss: 0.5595  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.2797  loss: 0.2797  time: 0.4364  data_time: 0.0676  lr: 0.001  max_mem: 3221M
[07/05 14:57:33] cvalgorithms INFO:  eta: 1 day, 0:37:24  iter: 187  total_loss: 0.5595  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.2797  loss: 0.2797  time: 0.4367  data_time: 0.0674  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:34] cvalgorithms INFO:  eta: 1 day, 0:40:10  iter: 189  total_loss: 0.5506  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.2753  loss: 0.2753  time: 0.4368  data_time: 0.0672  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:35] cvalgorithms INFO:  eta: 1 day, 0:41:35  iter: 191  total_loss: 0.5506  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.2753  loss: 0.2753  time: 0.4371  data_time: 0.0676  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:36] cvalgorithms INFO:  eta: 1 day, 0:43:21  iter: 193  total_loss: 0.5761  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.288  loss: 0.288  time: 0.4376  data_time: 0.0703  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:37] cvalgorithms INFO:  eta: 1 day, 0:44:38  iter: 195  total_loss: 0.7816  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.3908  loss: 0.3908  time: 0.4378  data_time: 0.0709  lr: 0.001  max_mem: 3221M
[07/05 14:57:37] cvalgorithms INFO:  eta: 1 day, 0:46:16  iter: 197  total_loss: 1.492  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7461  loss: 0.7461  time: 0.4380  data_time: 0.0715  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:38] cvalgorithms INFO:  eta: 1 day, 0:48:27  iter: 199  total_loss: 1.848  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.924  loss: 0.924  time: 0.4382  data_time: 0.0713  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:39] cvalgorithms INFO:  eta: 1 day, 0:49:10  iter: 201  total_loss: 1.995  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9974  loss: 0.9974  time: 0.4383  data_time: 0.0708  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:40] cvalgorithms INFO:  eta: 1 day, 0:49:46  iter: 203  total_loss: 1.848  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.924  loss: 0.924  time: 0.4385  data_time: 0.0695  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:41] cvalgorithms INFO:  eta: 1 day, 0:49:45  iter: 205  total_loss: 1.995  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9974  loss: 0.9974  time: 0.4386  data_time: 0.0690  lr: 0.001  max_mem: 3221M
[07/05 14:57:42] cvalgorithms INFO:  eta: 1 day, 0:50:27  iter: 207  total_loss: 1.848  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.924  loss: 0.924  time: 0.4388  data_time: 0.0690  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:43] cvalgorithms INFO:  eta: 1 day, 0:50:54  iter: 209  total_loss: 1.995  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9974  loss: 0.9974  time: 0.4390  data_time: 0.0692  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:44] cvalgorithms INFO:  eta: 1 day, 0:51:14  iter: 211  total_loss: 2.009  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.005  loss: 1.005  time: 0.4394  data_time: 0.0698  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:45] cvalgorithms INFO:  eta: 1 day, 0:51:33  iter: 213  total_loss: 1.847  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9235  loss: 0.9235  time: 0.4397  data_time: 0.0678  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:46] cvalgorithms INFO:  eta: 1 day, 0:51:32  iter: 215  total_loss: 1.688  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.844  loss: 0.844  time: 0.4399  data_time: 0.0679  lr: 0.001  max_mem: 3221M
[07/05 14:57:47] cvalgorithms INFO:  eta: 1 day, 0:51:53  iter: 217  total_loss: 1.358  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6791  loss: 0.6791  time: 0.4402  data_time: 0.0685  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:48] cvalgorithms INFO:  eta: 1 day, 0:51:58  iter: 219  total_loss: 1.358  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6791  loss: 0.6791  time: 0.4404  data_time: 0.0681  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:49] cvalgorithms INFO:  eta: 1 day, 0:52:04  iter: 221  total_loss: 1.314  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6569  loss: 0.6569  time: 0.4407  data_time: 0.0698  lr: 0.00090451  max_mem: 3221M
[07/05 15:55:36] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 15:55:36] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 15:56:05] cvalgorithms INFO: Starting training from iteration 0
[07/05 15:56:09] cvalgorithms INFO:  iter: 1  total_loss: 180.8  decode.loss_seg: 0.0004736  aux_0.loss: -8.928e-07  cnt.cnt_loss: 90.38  loss: 90.38  data_time: 0.0535  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:09] cvalgorithms INFO:  eta: 19:34:01  iter: 3  total_loss: 124.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 62.4  loss: 62.4  time: 0.3522  data_time: 0.0293  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:10] cvalgorithms INFO:  eta: 19:34:00  iter: 5  total_loss: 87.05  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.53  loss: 43.53  time: 0.3521  data_time: 0.0212  lr: 0.001  max_mem: 3221M
[07/05 15:56:11] cvalgorithms INFO:  eta: 19:34:00  iter: 7  total_loss: 87.05  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.53  loss: 43.53  time: 0.3520  data_time: 0.0170  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:12] cvalgorithms INFO:  eta: 19:32:51  iter: 9  total_loss: 87.05  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.53  loss: 43.53  time: 0.3516  data_time: 0.0145  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:12] cvalgorithms INFO:  eta: 19:33:30  iter: 11  total_loss: 75.08  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.54  loss: 37.54  time: 0.3518  data_time: 0.0128  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:13] cvalgorithms INFO:  eta: 19:33:30  iter: 13  total_loss: 62.39  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 31.19  loss: 31.19  time: 0.3517  data_time: 0.0115  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:14] cvalgorithms INFO:  eta: 19:33:32  iter: 15  total_loss: 49.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 24.6  loss: 24.6  time: 0.3518  data_time: 0.0106  lr: 0.001  max_mem: 3221M
[07/05 15:56:14] cvalgorithms INFO:  eta: 19:33:56  iter: 17  total_loss: 45.06  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 22.53  loss: 22.53  time: 0.3524  data_time: 0.0099  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:15] cvalgorithms INFO:  eta: 19:34:11  iter: 19  total_loss: 41.33  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 20.67  loss: 20.67  time: 0.3526  data_time: 0.0094  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:16] cvalgorithms INFO:  eta: 19:34:16  iter: 21  total_loss: 32.46  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.23  loss: 16.23  time: 0.3527  data_time: 0.0045  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:17] cvalgorithms INFO:  eta: 19:34:15  iter: 23  total_loss: 25.34  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.67  loss: 12.67  time: 0.3527  data_time: 0.0044  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:17] cvalgorithms INFO:  eta: 19:34:15  iter: 25  total_loss: 22.69  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 11.34  loss: 11.34  time: 0.3527  data_time: 0.0044  lr: 0.001  max_mem: 3221M
[07/05 15:56:18] cvalgorithms INFO:  eta: 19:34:48  iter: 27  total_loss: 19.19  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 9.597  loss: 9.597  time: 0.3529  data_time: 0.0044  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:19] cvalgorithms INFO:  eta: 19:35:36  iter: 29  total_loss: 15.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.649  loss: 7.649  time: 0.3532  data_time: 0.0044  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:19] cvalgorithms INFO:  eta: 19:35:53  iter: 31  total_loss: 13.63  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.813  loss: 6.813  time: 0.3540  data_time: 0.0044  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:20] cvalgorithms INFO:  eta: 19:36:05  iter: 33  total_loss: 10.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.07  loss: 5.07  time: 0.3543  data_time: 0.0045  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:21] cvalgorithms INFO:  eta: 19:36:19  iter: 35  total_loss: 8.058  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.029  loss: 4.029  time: 0.3546  data_time: 0.0045  lr: 0.001  max_mem: 3221M
[07/05 15:56:22] cvalgorithms INFO:  eta: 19:36:31  iter: 37  total_loss: 5.769  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.885  loss: 2.885  time: 0.3547  data_time: 0.0045  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:22] cvalgorithms INFO:  eta: 19:37:14  iter: 39  total_loss: 4.631  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.316  loss: 2.316  time: 0.3550  data_time: 0.0045  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:23] cvalgorithms INFO:  eta: 19:37:19  iter: 41  total_loss: 4.116  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.058  loss: 2.058  time: 0.3550  data_time: 0.0044  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:24] cvalgorithms INFO:  eta: 19:38:20  iter: 43  total_loss: 3.716  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.858  loss: 1.858  time: 0.3550  data_time: 0.0044  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:24] cvalgorithms INFO:  eta: 19:39:04  iter: 45  total_loss: 3.487  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.744  loss: 1.744  time: 0.3551  data_time: 0.0044  lr: 0.001  max_mem: 3221M
[07/05 15:56:25] cvalgorithms INFO:  eta: 19:39:58  iter: 47  total_loss: 3.171  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.586  loss: 1.586  time: 0.3552  data_time: 0.0044  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:26] cvalgorithms INFO:  eta: 19:40:49  iter: 49  total_loss: 3.171  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.586  loss: 1.586  time: 0.3553  data_time: 0.0044  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:27] cvalgorithms INFO:  eta: 19:41:39  iter: 51  total_loss: 3.171  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.586  loss: 1.586  time: 0.3554  data_time: 0.0044  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:27] cvalgorithms INFO:  eta: 19:42:34  iter: 53  total_loss: 3.038  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.519  loss: 1.519  time: 0.3555  data_time: 0.0044  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:28] cvalgorithms INFO:  eta: 19:43:04  iter: 55  total_loss: 2.708  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.354  loss: 1.354  time: 0.3555  data_time: 0.0045  lr: 0.001  max_mem: 3221M
[07/05 15:56:29] cvalgorithms INFO:  eta: 19:44:02  iter: 57  total_loss: 1.608  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8042  loss: 0.8042  time: 0.3557  data_time: 0.0045  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:30] cvalgorithms INFO:  eta: 19:44:58  iter: 59  total_loss: 1.608  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8042  loss: 0.8042  time: 0.3557  data_time: 0.0045  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:30] cvalgorithms INFO:  eta: 19:45:15  iter: 61  total_loss: 2.883  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.442  loss: 1.442  time: 0.3559  data_time: 0.0046  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:31] cvalgorithms INFO:  eta: 19:45:57  iter: 63  total_loss: 2.483  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.242  loss: 1.242  time: 0.3559  data_time: 0.0046  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:32] cvalgorithms INFO:  eta: 19:46:37  iter: 65  total_loss: 1.894  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9472  loss: 0.9472  time: 0.3561  data_time: 0.0046  lr: 0.001  max_mem: 3221M
[07/05 15:56:32] cvalgorithms INFO:  eta: 19:47:10  iter: 67  total_loss: 2.847  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.423  loss: 1.423  time: 0.3562  data_time: 0.0046  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:33] cvalgorithms INFO:  eta: 19:47:40  iter: 69  total_loss: 2.847  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.423  loss: 1.423  time: 0.3572  data_time: 0.0046  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:34] cvalgorithms INFO:  eta: 19:47:55  iter: 71  total_loss: 2.847  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.423  loss: 1.423  time: 0.3574  data_time: 0.0047  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:35] cvalgorithms INFO:  eta: 19:48:16  iter: 73  total_loss: 2.589  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.295  loss: 1.295  time: 0.3575  data_time: 0.0046  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:35] cvalgorithms INFO:  eta: 19:48:31  iter: 75  total_loss: 2.306  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.153  loss: 1.153  time: 0.3576  data_time: 0.0046  lr: 0.001  max_mem: 3221M
[07/05 15:56:36] cvalgorithms INFO:  eta: 19:48:41  iter: 77  total_loss: 2.589  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.295  loss: 1.295  time: 0.3577  data_time: 0.0045  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:37] cvalgorithms INFO:  eta: 19:49:08  iter: 79  total_loss: 2.306  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.153  loss: 1.153  time: 0.3582  data_time: 0.0045  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:38] cvalgorithms INFO:  eta: 19:49:52  iter: 81  total_loss: 2.306  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.153  loss: 1.153  time: 0.3586  data_time: 0.0045  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:38] cvalgorithms INFO:  eta: 19:50:34  iter: 83  total_loss: 2.122  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.061  loss: 1.061  time: 0.3590  data_time: 0.0045  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:39] cvalgorithms INFO:  eta: 19:50:57  iter: 85  total_loss: 2.122  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.061  loss: 1.061  time: 0.3596  data_time: 0.0046  lr: 0.001  max_mem: 3221M
[07/05 15:56:40] cvalgorithms INFO:  eta: 19:51:04  iter: 87  total_loss: 1.793  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8967  loss: 0.8967  time: 0.3601  data_time: 0.0047  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:41] cvalgorithms INFO:  eta: 19:51:39  iter: 89  total_loss: 1.156  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5781  loss: 0.5781  time: 0.3606  data_time: 0.0047  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:41] cvalgorithms INFO:  eta: 19:52:08  iter: 91  total_loss: 1.156  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5781  loss: 0.5781  time: 0.3611  data_time: 0.0047  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:42] cvalgorithms INFO:  eta: 19:52:33  iter: 93  total_loss: 1.483  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7414  loss: 0.7414  time: 0.3614  data_time: 0.0048  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:43] cvalgorithms INFO:  eta: 19:53:03  iter: 95  total_loss: 1.741  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8703  loss: 0.8703  time: 0.3622  data_time: 0.0048  lr: 0.001  max_mem: 3221M
[07/05 15:56:44] cvalgorithms INFO:  eta: 19:53:20  iter: 97  total_loss: 1.799  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8993  loss: 0.8993  time: 0.3626  data_time: 0.0048  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:45] cvalgorithms INFO:  eta: 19:53:32  iter: 99  total_loss: 1.782  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.891  loss: 0.891  time: 0.3628  data_time: 0.0048  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:45] cvalgorithms INFO:  eta: 19:53:40  iter: 101  total_loss: 1.469  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7343  loss: 0.7343  time: 0.3631  data_time: 0.0048  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:46] cvalgorithms INFO:  eta: 19:54:05  iter: 103  total_loss: 1.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9199  loss: 0.9199  time: 0.3635  data_time: 0.0049  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:47] cvalgorithms INFO:  eta: 19:54:25  iter: 105  total_loss: 1.853  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9265  loss: 0.9265  time: 0.3638  data_time: 0.0047  lr: 0.001  max_mem: 3221M
[07/05 15:56:48] cvalgorithms INFO:  eta: 19:54:54  iter: 107  total_loss: 1.941  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9704  loss: 0.9704  time: 0.3642  data_time: 0.0048  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:48] cvalgorithms INFO:  eta: 19:55:44  iter: 109  total_loss: 1.941  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9704  loss: 0.9704  time: 0.3646  data_time: 0.0047  lr: 9.5492e-05  max_mem: 3221M
[07/05 16:11:10] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 16:11:10] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 16:13:12] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 16:13:12] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 16:14:43] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 16:14:43] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 16:16:10] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 16:16:10] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 16:17:21] cvalgorithms INFO: Starting training from iteration 0
[07/05 16:17:24] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 114, in after_step
    next_epoch = self.trainer.epoch + 1
AttributeError: 'TrainerContainer' object has no attribute 'epoch'
[07/05 16:17:24] cvalgorithms INFO:  iter: 0  total_loss: 139.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 69.76  loss: 69.76  data_time: 0.0119  lr: 0.001  max_mem: 3221M
[07/06 11:05:06] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 11:05:07] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 11:05:39] cvalgorithms INFO: Starting training from iteration 0
[07/06 11:05:43] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 147, in after_step
    if self._period > 0 and next_iter % self._period == 0:
TypeError: '>' not supported between instances of 'Config' and 'int'
[07/06 11:05:43] cvalgorithms INFO:  iter: 0  total_loss: 420  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 210  loss: 210  data_time: 0.0642  lr: 0.001  max_mem: 3221M
[07/06 11:21:36] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 11:21:36] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 11:22:04] cvalgorithms INFO: Starting training from iteration 0
[07/06 13:04:51] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 13:04:51] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 13:05:21] cvalgorithms INFO: Starting training from iteration 0
[07/06 13:12:37] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 13:12:37] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 13:13:07] cvalgorithms INFO: Starting training from iteration 0
[07/06 13:13:34] cvalgorithms INFO:  iter: 1  total_loss: 207.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 103.7  loss: 103.7  data_time: 0.0301  lr: 0.00090451  max_mem: 3221M
[07/06 13:13:37] cvalgorithms INFO:  eta: 0:00:48  iter: 3  total_loss: 202.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 101.3  loss: 101.3  time: 0.5032  data_time: 0.0177  lr: 0.00034549  max_mem: 3221M
[07/06 13:13:39] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 116.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 58.2  loss: 58.2  time: 0.4324  data_time: 0.0136  lr: 0.001  max_mem: 3221M
[07/06 13:13:41] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 116.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 58.06  loss: 58.06  time: 0.4079  data_time: 0.0115  lr: 0.00065451  max_mem: 3221M
[07/06 13:13:42] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 84.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 42.37  loss: 42.37  time: 0.3976  data_time: 0.0101  lr: 9.5492e-05  max_mem: 3221M
[07/06 13:13:44] cvalgorithms INFO:  eta: 0:00:32  iter: 11  total_loss: 82.26  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.13  loss: 41.13  time: 0.3938  data_time: 0.0093  lr: 0.00090451  max_mem: 3221M
[07/06 13:17:33] cvalgorithms INFO:  eta: 0:00:31  iter: 13  total_loss: 73.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 36.57  loss: 36.57  time: 0.3880  data_time: 0.0087  lr: 0.00034549  max_mem: 3221M
[07/06 13:22:15] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 13:22:15] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 13:22:43] cvalgorithms INFO: Starting training from iteration 0
[07/06 13:23:05] cvalgorithms INFO:  iter: 1  total_loss: 435.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 217.9  loss: 217.9  data_time: 0.0315  lr: 0.00090451  max_mem: 3221M
[07/06 13:23:06] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 252.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 126.2  loss: 126.2  time: 0.3554  data_time: 0.0179  lr: 0.00034549  max_mem: 3221M
[07/06 13:23:07] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 204.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 102.1  loss: 102.1  time: 0.3578  data_time: 0.0136  lr: 0.001  max_mem: 3221M
[07/06 13:23:08] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 160  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 80.02  loss: 80.02  time: 0.3581  data_time: 0.0114  lr: 0.00065451  max_mem: 3221M
[07/06 13:23:08] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 160  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 80.02  loss: 80.02  time: 0.3578  data_time: 0.0100  lr: 9.5492e-05  max_mem: 3221M
[07/06 13:23:09] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 114.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 57.44  loss: 57.44  time: 0.3577  data_time: 0.0090  lr: 0.00090451  max_mem: 3221M
[07/06 13:23:10] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 77.22  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 38.61  loss: 38.61  time: 0.3575  data_time: 0.0083  lr: 0.00034549  max_mem: 3221M
[07/06 13:23:11] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 73.77  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 36.88  loss: 36.88  time: 0.3574  data_time: 0.0079  lr: 0.001  max_mem: 3221M
[07/06 13:23:11] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 68.42  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.21  loss: 34.21  time: 0.3574  data_time: 0.0075  lr: 0.00065451  max_mem: 3221M
[07/06 13:23:20] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 89, in test_and_save_results
    self._last_eval_results = self._eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 199, in _eval
    bar = ProgressBar(len(self.val_dataloader))
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\utils\data\dataloader.py", line 391, in __len__
    length = self._IterableDataset_len_called = len(self.dataset)  # type: ignore
  File "C:\Users\user1\PycharmProjects\cvalgorithms\datasets\builder.py", line 71, in __len__
    return len(self.sampler)
TypeError: object of type 'TrainingSampler' has no len()
[07/06 13:24:05] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 13:24:05] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 13:24:35] cvalgorithms INFO: Starting training from iteration 0
[07/06 13:24:38] cvalgorithms INFO:  iter: 1  total_loss: 298.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 149.4  loss: 149.4  data_time: 0.0354  lr: 0.00090451  max_mem: 3221M
[07/06 13:24:39] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 130.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 65.33  loss: 65.33  time: 0.3604  data_time: 0.0199  lr: 0.00034549  max_mem: 3221M
[07/06 13:24:40] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 155.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 77.6  loss: 77.6  time: 0.3582  data_time: 0.0147  lr: 0.001  max_mem: 3221M
[07/06 13:24:40] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 155.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 77.6  loss: 77.6  time: 0.3585  data_time: 0.0121  lr: 0.00065451  max_mem: 3221M
[07/06 13:24:41] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 126.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 63.41  loss: 63.41  time: 0.3585  data_time: 0.0106  lr: 9.5492e-05  max_mem: 3221M
[07/06 13:24:42] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 126.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 63.41  loss: 63.41  time: 0.3585  data_time: 0.0095  lr: 0.00090451  max_mem: 3221M
[07/06 13:24:43] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 79.64  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.82  loss: 39.82  time: 0.3584  data_time: 0.0088  lr: 0.00034549  max_mem: 3221M
[07/06 13:24:43] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 59.24  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 29.62  loss: 29.62  time: 0.3584  data_time: 0.0082  lr: 0.001  max_mem: 3221M
[07/06 13:24:44] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 51.41  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 25.71  loss: 25.71  time: 0.3585  data_time: 0.0078  lr: 0.00065451  max_mem: 3221M
[07/06 13:45:40] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 13:45:40] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 13:46:08] cvalgorithms INFO: Starting training from iteration 0
[07/06 13:46:12] cvalgorithms INFO:  iter: 1  total_loss: 385.3  decode.loss_seg: -1.164e-07  aux_0.loss: 0  cnt.cnt_loss: 192.6  loss: 192.6  data_time: 0.0359  lr: 0.00090451  max_mem: 3221M
[07/06 13:46:12] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 334.5  decode.loss_seg: -1.164e-07  aux_0.loss: 0  cnt.cnt_loss: 167.3  loss: 167.3  time: 0.3595  data_time: 0.0202  lr: 0.00034549  max_mem: 3221M
[07/06 13:46:13] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 199.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 99.93  loss: 99.93  time: 0.3579  data_time: 0.0150  lr: 0.001  max_mem: 3221M
[07/06 13:46:14] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 189.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 94.59  loss: 94.59  time: 0.3571  data_time: 0.0123  lr: 0.00065451  max_mem: 3221M
[07/06 13:46:14] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 147.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 73.55  loss: 73.55  time: 0.3570  data_time: 0.0107  lr: 9.5492e-05  max_mem: 3221M
[07/06 13:46:15] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 118.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 59.08  loss: 59.08  time: 0.3575  data_time: 0.0096  lr: 0.00090451  max_mem: 3221M
[07/06 13:46:16] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 81.55  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 40.78  loss: 40.78  time: 0.3580  data_time: 0.0089  lr: 0.00034549  max_mem: 3221M
[07/06 13:46:17] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 79.15  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.58  loss: 39.58  time: 0.3583  data_time: 0.0084  lr: 0.001  max_mem: 3221M
[07/06 13:46:17] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 64.71  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.35  loss: 32.35  time: 0.3589  data_time: 0.0079  lr: 0.00065451  max_mem: 3221M
[07/06 13:47:41] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 89, in test_and_save_results
    self._last_eval_results = self._eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 203, in _eval
    _img, _ground_truth = data['images_collect']['img_']
KeyError: 'img_'
[07/06 13:47:41] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 58.37  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 29.18  loss: 29.18  time: 0.3595  data_time: 0.0076  lr: 9.5492e-05  max_mem: 3221M
[07/06 13:48:26] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 13:48:26] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 13:48:56] cvalgorithms INFO: Starting training from iteration 0
[07/06 13:48:59] cvalgorithms INFO:  iter: 1  total_loss: 80.65  decode.loss_seg: -0.007989  aux_0.loss: 3.926e-06  cnt.cnt_loss: 40.33  loss: 40.33  data_time: 0.0545  lr: 0.00090451  max_mem: 3221M
[07/06 13:49:00] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 80.65  decode.loss_seg: 0  aux_0.loss: 8.793e-08  cnt.cnt_loss: 40.33  loss: 40.33  time: 0.3614  data_time: 0.0295  lr: 0.00034549  max_mem: 3221M
[07/06 13:49:01] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 87.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.58  loss: 43.57  time: 0.3625  data_time: 0.0213  lr: 0.001  max_mem: 3221M
[07/06 13:49:02] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 87.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.58  loss: 43.57  time: 0.3626  data_time: 0.0172  lr: 0.00065451  max_mem: 3221M
[07/06 13:49:02] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 84.76  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 42.39  loss: 42.38  time: 0.3640  data_time: 0.0146  lr: 9.5492e-05  max_mem: 3221M
[07/06 13:49:03] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 84.76  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 42.39  loss: 42.38  time: 0.3634  data_time: 0.0129  lr: 0.00090451  max_mem: 3221M
[07/06 13:49:04] cvalgorithms INFO:  eta: 0:00:31  iter: 13  total_loss: 82.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.05  loss: 41.05  time: 0.3652  data_time: 0.0118  lr: 0.00034549  max_mem: 3221M
[07/06 13:49:05] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 77.99  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 38.99  loss: 38.99  time: 0.3656  data_time: 0.0110  lr: 0.001  max_mem: 3221M
[07/06 13:49:05] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 70.64  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.32  loss: 35.32  time: 0.3667  data_time: 0.0103  lr: 0.00065451  max_mem: 3221M
[07/06 14:04:36] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 14:04:36] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 14:05:08] cvalgorithms INFO: Starting training from iteration 0
[07/06 14:05:12] cvalgorithms INFO:  iter: 1  total_loss: 397.1  decode.loss_seg: 1.519e-07  aux_0.loss: -8.723e-07  cnt.cnt_loss: 198.5  loss: 198.5  data_time: 0.0411  lr: 0.00090451  max_mem: 3221M
[07/06 14:05:13] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 159.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 79.68  loss: 79.68  time: 0.3568  data_time: 0.0227  lr: 0.00034549  max_mem: 3221M
[07/06 14:05:13] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 111.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 55.57  loss: 55.57  time: 0.3582  data_time: 0.0167  lr: 0.001  max_mem: 3221M
[07/06 14:05:14] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 120  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 59.98  loss: 59.98  time: 0.3574  data_time: 0.0135  lr: 0.00065451  max_mem: 3221M
[07/06 14:05:15] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 110.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 55.05  loss: 55.05  time: 0.3580  data_time: 0.0118  lr: 9.5492e-05  max_mem: 3221M
[07/06 14:05:16] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 100.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.4  loss: 50.4  time: 0.3605  data_time: 0.0107  lr: 0.00090451  max_mem: 3221M
[07/06 14:05:16] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 93.27  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 46.64  loss: 46.64  time: 0.3621  data_time: 0.0098  lr: 0.00034549  max_mem: 3221M
[07/06 14:05:17] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 78.92  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.46  loss: 39.46  time: 0.3638  data_time: 0.0093  lr: 0.001  max_mem: 3221M
[07/06 14:05:18] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 70.19  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.09  loss: 35.09  time: 0.3641  data_time: 0.0088  lr: 0.00065451  max_mem: 3221M
[07/06 16:34:05] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 16:34:05] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 16:34:36] cvalgorithms INFO: Starting training from iteration 0
[07/06 16:34:40] cvalgorithms INFO:  iter: 1  total_loss: 271.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 135.9  loss: 135.9  data_time: 0.0344  lr: 0.00090451  max_mem: 3221M
[07/06 16:34:41] cvalgorithms INFO:  eta: 0:00:36  iter: 3  total_loss: 139.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 69.78  loss: 69.78  time: 0.3798  data_time: 0.0200  lr: 0.00034549  max_mem: 3221M
[07/06 16:34:41] cvalgorithms INFO:  eta: 0:00:35  iter: 5  total_loss: 119.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 59.62  loss: 59.62  time: 0.3720  data_time: 0.0150  lr: 0.001  max_mem: 3221M
[07/06 16:34:42] cvalgorithms INFO:  eta: 0:00:34  iter: 7  total_loss: 119.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 59.62  loss: 59.62  time: 0.3698  data_time: 0.0124  lr: 0.00065451  max_mem: 3221M
[07/06 16:34:43] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 90.67  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 45.33  loss: 45.33  time: 0.3674  data_time: 0.0108  lr: 9.5492e-05  max_mem: 3221M
[07/06 16:34:44] cvalgorithms INFO:  eta: 0:00:32  iter: 11  total_loss: 88.76  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 44.38  loss: 44.38  time: 0.3675  data_time: 0.0099  lr: 0.00090451  max_mem: 3221M
[07/06 16:34:44] cvalgorithms INFO:  eta: 0:00:31  iter: 13  total_loss: 72.88  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 36.44  loss: 36.44  time: 0.3685  data_time: 0.0092  lr: 0.00034549  max_mem: 3221M
[07/06 16:34:45] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 74.66  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.33  loss: 37.33  time: 0.3683  data_time: 0.0088  lr: 0.001  max_mem: 3221M
[07/06 16:34:46] cvalgorithms INFO:  eta: 0:00:30  iter: 17  total_loss: 72.88  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 36.44  loss: 36.44  time: 0.3681  data_time: 0.0084  lr: 0.00065451  max_mem: 3221M
[07/06 16:34:46] cvalgorithms INFO: Start inference on 216 batches
[07/06 17:54:26] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 17:54:27] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 17:54:54] cvalgorithms INFO: Starting training from iteration 0
[07/06 17:54:58] cvalgorithms INFO:  iter: 1  total_loss: 238  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 119  loss: 119  data_time: 0.0572  lr: 0.00090451  max_mem: 3221M
[07/06 17:54:59] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 142.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 71.12  loss: 71.12  time: 0.3554  data_time: 0.0312  lr: 0.00034549  max_mem: 3221M
[07/06 17:55:00] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 106.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 53.41  loss: 53.41  time: 0.3619  data_time: 0.0226  lr: 0.001  max_mem: 3221M
[07/06 17:55:00] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 67.08  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.54  loss: 33.54  time: 0.3590  data_time: 0.0181  lr: 0.00065451  max_mem: 3221M
[07/06 17:55:01] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 70.73  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.37  loss: 35.37  time: 0.3582  data_time: 0.0153  lr: 9.5492e-05  max_mem: 3221M
[07/06 17:55:02] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 54.44  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.22  loss: 27.22  time: 0.3582  data_time: 0.0136  lr: 0.00090451  max_mem: 3221M
[07/06 17:55:02] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 49.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 24.88  loss: 24.88  time: 0.3579  data_time: 0.0124  lr: 0.00034549  max_mem: 3221M
[07/06 17:55:03] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 49.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 24.88  loss: 24.88  time: 0.3574  data_time: 0.0114  lr: 0.001  max_mem: 3221M
[07/06 17:55:04] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 46.55  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.28  loss: 23.28  time: 0.3575  data_time: 0.0106  lr: 0.00065451  max_mem: 3221M
[07/06 17:55:05] cvalgorithms INFO: Start inference on 216 batches
[07/06 17:55:05] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 88, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 209, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluator)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 67, in inference_on_dataset
    evaluator.reset()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 38, in reset
    evaluator.reset()
TypeError: reset() missing 1 required positional argument: 'self'
[07/06 17:55:05] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 42.96  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 21.48  loss: 21.48  time: 0.3572  data_time: 0.0100  lr: 9.5492e-05  max_mem: 3221M
[07/06 17:56:37] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 17:56:37] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 17:57:06] cvalgorithms INFO: Starting training from iteration 0
[07/06 17:57:10] cvalgorithms INFO:  iter: 1  total_loss: 99.1  decode.loss_seg: -6.598e-09  aux_0.loss: 5.344e-07  cnt.cnt_loss: 49.55  loss: 49.55  data_time: 0.0666  lr: 0.00090451  max_mem: 3221M
[07/06 17:57:11] cvalgorithms INFO:  eta: 0:00:35  iter: 3  total_loss: 70.47  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.23  loss: 35.23  time: 0.3662  data_time: 0.0355  lr: 0.00034549  max_mem: 3221M
[07/06 17:57:12] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 70.47  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.23  loss: 35.23  time: 0.3613  data_time: 0.0252  lr: 0.001  max_mem: 3221M
[07/06 17:57:12] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 70.47  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.23  loss: 35.23  time: 0.3604  data_time: 0.0200  lr: 0.00065451  max_mem: 3221M
[07/06 17:57:13] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 47.26  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.63  loss: 23.63  time: 0.3592  data_time: 0.0168  lr: 9.5492e-05  max_mem: 3221M
[07/06 17:57:14] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 47.26  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.63  loss: 23.63  time: 0.3589  data_time: 0.0148  lr: 0.00090451  max_mem: 3221M
[07/06 17:57:14] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 28.68  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 14.34  loss: 14.34  time: 0.3585  data_time: 0.0133  lr: 0.00034549  max_mem: 3221M
[07/06 17:57:15] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 25.45  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.72  loss: 12.72  time: 0.3583  data_time: 0.0122  lr: 0.001  max_mem: 3221M
[07/06 17:57:16] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 24  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12  loss: 12  time: 0.3583  data_time: 0.0113  lr: 0.00065451  max_mem: 3221M
[07/06 17:57:17] cvalgorithms INFO: Start inference on 216 batches
[07/06 17:57:17] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 88, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 209, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluator)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 66, in inference_on_dataset
    evaluator.reset()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 37, in reset
    evaluator.reset()
TypeError: reset() missing 1 required positional argument: 'self'
[07/06 17:57:17] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 24.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.3  loss: 12.3  time: 0.3583  data_time: 0.0107  lr: 9.5492e-05  max_mem: 3221M
[07/06 17:58:09] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 17:58:09] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 17:58:39] cvalgorithms INFO: Starting training from iteration 0
[07/06 17:58:42] cvalgorithms INFO:  iter: 1  total_loss: 138.9  decode.loss_seg: -1.414e-08  aux_0.loss: 3.074e-07  cnt.cnt_loss: 69.46  loss: 69.46  data_time: 0.0685  lr: 0.00090451  max_mem: 3221M
[07/06 17:58:43] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 59.47  decode.loss_seg: -1.414e-08  aux_0.loss: 3.653e-08  cnt.cnt_loss: 29.73  loss: 29.73  time: 0.3589  data_time: 0.0364  lr: 0.00034549  max_mem: 3221M
[07/06 17:58:44] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 57.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.91  loss: 28.91  time: 0.3584  data_time: 0.0258  lr: 0.001  max_mem: 3221M
[07/06 17:58:45] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 65.91  decode.loss_seg: 0  aux_0.loss: 3.653e-08  cnt.cnt_loss: 32.95  loss: 32.95  time: 0.3584  data_time: 0.0205  lr: 0.00065451  max_mem: 3221M
[07/06 17:58:45] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 65.91  decode.loss_seg: 0  aux_0.loss: 3.653e-08  cnt.cnt_loss: 32.95  loss: 32.95  time: 0.3591  data_time: 0.0173  lr: 9.5492e-05  max_mem: 3221M
[07/06 17:58:46] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 57.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.91  loss: 28.91  time: 0.3592  data_time: 0.0152  lr: 0.00090451  max_mem: 3221M
[07/06 17:58:47] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 57.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.91  loss: 28.91  time: 0.3598  data_time: 0.0137  lr: 0.00034549  max_mem: 3221M
[07/06 17:58:48] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 57.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.91  loss: 28.91  time: 0.3618  data_time: 0.0125  lr: 0.001  max_mem: 3221M
[07/06 17:58:48] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 56.41  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.2  loss: 28.2  time: 0.3624  data_time: 0.0117  lr: 0.00065451  max_mem: 3221M
[07/06 17:58:54] cvalgorithms INFO: Start inference on 216 batches
[07/06 18:22:04] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 18:22:04] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 18:22:32] cvalgorithms INFO: Starting training from iteration 0
[07/06 18:22:36] cvalgorithms INFO:  iter: 1  total_loss: 147.3  decode.loss_seg: -0.001927  aux_0.loss: -6.447e-07  cnt.cnt_loss: 73.63  loss: 73.63  data_time: 0.0395  lr: 0.00090451  max_mem: 3221M
[07/06 18:22:37] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 87.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.9  loss: 43.9  time: 0.3514  data_time: 0.0223  lr: 0.00034549  max_mem: 3221M
[07/06 18:22:37] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 83.48  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.74  loss: 41.74  time: 0.3536  data_time: 0.0166  lr: 0.001  max_mem: 3221M
[07/06 18:22:38] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 83.48  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.74  loss: 41.74  time: 0.3534  data_time: 0.0136  lr: 0.00065451  max_mem: 3221M
[07/06 18:22:39] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 74.51  decode.loss_seg: 0  aux_0.loss: 5.809e-08  cnt.cnt_loss: 37.26  loss: 37.26  time: 0.3546  data_time: 0.0118  lr: 9.5492e-05  max_mem: 3221M
[07/06 18:22:39] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 67.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.99  loss: 33.98  time: 0.3541  data_time: 0.0106  lr: 0.00090451  max_mem: 3221M
[07/06 18:22:40] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 59.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 29.95  loss: 29.95  time: 0.3541  data_time: 0.0097  lr: 0.00034549  max_mem: 3221M
[07/06 18:22:41] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 47.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.92  loss: 23.92  time: 0.3554  data_time: 0.0091  lr: 0.001  max_mem: 3221M
[07/06 18:22:42] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 55.56  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.78  loss: 27.78  time: 0.3553  data_time: 0.0086  lr: 0.00065451  max_mem: 3221M
[07/06 18:22:46] cvalgorithms INFO: Start inference on 216 batches
[07/06 19:13:13] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 19:13:13] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 19:13:40] cvalgorithms INFO: Starting training from iteration 0
[07/06 19:13:45] cvalgorithms INFO:  iter: 1  total_loss: 238.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 119.3  loss: 119.3  data_time: 0.0849  lr: 0.00090451  max_mem: 3221M
[07/06 19:13:45] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 152.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.39  loss: 76.39  time: 0.3600  data_time: 0.0447  lr: 0.00034549  max_mem: 3221M
[07/06 19:13:46] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 84.15  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 42.07  loss: 42.07  time: 0.3601  data_time: 0.0315  lr: 0.001  max_mem: 3221M
[07/06 19:13:47] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 78.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.4  loss: 39.4  time: 0.3594  data_time: 0.0247  lr: 0.00065451  max_mem: 3221M
[07/06 19:13:47] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 54.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.35  loss: 27.35  time: 0.3587  data_time: 0.0207  lr: 9.5492e-05  max_mem: 3221M
[07/06 19:13:48] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 42.32  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 21.16  loss: 21.16  time: 0.3579  data_time: 0.0182  lr: 0.00090451  max_mem: 3221M
[07/06 19:13:49] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 54.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.35  loss: 27.35  time: 0.3577  data_time: 0.0162  lr: 0.00034549  max_mem: 3221M
[07/06 19:13:50] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 54.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.35  loss: 27.35  time: 0.3572  data_time: 0.0147  lr: 0.001  max_mem: 3221M
[07/06 19:13:50] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 54.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.35  loss: 27.35  time: 0.3570  data_time: 0.0136  lr: 0.00065451  max_mem: 3221M
[07/06 19:14:38] cvalgorithms INFO: Start inference on 216 batches
[07/06 19:15:50] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 19:15:50] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 19:16:19] cvalgorithms INFO: Starting training from iteration 0
[07/06 19:16:22] cvalgorithms INFO:  iter: 1  total_loss: 435  decode.loss_seg: 1.78e-07  aux_0.loss: -1.173e-06  cnt.cnt_loss: 217.5  loss: 217.5  data_time: 0.0502  lr: 0.00090451  max_mem: 3221M
[07/06 19:16:23] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 241.8  decode.loss_seg: 0  aux_0.loss: -3.339e-07  cnt.cnt_loss: 120.9  loss: 120.9  time: 0.3566  data_time: 0.0276  lr: 0.00034549  max_mem: 3221M
[07/06 19:16:24] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 100.7  decode.loss_seg: 0  aux_0.loss: -1.153e-07  cnt.cnt_loss: 50.35  loss: 50.35  time: 0.3579  data_time: 0.0200  lr: 0.001  max_mem: 3221M
[07/06 19:16:24] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 82.43  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.21  loss: 41.21  time: 0.3570  data_time: 0.0162  lr: 0.00065451  max_mem: 3221M
[07/06 19:16:25] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 69.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.6  loss: 34.6  time: 0.3564  data_time: 0.0139  lr: 9.5492e-05  max_mem: 3221M
[07/06 19:16:26] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 69.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.6  loss: 34.6  time: 0.3561  data_time: 0.0122  lr: 0.00090451  max_mem: 3221M
[07/06 19:16:27] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 65.46  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.73  loss: 32.73  time: 0.3559  data_time: 0.0111  lr: 0.00034549  max_mem: 3221M
[07/06 19:16:27] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 69.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.6  loss: 34.6  time: 0.3558  data_time: 0.0103  lr: 0.001  max_mem: 3221M
[07/06 19:16:28] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 66.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.05  loss: 33.05  time: 0.3563  data_time: 0.0097  lr: 0.00065451  max_mem: 3221M
[07/06 19:16:36] cvalgorithms INFO: Start inference on 216 batches
[07/06 19:16:49] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 88, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 209, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluator)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 66, in inference_on_dataset
    evaluator.reset()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 37, in reset
    evaluator.reset()
TypeError: reset() missing 1 required positional argument: 'self'
[07/06 19:16:49] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 65.46  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.73  loss: 32.73  time: 0.3563  data_time: 0.0091  lr: 9.5492e-05  max_mem: 3221M
[07/06 19:17:25] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 19:17:25] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 19:17:54] cvalgorithms INFO: Starting training from iteration 0
[07/06 19:17:58] cvalgorithms INFO:  iter: 1  total_loss: 144.8  decode.loss_seg: -4.354e-07  aux_0.loss: 0  cnt.cnt_loss: 72.42  loss: 72.42  data_time: 0.0766  lr: 0.00090451  max_mem: 3221M
[07/06 19:17:58] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 144.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.42  loss: 72.42  time: 0.3556  data_time: 0.0405  lr: 0.00034549  max_mem: 3221M
[07/06 19:17:59] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 144.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.42  loss: 72.42  time: 0.3559  data_time: 0.0285  lr: 0.001  max_mem: 3221M
[07/06 19:18:00] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 144.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.42  loss: 72.42  time: 0.3559  data_time: 0.0225  lr: 0.00065451  max_mem: 3221M
[07/06 19:18:00] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 189.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 94.63  loss: 94.63  time: 0.3563  data_time: 0.0188  lr: 9.5492e-05  max_mem: 3221M
[07/06 19:18:01] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 168.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 84.36  loss: 84.36  time: 0.3586  data_time: 0.0164  lr: 0.00090451  max_mem: 3221M
[07/06 19:18:02] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 153.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.56  loss: 76.56  time: 0.3587  data_time: 0.0148  lr: 0.00034549  max_mem: 3221M
[07/06 19:18:03] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 168.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 84.36  loss: 84.36  time: 0.3585  data_time: 0.0134  lr: 0.001  max_mem: 3221M
[07/06 19:18:03] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 153.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.56  loss: 76.56  time: 0.3586  data_time: 0.0125  lr: 0.00065451  max_mem: 3221M
[07/06 19:18:04] cvalgorithms INFO: Start inference on 216 batches
[07/07 10:29:43] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 10:29:43] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 10:30:10] cvalgorithms INFO: Starting training from iteration 0
[07/07 10:30:14] cvalgorithms INFO:  iter: 1  total_loss: 148.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 74.14  loss: 74.14  data_time: 0.0634  lr: 0.00090451  max_mem: 3221M
[07/07 10:30:14] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 198.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 99.47  loss: 99.47  time: 0.3499  data_time: 0.0339  lr: 0.00034549  max_mem: 3221M
[07/07 10:30:15] cvalgorithms INFO:  eta: 0:00:32  iter: 5  total_loss: 172.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 86.26  loss: 86.26  time: 0.3500  data_time: 0.0240  lr: 0.001  max_mem: 3221M
[07/07 10:30:16] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 129.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 64.84  loss: 64.84  time: 0.3506  data_time: 0.0192  lr: 0.00065451  max_mem: 3221M
[07/07 10:30:17] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 125.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 62.93  loss: 62.93  time: 0.3514  data_time: 0.0163  lr: 9.5492e-05  max_mem: 3221M
[07/07 10:30:17] cvalgorithms INFO:  eta: 0:00:30  iter: 11  total_loss: 125.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 62.93  loss: 62.93  time: 0.3516  data_time: 0.0144  lr: 0.00090451  max_mem: 3221M
[07/07 10:30:18] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 122  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 61.02  loss: 61.02  time: 0.3516  data_time: 0.0129  lr: 0.00034549  max_mem: 3221M
[07/07 10:30:19] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 105.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 52.81  loss: 52.81  time: 0.3517  data_time: 0.0119  lr: 0.001  max_mem: 3221M
[07/07 10:30:19] cvalgorithms INFO:  eta: 0:00:28  iter: 17  total_loss: 97.95  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 48.98  loss: 48.98  time: 0.3519  data_time: 0.0111  lr: 0.00065451  max_mem: 3221M
[07/07 10:31:39] cvalgorithms INFO: Start inference on 216 batches
[07/07 10:38:21] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 88, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 209, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluator)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 75, in inference_on_dataset
    stack.enter_context(inference_context(model))
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\contextlib.py", line 330, in enter_context
    result = _cm_type.__enter__(cm)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\contextlib.py", line 81, in __enter__
    return next(self.gen)
TypeError: 'NoneType' object is not an iterator
[07/07 10:38:21] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 76.91  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 38.46  loss: 38.46  time: 0.3519  data_time: 0.0104  lr: 9.5492e-05  max_mem: 3221M
[07/07 10:59:12] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 10:59:12] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 10:59:40] cvalgorithms INFO: Starting training from iteration 0
[07/07 10:59:44] cvalgorithms INFO:  iter: 1  total_loss: 428.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 214.3  loss: 214.3  data_time: 0.0356  lr: 0.00090451  max_mem: 3221M
[07/07 10:59:45] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 230.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 115.4  loss: 115.4  time: 0.3623  data_time: 0.0245  lr: 0.00034549  max_mem: 3221M
[07/07 10:59:46] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 244.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 122.4  loss: 122.4  time: 0.3588  data_time: 0.0180  lr: 0.001  max_mem: 3221M
[07/07 10:59:46] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 228.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 114.4  loss: 114.4  time: 0.3580  data_time: 0.0147  lr: 0.00065451  max_mem: 3221M
[07/07 10:59:47] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 214.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 107.4  loss: 107.4  time: 0.3568  data_time: 0.0126  lr: 9.5492e-05  max_mem: 3221M
[07/07 10:59:48] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 214.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 107.4  loss: 107.4  time: 0.3564  data_time: 0.0113  lr: 0.00090451  max_mem: 3221M
[07/07 10:59:49] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 155  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 77.48  loss: 77.48  time: 0.3563  data_time: 0.0103  lr: 0.00034549  max_mem: 3221M
[07/07 10:59:49] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 78.23  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.12  loss: 39.12  time: 0.3567  data_time: 0.0096  lr: 0.001  max_mem: 3221M
[07/07 10:59:50] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 54.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.07  loss: 27.07  time: 0.3571  data_time: 0.0091  lr: 0.00065451  max_mem: 3221M
[07/07 10:59:53] cvalgorithms INFO: Start inference on 216 batches
[07/07 11:09:20] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 11:09:20] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 11:09:50] cvalgorithms INFO: Starting training from iteration 0
[07/07 11:09:54] cvalgorithms INFO:  iter: 1  total_loss: 343  decode.loss_seg: 0.00135  aux_0.loss: 3.162e-06  cnt.cnt_loss: 171.5  loss: 171.5  data_time: 0.0704  lr: 0.00090451  max_mem: 3221M
[07/07 11:09:55] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 272.2  decode.loss_seg: 0  aux_0.loss: 1.089e-06  cnt.cnt_loss: 136.1  loss: 136.1  time: 0.3539  data_time: 0.0375  lr: 0.00034549  max_mem: 3221M
[07/07 11:09:56] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 224.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 112.1  loss: 112.1  time: 0.3555  data_time: 0.0265  lr: 0.001  max_mem: 3221M
[07/07 11:09:56] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 224.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 112.1  loss: 112.1  time: 0.3558  data_time: 0.0210  lr: 0.00065451  max_mem: 3221M
[07/07 11:09:57] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 146  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 73.02  loss: 73.02  time: 0.3560  data_time: 0.0177  lr: 9.5492e-05  max_mem: 3221M
[07/07 11:09:58] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 88.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 44.07  loss: 44.07  time: 0.3563  data_time: 0.0155  lr: 0.00090451  max_mem: 3221M
[07/07 11:09:58] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 75.46  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.73  loss: 37.73  time: 0.3561  data_time: 0.0139  lr: 0.00034549  max_mem: 3221M
[07/07 11:09:59] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 63.39  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 31.69  loss: 31.69  time: 0.3564  data_time: 0.0128  lr: 0.001  max_mem: 3221M
[07/07 11:10:00] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 49.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 24.95  loss: 24.95  time: 0.3573  data_time: 0.0119  lr: 0.00065451  max_mem: 3221M
[07/07 11:10:11] cvalgorithms INFO: Start inference on 216 batches
[07/07 11:14:52] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 11:14:52] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 11:15:21] cvalgorithms INFO: Starting training from iteration 0
[07/07 11:26:49] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 11:26:49] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 11:27:18] cvalgorithms INFO: Starting training from iteration 0
[07/07 11:27:22] cvalgorithms INFO:  iter: 1  total_loss: 371.6  decode.loss_seg: -0.0009106  aux_0.loss: 1.193e-06  cnt.cnt_loss: 185.8  loss: 185.8  data_time: 0.0482  lr: 0.00090451  max_mem: 3221M
[07/07 11:27:23] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 255.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 127.9  loss: 127.9  time: 0.3588  data_time: 0.0266  lr: 0.00034549  max_mem: 3221M
[07/07 11:27:24] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 159.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 79.84  loss: 79.84  time: 0.3588  data_time: 0.0193  lr: 0.001  max_mem: 3221M
[07/07 11:27:24] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 159.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 79.84  loss: 79.84  time: 0.3580  data_time: 0.0156  lr: 0.00065451  max_mem: 3221M
[07/07 11:27:25] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 122.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 61.26  loss: 61.26  time: 0.3589  data_time: 0.0134  lr: 9.5492e-05  max_mem: 3221M
[07/07 11:27:26] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 100.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.14  loss: 50.14  time: 0.3597  data_time: 0.0121  lr: 0.00090451  max_mem: 3221M
[07/07 11:27:26] cvalgorithms INFO:  eta: 0:00:31  iter: 13  total_loss: 79.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.8  loss: 39.8  time: 0.3597  data_time: 0.0111  lr: 0.00034549  max_mem: 3221M
[07/07 11:27:27] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 69.08  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.54  loss: 34.54  time: 0.3593  data_time: 0.0104  lr: 0.001  max_mem: 3221M
[07/07 11:27:28] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 67.79  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.89  loss: 33.89  time: 0.3588  data_time: 0.0097  lr: 0.00065451  max_mem: 3221M
[07/07 11:27:29] cvalgorithms INFO: Start inference on 216 batches
[07/07 11:32:22] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 11:32:22] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 11:32:52] cvalgorithms INFO: Starting training from iteration 0
[07/07 12:11:25] cvalgorithms INFO:  iter: 1  total_loss: 150.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 75.15  loss: 75.15  data_time: 1154.7110  lr: 0.00090451  max_mem: 3221M
[07/07 12:11:26] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 125.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 62.93  loss: 62.93  time: 0.3499  data_time: 577.3578  lr: 0.00034549  max_mem: 3221M
[07/07 12:11:27] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 92.85  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 46.42  loss: 46.42  time: 0.3524  data_time: 384.9067  lr: 0.001  max_mem: 3221M
[07/07 12:11:27] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 70.32  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.16  loss: 35.16  time: 0.3515  data_time: 288.6811  lr: 0.00065451  max_mem: 3221M
[07/07 12:11:28] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 70.32  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.16  loss: 35.16  time: 0.3520  data_time: 230.9458  lr: 9.5492e-05  max_mem: 3221M
[07/07 12:11:29] cvalgorithms INFO:  eta: 0:00:30  iter: 11  total_loss: 58.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 29.42  loss: 29.42  time: 0.3517  data_time: 192.4556  lr: 0.00090451  max_mem: 3221M
[07/07 12:11:30] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 47.55  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.78  loss: 23.78  time: 0.3519  data_time: 164.9625  lr: 0.00034549  max_mem: 3221M
[07/07 12:11:30] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 45.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 22.87  loss: 22.87  time: 0.3530  data_time: 144.3428  lr: 0.001  max_mem: 3221M
[07/07 12:11:31] cvalgorithms INFO:  eta: 0:00:28  iter: 17  total_loss: 35.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.6  loss: 17.6  time: 0.3542  data_time: 128.3053  lr: 0.00065451  max_mem: 3221M
[07/07 12:11:32] cvalgorithms INFO: Start inference on 216 batches
[07/07 12:28:35] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 12:28:35] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 12:29:03] cvalgorithms INFO: Starting training from iteration 0
[07/07 12:29:03] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 123, in train
    self.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 127, in run_step
    self._trainer.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 211, in run_step
    loss_dict = self.model(_img, ground_truth=_ground_truth, return_metrics=True)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 305, in forward
    metrics = self.forward_train(inputs, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 211, in forward_train
    x = self.extract_feat(inputs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 55, in extract_feat
    inputs_n, inputs_g = torch.chunk(inputs, 2, dim=1)
ValueError: not enough values to unpack (expected 2, got 1)
[07/07 12:29:03] cvalgorithms INFO:  iter: 0    lr: N/A  max_mem: 145M
[07/07 12:34:24] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 12:34:24] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 12:34:54] cvalgorithms INFO: Starting training from iteration 0
[07/07 12:37:14] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 12:37:14] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 12:37:43] cvalgorithms INFO: Starting training from iteration 0
[07/07 13:13:10] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 123, in train
    self.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 127, in run_step
    self._trainer.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 211, in run_step
    loss_dict = self.model(_img, ground_truth=_ground_truth, return_metrics=True)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 305, in forward
    metrics = self.forward_train(inputs, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 213, in forward_train
    loss_decode = self._decode_head_forward_train(x, ground_truth)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 106, in _decode_head_forward_train
    loss_decode = self.decode_head.forward_train(x, ground_truth)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\decode_heads\decode_head.py", line 197, in forward_train
    losses = self.losses(seg_logits, gt_semantic_seg)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\decode_heads\decode_head.py", line 231, in losses
    align_corners=self.align_corners)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\utils\warpper.py", line 28, in resize
    return F.interpolate(input, size, scale_factor, mode, align_corners)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\functional.py", line 3476, in interpolate
    "size shape must match input shape. " "Input is {}D, size is {}".format(dim, len(size))
ValueError: size shape must match input shape. Input is 2D, size is 1
[07/07 13:13:10] cvalgorithms INFO:  iter: 0    lr: N/A  max_mem: 3199M
[07/07 13:16:38] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 13:16:38] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 13:17:06] cvalgorithms INFO: Starting training from iteration 0
[07/07 13:19:27] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 13:19:27] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 13:19:56] cvalgorithms INFO: Starting training from iteration 0
[07/07 13:21:35] cvalgorithms INFO:  iter: 1  total_loss: 397.7  decode.loss_seg: 0.0003795  aux_0.loss: -9.253e-07  cnt.cnt_loss: 198.9  loss: 198.9  data_time: 45.8626  lr: 0.00090451  max_mem: 3221M
[07/07 13:21:35] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 199.3  decode.loss_seg: 8.243e-05  aux_0.loss: -5.912e-07  cnt.cnt_loss: 99.67  loss: 99.67  time: 0.3642  data_time: 22.9340  lr: 0.00034549  max_mem: 3221M
[07/07 13:21:36] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 148.9  decode.loss_seg: 0  aux_0.loss: -3.361e-08  cnt.cnt_loss: 74.47  loss: 74.47  time: 0.3613  data_time: 15.2910  lr: 0.001  max_mem: 3221M
[07/07 13:21:37] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 148.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 74.47  loss: 74.47  time: 0.3598  data_time: 11.4694  lr: 0.00065451  max_mem: 3221M
[07/07 13:21:37] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 160.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 80.2  loss: 80.2  time: 0.3586  data_time: 9.1765  lr: 9.5492e-05  max_mem: 3221M
[07/07 13:21:38] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 112.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 56.39  loss: 56.39  time: 0.3612  data_time: 7.6478  lr: 0.00090451  max_mem: 3221M
[07/07 13:21:39] cvalgorithms INFO:  eta: 0:00:31  iter: 13  total_loss: 97.19  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 48.6  loss: 48.6  time: 0.3618  data_time: 6.5562  lr: 0.00034549  max_mem: 3221M
[07/07 13:21:40] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 78.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.37  loss: 39.37  time: 0.3607  data_time: 5.7373  lr: 0.001  max_mem: 3221M
[07/07 13:21:40] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 68.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.25  loss: 34.25  time: 0.3599  data_time: 5.1003  lr: 0.00065451  max_mem: 3221M
[07/07 13:21:41] cvalgorithms INFO: Start inference on 216 batches
[07/07 13:22:09] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 88, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 165, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluator)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 89, in inference_on_dataset
    _img, _ground_truth = inputs['image'], inputs['ground_truth']
TypeError: list indices must be integers or slices, not str
[07/07 13:22:09] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 56.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.37  loss: 28.37  time: 0.3594  data_time: 4.5907  lr: 9.5492e-05  max_mem: 3221M
[07/07 13:23:02] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 13:23:02] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 13:23:32] cvalgorithms INFO: Starting training from iteration 0
[07/07 13:23:35] cvalgorithms INFO:  iter: 1  total_loss: 476.6  decode.loss_seg: -1.915e-07  aux_0.loss: 0  cnt.cnt_loss: 238.3  loss: 238.3  data_time: 0.0289  lr: 0.00090451  max_mem: 3221M
[07/07 13:23:36] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 202.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 101.1  loss: 101.1  time: 0.3589  data_time: 0.0166  lr: 0.00034549  max_mem: 3221M
[07/07 13:23:37] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 115.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 57.79  loss: 57.79  time: 0.3574  data_time: 0.0126  lr: 0.001  max_mem: 3221M
[07/07 13:23:37] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 115.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 57.79  loss: 57.79  time: 0.3601  data_time: 0.0105  lr: 0.00065451  max_mem: 3221M
[07/07 13:23:38] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 115.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 57.79  loss: 57.79  time: 0.3596  data_time: 0.0093  lr: 9.5492e-05  max_mem: 3221M
[07/07 13:23:39] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 62.08  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 31.04  loss: 31.04  time: 0.3594  data_time: 0.0085  lr: 0.00090451  max_mem: 3221M
[07/07 13:23:40] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 62.08  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 31.04  loss: 31.04  time: 0.3587  data_time: 0.0079  lr: 0.00034549  max_mem: 3221M
[07/07 13:23:40] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 48.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 24.37  loss: 24.37  time: 0.3588  data_time: 0.0075  lr: 0.001  max_mem: 3221M
[07/07 13:23:41] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 58.77  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 29.39  loss: 29.39  time: 0.3587  data_time: 0.0072  lr: 0.00065451  max_mem: 3221M
[07/07 13:23:42] cvalgorithms INFO: Start inference on 216 batches
[07/07 13:29:04] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 13:29:04] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 13:29:32] cvalgorithms INFO: Starting training from iteration 0
[07/07 13:29:36] cvalgorithms INFO:  iter: 1  total_loss: 273.8  decode.loss_seg: 0.0007726  aux_0.loss: 2.656e-05  cnt.cnt_loss: 136.9  loss: 136.9  data_time: 0.0638  lr: 0.00090451  max_mem: 3221M
[07/07 13:29:36] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 273.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 136.9  loss: 136.9  time: 0.3525  data_time: 0.0340  lr: 0.00034549  max_mem: 3221M
[07/07 13:29:37] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 202.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 101.2  loss: 101.2  time: 0.3520  data_time: 0.0242  lr: 0.001  max_mem: 3221M
[07/07 13:29:38] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 154  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.99  loss: 76.99  time: 0.3527  data_time: 0.0192  lr: 0.00065451  max_mem: 3221M
[07/07 13:29:38] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 151.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 75.6  loss: 75.6  time: 0.3536  data_time: 0.0162  lr: 9.5492e-05  max_mem: 3221M
[07/07 13:29:39] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 144.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.4  loss: 72.4  time: 0.3537  data_time: 0.0143  lr: 0.00090451  max_mem: 3221M
[07/07 13:29:40] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 128.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 64.11  loss: 64.11  time: 0.3541  data_time: 0.0128  lr: 0.00034549  max_mem: 3221M
[07/07 13:29:41] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 108.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 54.27  loss: 54.27  time: 0.3544  data_time: 0.0118  lr: 0.001  max_mem: 3221M
[07/07 13:29:41] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 90.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 45.37  loss: 45.37  time: 0.3559  data_time: 0.0110  lr: 0.00065451  max_mem: 3221M
[07/07 13:29:42] cvalgorithms INFO: Start inference on 216 batches
[07/07 13:30:10] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 88, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 165, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluator)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 95, in inference_on_dataset
    for key, value in _ground_truth.items():
KeyError: 'ground_truth'
[07/07 13:30:10] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 71.48  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.74  loss: 35.74  time: 0.3574  data_time: 0.0104  lr: 9.5492e-05  max_mem: 3221M
[07/07 13:31:01] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 13:31:01] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 13:31:30] cvalgorithms INFO: Starting training from iteration 0
[07/07 13:31:34] cvalgorithms INFO:  iter: 1  total_loss: 362.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 181.4  loss: 181.4  data_time: 0.0244  lr: 0.00090451  max_mem: 3221M
[07/07 13:31:35] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 320.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 160.3  loss: 160.3  time: 0.3587  data_time: 0.0143  lr: 0.00034549  max_mem: 3221M
[07/07 13:31:35] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 231.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 115.7  loss: 115.7  time: 0.3574  data_time: 0.0109  lr: 0.001  max_mem: 3221M
[07/07 13:31:36] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 144  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.02  loss: 72.02  time: 0.3577  data_time: 0.0092  lr: 0.00065451  max_mem: 3221M
[07/07 13:31:37] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 103  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 51.51  loss: 51.51  time: 0.3577  data_time: 0.0082  lr: 9.5492e-05  max_mem: 3221M
[07/07 13:31:37] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 88.19  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 44.09  loss: 44.09  time: 0.3584  data_time: 0.0075  lr: 0.00090451  max_mem: 3221M
[07/07 13:31:38] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 72.19  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 36.1  loss: 36.1  time: 0.3588  data_time: 0.0072  lr: 0.00034549  max_mem: 3221M
[07/07 13:31:39] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 53.89  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 26.95  loss: 26.95  time: 0.3587  data_time: 0.0068  lr: 0.001  max_mem: 3221M
[07/07 13:31:40] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 50.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 25.4  loss: 25.4  time: 0.3588  data_time: 0.0066  lr: 0.00065451  max_mem: 3221M
[07/07 13:31:40] cvalgorithms INFO: Start inference on 216 batches
[07/07 13:32:10] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 88, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 165, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluator)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 95, in inference_on_dataset
    for key, value in _ground_truth.items():
KeyError: 'ground_truth'
[07/07 13:32:10] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 50.23  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 25.12  loss: 25.12  time: 0.3584  data_time: 0.0063  lr: 9.5492e-05  max_mem: 3221M
[07/07 13:33:16] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 13:33:16] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 13:33:48] cvalgorithms INFO: Starting training from iteration 0
[07/07 13:33:52] cvalgorithms INFO:  iter: 1  total_loss: 303.9  decode.loss_seg: -0.0003229  aux_0.loss: -7.727e-07  cnt.cnt_loss: 152  loss: 152  data_time: 0.0679  lr: 0.00090451  max_mem: 3221M
[07/07 13:33:53] cvalgorithms INFO:  eta: 0:00:35  iter: 3  total_loss: 240  decode.loss_seg: -9.638e-05  aux_0.loss: -7.548e-07  cnt.cnt_loss: 120  loss: 120  time: 0.3670  data_time: 0.0367  lr: 0.00034549  max_mem: 3221M
[07/07 13:33:54] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 179.2  decode.loss_seg: 0  aux_0.loss: -1.128e-07  cnt.cnt_loss: 89.6  loss: 89.6  time: 0.3653  data_time: 0.0260  lr: 0.001  max_mem: 3221M
[07/07 13:33:55] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 240  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 120  loss: 120  time: 0.3678  data_time: 0.0210  lr: 0.00065451  max_mem: 3221M
[07/07 13:33:55] cvalgorithms INFO:  eta: 0:00:33  iter: 9  total_loss: 179.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 89.6  loss: 89.6  time: 0.3694  data_time: 0.0178  lr: 9.5492e-05  max_mem: 3221M
[07/07 13:33:56] cvalgorithms INFO:  eta: 0:00:32  iter: 11  total_loss: 137  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 68.51  loss: 68.51  time: 0.3712  data_time: 0.0158  lr: 0.00090451  max_mem: 3221M
[07/07 13:33:57] cvalgorithms INFO:  eta: 0:00:32  iter: 13  total_loss: 128.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 64.33  loss: 64.33  time: 0.3775  data_time: 0.0143  lr: 0.00034549  max_mem: 3221M
[07/07 13:33:58] cvalgorithms INFO:  eta: 0:00:31  iter: 15  total_loss: 112.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 56.11  loss: 56.11  time: 0.3811  data_time: 0.0133  lr: 0.001  max_mem: 3221M
[07/07 13:33:59] cvalgorithms INFO:  eta: 0:00:30  iter: 17  total_loss: 88.31  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 44.15  loss: 44.15  time: 0.3842  data_time: 0.0123  lr: 0.00065451  max_mem: 3221M
[07/07 13:33:59] cvalgorithms INFO: Start inference on 216 batches
[07/07 13:36:54] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 13:36:54] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 13:37:23] cvalgorithms INFO: Starting training from iteration 0
[07/07 13:37:27] cvalgorithms INFO:  iter: 1  total_loss: 125.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 62.81  loss: 62.81  data_time: 0.0782  lr: 0.00090451  max_mem: 3221M
[07/07 13:37:28] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 148.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 74.21  loss: 74.21  time: 0.3555  data_time: 0.0414  lr: 0.00034549  max_mem: 3221M
[07/07 13:37:28] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 75.09  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.55  loss: 37.55  time: 0.3555  data_time: 0.0290  lr: 0.001  max_mem: 3221M
[07/07 13:37:29] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 75.09  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.55  loss: 37.55  time: 0.3568  data_time: 0.0229  lr: 0.00065451  max_mem: 3221M
[07/07 13:37:30] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 75.09  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.55  loss: 37.55  time: 0.3571  data_time: 0.0192  lr: 9.5492e-05  max_mem: 3221M
[07/07 13:37:31] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 56.89  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.45  loss: 28.45  time: 0.3569  data_time: 0.0168  lr: 0.00090451  max_mem: 3221M
[07/07 13:37:31] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 46.47  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.23  loss: 23.23  time: 0.3585  data_time: 0.0151  lr: 0.00034549  max_mem: 3221M
[07/07 13:37:32] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 41.99  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 21  loss: 21  time: 0.3589  data_time: 0.0138  lr: 0.001  max_mem: 3221M
[07/07 13:37:33] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 39.16  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 19.58  loss: 19.58  time: 0.3590  data_time: 0.0128  lr: 0.00065451  max_mem: 3221M
[07/07 13:37:34] cvalgorithms INFO: Start inference on 216 batches
[07/07 14:07:59] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 14:07:59] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 14:08:27] cvalgorithms INFO: Starting training from iteration 0
[07/07 14:08:31] cvalgorithms INFO:  iter: 1  total_loss: 273.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 136.9  loss: 136.9  data_time: 0.0481  lr: 0.00090451  max_mem: 3221M
[07/07 14:08:32] cvalgorithms INFO:  eta: 0:00:35  iter: 3  total_loss: 128.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 64.11  loss: 64.11  time: 0.3675  data_time: 0.0264  lr: 0.00034549  max_mem: 3221M
[07/07 14:08:33] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 101.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.68  loss: 50.68  time: 0.3641  data_time: 0.0191  lr: 0.001  max_mem: 3221M
[07/07 14:08:33] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 78.88  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.44  loss: 39.44  time: 0.3608  data_time: 0.0154  lr: 0.00065451  max_mem: 3221M
[07/07 14:08:34] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 78.88  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.44  loss: 39.44  time: 0.3593  data_time: 0.0132  lr: 9.5492e-05  max_mem: 3221M
[07/07 14:08:35] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 80.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 40.37  loss: 40.37  time: 0.3587  data_time: 0.0117  lr: 0.00090451  max_mem: 3221M
[07/07 14:08:35] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 78.88  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.44  loss: 39.44  time: 0.3587  data_time: 0.0106  lr: 0.00034549  max_mem: 3221M
[07/07 14:08:36] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 69.73  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.86  loss: 34.86  time: 0.3590  data_time: 0.0098  lr: 0.001  max_mem: 3221M
[07/07 14:08:37] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 58.27  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 29.14  loss: 29.14  time: 0.3586  data_time: 0.0092  lr: 0.00065451  max_mem: 3221M
[07/07 14:08:38] cvalgorithms INFO: Start inference on 216 batches
[07/07 14:10:15] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 14:10:15] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 14:10:45] cvalgorithms INFO: Starting training from iteration 0
[07/07 14:10:48] cvalgorithms INFO:  iter: 1  total_loss: 46.51  decode.loss_seg: -0.002695  aux_0.loss: 1.465e-05  cnt.cnt_loss: 23.26  loss: 23.26  data_time: 0.0487  lr: 0.00090451  max_mem: 3221M
[07/07 14:10:49] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 96.61  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 48.31  loss: 48.3  time: 0.3595  data_time: 0.0266  lr: 0.00034549  max_mem: 3221M
[07/07 14:10:50] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 66.82  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.41  loss: 33.41  time: 0.3574  data_time: 0.0191  lr: 0.001  max_mem: 3221M
[07/07 14:10:51] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 67.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.57  loss: 33.57  time: 0.3577  data_time: 0.0154  lr: 0.00065451  max_mem: 3221M
[07/07 14:10:51] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 61.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 30.92  loss: 30.92  time: 0.3579  data_time: 0.0132  lr: 9.5492e-05  max_mem: 3221M
[07/07 14:10:52] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 61.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 30.92  loss: 30.92  time: 0.3611  data_time: 0.0118  lr: 0.00090451  max_mem: 3221M
[07/07 14:10:53] cvalgorithms INFO:  eta: 0:00:31  iter: 13  total_loss: 48.49  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 24.25  loss: 24.25  time: 0.3610  data_time: 0.0108  lr: 0.00034549  max_mem: 3221M
[07/07 14:10:54] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 33.67  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.84  loss: 16.84  time: 0.3611  data_time: 0.0100  lr: 0.001  max_mem: 3221M
[07/07 14:10:54] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 33.67  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.84  loss: 16.84  time: 0.3610  data_time: 0.0094  lr: 0.00065451  max_mem: 3221M
[07/07 14:10:55] cvalgorithms INFO: Start inference on 216 batches
[07/07 14:17:35] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 14:17:35] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 14:18:03] cvalgorithms INFO: Starting training from iteration 0
[07/07 14:18:07] cvalgorithms INFO:  iter: 1  total_loss: 128.4  decode.loss_seg: -2.106e-07  aux_0.loss: 0  cnt.cnt_loss: 64.21  loss: 64.21  data_time: 0.0522  lr: 0.00090451  max_mem: 3221M
[07/07 14:18:07] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 86.64  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.32  loss: 43.32  time: 0.3571  data_time: 0.0283  lr: 0.00034549  max_mem: 3221M
[07/07 14:18:08] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 83.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.87  loss: 41.87  time: 0.3554  data_time: 0.0204  lr: 0.001  max_mem: 3221M
[07/07 14:18:09] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 86.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.35  loss: 43.35  time: 0.3564  data_time: 0.0164  lr: 0.00065451  max_mem: 3221M
[07/07 14:18:10] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 86.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.35  loss: 43.35  time: 0.3572  data_time: 0.0139  lr: 9.5492e-05  max_mem: 3221M
[07/07 14:18:10] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 56.76  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.38  loss: 28.38  time: 0.3573  data_time: 0.0123  lr: 0.00090451  max_mem: 3221M
[07/07 14:18:11] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 51.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 25.75  loss: 25.75  time: 0.3571  data_time: 0.0112  lr: 0.00034549  max_mem: 3221M
[07/07 14:18:12] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 56.76  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.38  loss: 28.38  time: 0.3589  data_time: 0.0104  lr: 0.001  max_mem: 3221M
[07/07 14:18:12] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 51.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 25.75  loss: 25.75  time: 0.3589  data_time: 0.0098  lr: 0.00065451  max_mem: 3221M
[07/07 14:18:13] cvalgorithms INFO: Start inference on 216 batches
[07/07 14:38:02] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 14:38:02] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 14:38:29] cvalgorithms INFO: Starting training from iteration 0
[07/07 14:38:33] cvalgorithms INFO:  iter: 1  total_loss: 308.6  decode.loss_seg: 0.0005881  aux_0.loss: 4.011e-05  cnt.cnt_loss: 154.3  loss: 154.3  data_time: 0.0393  lr: 0.00090451  max_mem: 3221M
[07/07 14:38:34] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 143.6  decode.loss_seg: 0  aux_0.loss: -1.17e-06  cnt.cnt_loss: 71.8  loss: 71.8  time: 0.3545  data_time: 0.0220  lr: 0.00034549  max_mem: 3221M
[07/07 14:38:35] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 160.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 80.17  loss: 80.17  time: 0.3529  data_time: 0.0161  lr: 0.001  max_mem: 3221M
[07/07 14:38:35] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 136.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 68.24  loss: 68.24  time: 0.3549  data_time: 0.0132  lr: 0.00065451  max_mem: 3221M
[07/07 14:38:36] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 126.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 63.32  loss: 63.32  time: 0.3552  data_time: 0.0115  lr: 9.5492e-05  max_mem: 3221M
[07/07 14:38:37] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 111.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 55.64  loss: 55.64  time: 0.3562  data_time: 0.0103  lr: 0.00090451  max_mem: 3221M
[07/07 14:38:38] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 100.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.39  loss: 50.39  time: 0.3571  data_time: 0.0095  lr: 0.00034549  max_mem: 3221M
[07/07 14:38:38] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 84.03  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 42.02  loss: 42.02  time: 0.3574  data_time: 0.0089  lr: 0.001  max_mem: 3221M
[07/07 14:38:39] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 67.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.55  loss: 33.55  time: 0.3573  data_time: 0.0084  lr: 0.00065451  max_mem: 3221M
[07/07 14:38:40] cvalgorithms INFO: Start inference on 216 batches
[07/07 15:28:35] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 15:28:35] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 15:29:02] cvalgorithms INFO: Starting training from iteration 0
[07/07 15:29:07] cvalgorithms INFO:  iter: 1  total_loss: 31.46  decode.loss_seg: -8.698e-06  aux_0.loss: 1.266e-05  cnt.cnt_loss: 15.73  loss: 15.73  data_time: 0.0235  lr: 0.00090451  max_mem: 3221M
[07/07 15:29:07] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 63.19  decode.loss_seg: -8.698e-06  aux_0.loss: 0  cnt.cnt_loss: 31.6  loss: 31.6  time: 0.3584  data_time: 0.0140  lr: 0.00034549  max_mem: 3221M
[07/07 15:29:08] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 61.48  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 30.74  loss: 30.74  time: 0.3582  data_time: 0.0109  lr: 0.001  max_mem: 3221M
[07/07 15:29:09] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 82.01  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.01  loss: 41.01  time: 0.3583  data_time: 0.0094  lr: 0.00065451  max_mem: 3221M
[07/07 15:29:09] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 77.29  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 38.64  loss: 38.64  time: 0.3569  data_time: 0.0085  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:29:10] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 63.77  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 31.88  loss: 31.88  time: 0.3563  data_time: 0.0079  lr: 0.00090451  max_mem: 3221M
[07/07 15:29:11] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 63.87  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 31.94  loss: 31.94  time: 0.3559  data_time: 0.0073  lr: 0.00034549  max_mem: 3221M
[07/07 15:29:12] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 60.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 30.05  loss: 30.05  time: 0.3561  data_time: 0.0069  lr: 0.001  max_mem: 3221M
[07/07 15:29:12] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 56.23  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.11  loss: 28.11  time: 0.3565  data_time: 0.0066  lr: 0.00065451  max_mem: 3221M
[07/07 15:29:13] cvalgorithms INFO: Start inference on 216 batches
[07/07 15:29:42] cvalgorithms INFO: Inference done 11/216. Dataloading: 0.0008 s/iter. Inference: 0.0520 s/iter. Eval: 0.0005 s/iter. Total: 0.0534 s/iter. ETA=0:00:10
[07/07 15:29:42] cvalgorithms INFO: Inference done 12/216. Dataloading: 0.0008 s/iter. Inference: 0.0520 s/iter. Eval: 0.0005 s/iter. Total: 0.0535 s/iter. ETA=0:00:10
[07/07 15:29:42] cvalgorithms INFO: Inference done 13/216. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0005 s/iter. Total: 0.0536 s/iter. ETA=0:00:10
[07/07 15:29:42] cvalgorithms INFO: Inference done 14/216. Dataloading: 0.0009 s/iter. Inference: 0.0521 s/iter. Eval: 0.0005 s/iter. Total: 0.0536 s/iter. ETA=0:00:10
[07/07 15:29:42] cvalgorithms INFO: Inference done 15/216. Dataloading: 0.0009 s/iter. Inference: 0.0521 s/iter. Eval: 0.0005 s/iter. Total: 0.0537 s/iter. ETA=0:00:10
[07/07 15:29:42] cvalgorithms INFO: Inference done 16/216. Dataloading: 0.0009 s/iter. Inference: 0.0524 s/iter. Eval: 0.0006 s/iter. Total: 0.0540 s/iter. ETA=0:00:10
[07/07 15:29:42] cvalgorithms INFO: Inference done 17/216. Dataloading: 0.0009 s/iter. Inference: 0.0526 s/iter. Eval: 0.0006 s/iter. Total: 0.0543 s/iter. ETA=0:00:10
[07/07 15:29:42] cvalgorithms INFO: Inference done 18/216. Dataloading: 0.0010 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:10
[07/07 15:29:42] cvalgorithms INFO: Inference done 19/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 20/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 21/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 22/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 23/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 24/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 25/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 26/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 27/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 28/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 29/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0551 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 30/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 31/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 32/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 33/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 34/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 35/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 36/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:09
[07/07 15:29:43] cvalgorithms INFO: Inference done 37/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0555 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 38/216. Dataloading: 0.0011 s/iter. Inference: 0.0535 s/iter. Eval: 0.0006 s/iter. Total: 0.0556 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 39/216. Dataloading: 0.0011 s/iter. Inference: 0.0535 s/iter. Eval: 0.0006 s/iter. Total: 0.0556 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 40/216. Dataloading: 0.0011 s/iter. Inference: 0.0535 s/iter. Eval: 0.0006 s/iter. Total: 0.0556 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 41/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0555 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 42/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0555 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 43/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0555 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 44/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 45/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 46/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 47/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 48/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 49/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 50/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 51/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 52/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 53/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:08
[07/07 15:29:44] cvalgorithms INFO: Inference done 54/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:08
[07/07 15:29:44] cvalgorithms INFO: Inference done 55/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0551 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 56/216. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0551 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 57/216. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0551 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 58/216. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0551 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 59/216. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 60/216. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 61/216. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 62/216. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 63/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 64/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 65/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 66/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 67/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 68/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 69/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 70/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 71/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:07
[07/07 15:29:45] cvalgorithms INFO: Inference done 72/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:07
[07/07 15:29:45] cvalgorithms INFO: Inference done 73/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:07
[07/07 15:29:45] cvalgorithms INFO: Inference done 74/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 75/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 76/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 77/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 78/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 79/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 80/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 81/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 82/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 83/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 84/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 85/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 86/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 87/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 88/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 89/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:06
[07/07 15:29:46] cvalgorithms INFO: Inference done 90/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:06
[07/07 15:29:46] cvalgorithms INFO: Inference done 91/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:06
[07/07 15:29:46] cvalgorithms INFO: Inference done 92/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 93/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 94/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 95/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 96/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 97/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 98/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 99/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 100/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 101/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 102/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 103/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 104/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 105/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 106/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 107/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:47] cvalgorithms INFO: Inference done 108/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:47] cvalgorithms INFO: Inference done 109/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:47] cvalgorithms INFO: Inference done 110/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 111/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 112/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 113/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 114/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 115/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 116/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 117/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 118/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 119/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 120/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 121/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 122/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 123/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 124/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 125/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:04
[07/07 15:29:48] cvalgorithms INFO: Inference done 126/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:04
[07/07 15:29:48] cvalgorithms INFO: Inference done 127/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:04
[07/07 15:29:48] cvalgorithms INFO: Inference done 128/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 129/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 130/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 131/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 132/216. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0551 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 133/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 134/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 135/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 136/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 137/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 138/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 139/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 140/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 141/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 142/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 143/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 144/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:03
[07/07 15:29:49] cvalgorithms INFO: Inference done 145/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 146/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 147/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 148/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 149/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 150/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 151/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 152/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 153/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 154/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 155/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 156/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 157/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 158/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 159/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 160/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 161/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 162/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:50] cvalgorithms INFO: Inference done 163/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:50] cvalgorithms INFO: Inference done 164/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 165/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 166/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 167/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 168/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 169/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 170/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 171/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 172/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 173/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 174/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 175/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 176/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 177/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 178/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 179/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 180/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:51] cvalgorithms INFO: Inference done 181/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:51] cvalgorithms INFO: Inference done 182/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 183/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 184/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 185/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 186/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 187/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 188/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 189/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 190/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 191/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 192/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 193/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 194/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 195/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 196/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 197/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 198/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:52] cvalgorithms INFO: Inference done 199/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:52] cvalgorithms INFO: Inference done 200/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 201/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 202/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 203/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 204/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 205/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 206/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 207/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 208/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 209/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 210/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 211/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 212/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 213/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 214/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 215/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 216/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:54] cvalgorithms INFO: Total inference time: 0:00:12.333969 (0.058455 s / iter per device, on 1 devices)
[07/07 15:29:54] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.053119 s / iter per device, on 1 devices)
[07/07 15:32:29] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 15:32:29] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 15:33:01] cvalgorithms INFO: Starting training from iteration 0
[07/07 15:33:04] cvalgorithms INFO:  iter: 1  total_loss: 85.46  decode.loss_seg: 0.000409  aux_0.loss: 2.792e-07  cnt.cnt_loss: 42.73  loss: 42.73  data_time: 0.0620  lr: 0.00090451  max_mem: 3221M
[07/07 15:33:05] cvalgorithms INFO:  eta: 0:00:37  iter: 3  total_loss: 133.2  decode.loss_seg: 0  aux_0.loss: 2.792e-07  cnt.cnt_loss: 66.6  loss: 66.6  time: 0.3900  data_time: 0.0340  lr: 0.00034549  max_mem: 3221M
[07/07 15:33:06] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 88.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 44.05  loss: 44.05  time: 0.3749  data_time: 0.0243  lr: 0.001  max_mem: 3221M
[07/07 15:33:06] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 83.89  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.94  loss: 41.94  time: 0.3694  data_time: 0.0194  lr: 0.00065451  max_mem: 3221M
[07/07 15:33:07] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 60.18  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 30.09  loss: 30.09  time: 0.3668  data_time: 0.0165  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:33:08] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 57.69  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.85  loss: 28.85  time: 0.3648  data_time: 0.0145  lr: 0.00090451  max_mem: 3221M
[07/07 15:33:09] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 55.05  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.52  loss: 27.52  time: 0.3632  data_time: 0.0130  lr: 0.00034549  max_mem: 3221M
[07/07 15:33:09] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 52.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 26.37  loss: 26.37  time: 0.3629  data_time: 0.0119  lr: 0.001  max_mem: 3221M
[07/07 15:33:10] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 46.58  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.29  loss: 23.29  time: 0.3624  data_time: 0.0111  lr: 0.00065451  max_mem: 3221M
[07/07 15:33:11] cvalgorithms INFO: Start inference on 216 batches
[07/07 15:33:42] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 88, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 165, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluator)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 108, in inference_on_dataset
    log_every_n_seconds(
NameError: name 'log_every_n_seconds' is not defined
[07/07 15:33:42] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 40.71  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 20.35  loss: 20.35  time: 0.3622  data_time: 0.0105  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:35:49] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 15:35:49] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 15:36:19] cvalgorithms INFO: Starting training from iteration 0
[07/07 15:36:23] cvalgorithms INFO:  iter: 1  total_loss: 246.9  decode.loss_seg: 2.834e-07  aux_0.loss: -4.866e-07  cnt.cnt_loss: 123.4  loss: 123.4  data_time: 0.0471  lr: 0.00090451  max_mem: 3221M
[07/07 15:36:24] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 172.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 86.08  loss: 86.08  time: 0.3592  data_time: 0.0258  lr: 0.00034549  max_mem: 3221M
[07/07 15:36:24] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 152.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.32  loss: 76.32  time: 0.3587  data_time: 0.0188  lr: 0.001  max_mem: 3221M
[07/07 15:36:25] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 152.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.32  loss: 76.32  time: 0.3580  data_time: 0.0152  lr: 0.00065451  max_mem: 3221M
[07/07 15:36:26] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 152.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.32  loss: 76.32  time: 0.3577  data_time: 0.0131  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:36:26] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 152.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.32  loss: 76.32  time: 0.3576  data_time: 0.0117  lr: 0.00090451  max_mem: 3221M
[07/07 15:36:27] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 123.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 61.95  loss: 61.95  time: 0.3577  data_time: 0.0106  lr: 0.00034549  max_mem: 3221M
[07/07 15:36:28] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 105.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 52.86  loss: 52.86  time: 0.3576  data_time: 0.0098  lr: 0.001  max_mem: 3221M
[07/07 15:36:29] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 97.79  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 48.9  loss: 48.9  time: 0.3578  data_time: 0.0092  lr: 0.00065451  max_mem: 3221M
[07/07 15:36:29] cvalgorithms INFO: Start inference on 216 batches
[07/07 15:37:16] cvalgorithms INFO: Total inference time: 0:00:12.742644 (0.060392 s / iter per device, on 1 devices)
[07/07 15:37:16] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056372 s / iter per device, on 1 devices)
[07/07 15:37:16] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 84.68  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 42.34  loss: 42.34  time: 0.3581  data_time: 0.0087  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:37:17] cvalgorithms INFO:  eta: 0:00:27  iter: 21  total_loss: 66.66  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.33  loss: 33.33  time: 0.3624  data_time: 0.0058  lr: 0.00090451  max_mem: 3221M
[07/07 15:37:18] cvalgorithms INFO:  eta: 0:00:27  iter: 23  total_loss: 59.18  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 29.59  loss: 29.59  time: 0.3661  data_time: 0.0072  lr: 0.00034549  max_mem: 3221M
[07/07 15:37:18] cvalgorithms INFO:  eta: 0:00:26  iter: 25  total_loss: 52.77  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 26.39  loss: 26.39  time: 0.3685  data_time: 0.0072  lr: 0.001  max_mem: 3221M
[07/07 15:37:19] cvalgorithms INFO:  eta: 0:00:25  iter: 27  total_loss: 39.03  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 19.52  loss: 19.52  time: 0.3693  data_time: 0.0072  lr: 0.00065451  max_mem: 3221M
[07/07 15:37:20] cvalgorithms INFO:  eta: 0:00:25  iter: 29  total_loss: 27.48  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 13.74  loss: 13.74  time: 0.3713  data_time: 0.0072  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:37:21] cvalgorithms INFO:  eta: 0:00:24  iter: 31  total_loss: 21.17  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 10.59  loss: 10.59  time: 0.3727  data_time: 0.0073  lr: 0.00090451  max_mem: 3221M
[07/07 15:37:22] cvalgorithms INFO:  eta: 0:00:23  iter: 33  total_loss: 20.36  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 10.18  loss: 10.18  time: 0.3736  data_time: 0.0074  lr: 0.00034549  max_mem: 3221M
[07/07 15:37:22] cvalgorithms INFO:  eta: 0:00:23  iter: 35  total_loss: 20.16  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 10.08  loss: 10.08  time: 0.3748  data_time: 0.0074  lr: 0.001  max_mem: 3221M
[07/07 15:37:23] cvalgorithms INFO:  eta: 0:00:22  iter: 37  total_loss: 18.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 9.4  loss: 9.4  time: 0.3758  data_time: 0.0075  lr: 0.00065451  max_mem: 3221M
[07/07 15:37:24] cvalgorithms INFO: Start inference on 216 batches
[07/07 15:38:09] cvalgorithms INFO: Total inference time: 0:00:13.058978 (0.061891 s / iter per device, on 1 devices)
[07/07 15:38:09] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.057039 s / iter per device, on 1 devices)
[07/07 15:38:09] cvalgorithms INFO:  eta: 0:00:22  iter: 39  total_loss: 17.29  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 8.646  loss: 8.646  time: 0.3765  data_time: 0.0075  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:38:10] cvalgorithms INFO:  eta: 0:00:22  iter: 41  total_loss: 14.12  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.062  loss: 7.062  time: 0.3787  data_time: 0.0077  lr: 0.00090451  max_mem: 3221M
[07/07 15:38:11] cvalgorithms INFO:  eta: 0:00:21  iter: 43  total_loss: 11.52  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.759  loss: 5.759  time: 0.3796  data_time: 0.0068  lr: 0.00034549  max_mem: 3221M
[07/07 15:38:12] cvalgorithms INFO:  eta: 0:00:20  iter: 45  total_loss: 10.19  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.094  loss: 5.094  time: 0.3803  data_time: 0.0069  lr: 0.001  max_mem: 3221M
[07/07 15:38:12] cvalgorithms INFO:  eta: 0:00:20  iter: 47  total_loss: 8.721  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.36  loss: 4.36  time: 0.3808  data_time: 0.0069  lr: 0.00065451  max_mem: 3221M
[07/07 15:38:13] cvalgorithms INFO:  eta: 0:00:19  iter: 49  total_loss: 7.03  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.515  loss: 3.515  time: 0.3813  data_time: 0.0069  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:38:14] cvalgorithms INFO:  eta: 0:00:18  iter: 51  total_loss: 5.926  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.963  loss: 2.963  time: 0.3823  data_time: 0.0070  lr: 0.00090451  max_mem: 3221M
[07/07 15:38:15] cvalgorithms INFO:  eta: 0:00:17  iter: 53  total_loss: 5.322  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.661  loss: 2.661  time: 0.3833  data_time: 0.0070  lr: 0.00034549  max_mem: 3221M
[07/07 15:38:16] cvalgorithms INFO:  eta: 0:00:17  iter: 55  total_loss: 5.096  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.548  loss: 2.548  time: 0.3838  data_time: 0.0070  lr: 0.001  max_mem: 3221M
[07/07 15:38:16] cvalgorithms INFO:  eta: 0:00:16  iter: 57  total_loss: 4.199  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.099  loss: 2.099  time: 0.3842  data_time: 0.0070  lr: 0.00065451  max_mem: 3221M
[07/07 15:38:17] cvalgorithms INFO: Start inference on 216 batches
[07/07 15:39:05] cvalgorithms INFO: Total inference time: 0:00:13.431921 (0.063658 s / iter per device, on 1 devices)
[07/07 15:39:05] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.057582 s / iter per device, on 1 devices)
[07/07 15:42:22] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 15:42:22] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 15:42:53] cvalgorithms INFO: Starting training from iteration 0
[07/07 15:42:57] cvalgorithms INFO:  iter: 1  total_loss: 402.4  decode.loss_seg: 0.001992  aux_0.loss: 4.28e-08  cnt.cnt_loss: 201.2  loss: 201.2  data_time: 0.0547  lr: 0.00090451  max_mem: 3221M
[07/07 15:42:58] cvalgorithms INFO:  eta: 0:00:36  iter: 3  total_loss: 281.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 140.8  loss: 140.8  time: 0.3838  data_time: 0.0299  lr: 0.00034549  max_mem: 3221M
[07/07 15:42:59] cvalgorithms INFO:  eta: 0:00:35  iter: 5  total_loss: 192.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 96.05  loss: 96.05  time: 0.3781  data_time: 0.0216  lr: 0.001  max_mem: 3221M
[07/07 15:43:00] cvalgorithms INFO:  eta: 0:00:35  iter: 7  total_loss: 144.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.1  loss: 72.1  time: 0.3805  data_time: 0.0176  lr: 0.00065451  max_mem: 3221M
[07/07 15:43:00] cvalgorithms INFO:  eta: 0:00:34  iter: 9  total_loss: 115.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 57.58  loss: 57.58  time: 0.3810  data_time: 0.0154  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:43:01] cvalgorithms INFO:  eta: 0:00:33  iter: 11  total_loss: 103.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 51.97  loss: 51.97  time: 0.3813  data_time: 0.0138  lr: 0.00090451  max_mem: 3221M
[07/07 15:43:02] cvalgorithms INFO:  eta: 0:00:32  iter: 13  total_loss: 87.89  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.94  loss: 43.94  time: 0.3822  data_time: 0.0126  lr: 0.00034549  max_mem: 3221M
[07/07 15:43:03] cvalgorithms INFO:  eta: 0:00:32  iter: 15  total_loss: 72.47  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 36.24  loss: 36.24  time: 0.3810  data_time: 0.0117  lr: 0.001  max_mem: 3221M
[07/07 15:43:03] cvalgorithms INFO:  eta: 0:00:31  iter: 17  total_loss: 72.47  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 36.24  loss: 36.24  time: 0.3827  data_time: 0.0110  lr: 0.00065451  max_mem: 3221M
[07/07 15:43:04] cvalgorithms INFO: Start inference on 216 batches
[07/07 15:43:37] cvalgorithms INFO: Inference done 11/216. Dataloading: 0.0010 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:11
[07/07 15:43:37] cvalgorithms INFO: Inference done 12/216. Dataloading: 0.0010 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:11
[07/07 15:43:37] cvalgorithms INFO: Inference done 13/216. Dataloading: 0.0010 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:11
[07/07 15:43:37] cvalgorithms INFO: Inference done 14/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:11
[07/07 15:43:37] cvalgorithms INFO: Inference done 15/216. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:11
[07/07 15:43:37] cvalgorithms INFO: Inference done 16/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0551 s/iter. ETA=0:00:11
[07/07 15:43:37] cvalgorithms INFO: Inference done 17/216. Dataloading: 0.0011 s/iter. Inference: 0.0535 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:11
[07/07 15:43:37] cvalgorithms INFO: Inference done 18/216. Dataloading: 0.0011 s/iter. Inference: 0.0536 s/iter. Eval: 0.0006 s/iter. Total: 0.0555 s/iter. ETA=0:00:10
[07/07 15:43:37] cvalgorithms INFO: Inference done 19/216. Dataloading: 0.0011 s/iter. Inference: 0.0537 s/iter. Eval: 0.0006 s/iter. Total: 0.0556 s/iter. ETA=0:00:10
[07/07 15:43:37] cvalgorithms INFO: Inference done 20/216. Dataloading: 0.0011 s/iter. Inference: 0.0538 s/iter. Eval: 0.0006 s/iter. Total: 0.0557 s/iter. ETA=0:00:10
[07/07 15:43:37] cvalgorithms INFO: Inference done 21/216. Dataloading: 0.0011 s/iter. Inference: 0.0538 s/iter. Eval: 0.0006 s/iter. Total: 0.0558 s/iter. ETA=0:00:10
[07/07 15:43:37] cvalgorithms INFO: Inference done 22/216. Dataloading: 0.0011 s/iter. Inference: 0.0539 s/iter. Eval: 0.0006 s/iter. Total: 0.0558 s/iter. ETA=0:00:10
[07/07 15:43:37] cvalgorithms INFO: Inference done 23/216. Dataloading: 0.0011 s/iter. Inference: 0.0540 s/iter. Eval: 0.0006 s/iter. Total: 0.0560 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 24/216. Dataloading: 0.0011 s/iter. Inference: 0.0541 s/iter. Eval: 0.0006 s/iter. Total: 0.0560 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 25/216. Dataloading: 0.0011 s/iter. Inference: 0.0542 s/iter. Eval: 0.0006 s/iter. Total: 0.0561 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 26/216. Dataloading: 0.0011 s/iter. Inference: 0.0542 s/iter. Eval: 0.0006 s/iter. Total: 0.0561 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 27/216. Dataloading: 0.0011 s/iter. Inference: 0.0542 s/iter. Eval: 0.0006 s/iter. Total: 0.0562 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 28/216. Dataloading: 0.0011 s/iter. Inference: 0.0542 s/iter. Eval: 0.0006 s/iter. Total: 0.0562 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 29/216. Dataloading: 0.0011 s/iter. Inference: 0.0543 s/iter. Eval: 0.0006 s/iter. Total: 0.0563 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 30/216. Dataloading: 0.0011 s/iter. Inference: 0.0543 s/iter. Eval: 0.0006 s/iter. Total: 0.0563 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 31/216. Dataloading: 0.0011 s/iter. Inference: 0.0543 s/iter. Eval: 0.0006 s/iter. Total: 0.0563 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 32/216. Dataloading: 0.0011 s/iter. Inference: 0.0543 s/iter. Eval: 0.0006 s/iter. Total: 0.0563 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 33/216. Dataloading: 0.0011 s/iter. Inference: 0.0544 s/iter. Eval: 0.0006 s/iter. Total: 0.0564 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 34/216. Dataloading: 0.0011 s/iter. Inference: 0.0544 s/iter. Eval: 0.0006 s/iter. Total: 0.0564 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 35/216. Dataloading: 0.0011 s/iter. Inference: 0.0544 s/iter. Eval: 0.0006 s/iter. Total: 0.0564 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 36/216. Dataloading: 0.0011 s/iter. Inference: 0.0545 s/iter. Eval: 0.0006 s/iter. Total: 0.0564 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 37/216. Dataloading: 0.0011 s/iter. Inference: 0.0545 s/iter. Eval: 0.0006 s/iter. Total: 0.0565 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 38/216. Dataloading: 0.0011 s/iter. Inference: 0.0545 s/iter. Eval: 0.0006 s/iter. Total: 0.0565 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 39/216. Dataloading: 0.0011 s/iter. Inference: 0.0545 s/iter. Eval: 0.0006 s/iter. Total: 0.0565 s/iter. ETA=0:00:09
[07/07 15:43:38] cvalgorithms INFO: Inference done 40/216. Dataloading: 0.0011 s/iter. Inference: 0.0546 s/iter. Eval: 0.0006 s/iter. Total: 0.0565 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 41/216. Dataloading: 0.0011 s/iter. Inference: 0.0546 s/iter. Eval: 0.0006 s/iter. Total: 0.0566 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 42/216. Dataloading: 0.0011 s/iter. Inference: 0.0547 s/iter. Eval: 0.0006 s/iter. Total: 0.0567 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 43/216. Dataloading: 0.0011 s/iter. Inference: 0.0547 s/iter. Eval: 0.0006 s/iter. Total: 0.0567 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 44/216. Dataloading: 0.0011 s/iter. Inference: 0.0548 s/iter. Eval: 0.0006 s/iter. Total: 0.0569 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 45/216. Dataloading: 0.0011 s/iter. Inference: 0.0549 s/iter. Eval: 0.0006 s/iter. Total: 0.0569 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 46/216. Dataloading: 0.0011 s/iter. Inference: 0.0549 s/iter. Eval: 0.0006 s/iter. Total: 0.0570 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 47/216. Dataloading: 0.0011 s/iter. Inference: 0.0550 s/iter. Eval: 0.0006 s/iter. Total: 0.0570 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 48/216. Dataloading: 0.0011 s/iter. Inference: 0.0550 s/iter. Eval: 0.0006 s/iter. Total: 0.0571 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 49/216. Dataloading: 0.0011 s/iter. Inference: 0.0551 s/iter. Eval: 0.0006 s/iter. Total: 0.0571 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 50/216. Dataloading: 0.0011 s/iter. Inference: 0.0551 s/iter. Eval: 0.0006 s/iter. Total: 0.0571 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 51/216. Dataloading: 0.0011 s/iter. Inference: 0.0551 s/iter. Eval: 0.0006 s/iter. Total: 0.0571 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 52/216. Dataloading: 0.0011 s/iter. Inference: 0.0552 s/iter. Eval: 0.0006 s/iter. Total: 0.0572 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 53/216. Dataloading: 0.0011 s/iter. Inference: 0.0552 s/iter. Eval: 0.0006 s/iter. Total: 0.0573 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 54/216. Dataloading: 0.0011 s/iter. Inference: 0.0552 s/iter. Eval: 0.0006 s/iter. Total: 0.0573 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 55/216. Dataloading: 0.0011 s/iter. Inference: 0.0553 s/iter. Eval: 0.0006 s/iter. Total: 0.0573 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 56/216. Dataloading: 0.0011 s/iter. Inference: 0.0553 s/iter. Eval: 0.0006 s/iter. Total: 0.0573 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 57/216. Dataloading: 0.0011 s/iter. Inference: 0.0553 s/iter. Eval: 0.0006 s/iter. Total: 0.0574 s/iter. ETA=0:00:09
[07/07 15:43:40] cvalgorithms INFO: Inference done 58/216. Dataloading: 0.0011 s/iter. Inference: 0.0554 s/iter. Eval: 0.0006 s/iter. Total: 0.0574 s/iter. ETA=0:00:09
[07/07 15:43:40] cvalgorithms INFO: Inference done 59/216. Dataloading: 0.0011 s/iter. Inference: 0.0554 s/iter. Eval: 0.0006 s/iter. Total: 0.0574 s/iter. ETA=0:00:09
[07/07 15:43:40] cvalgorithms INFO: Inference done 60/216. Dataloading: 0.0011 s/iter. Inference: 0.0554 s/iter. Eval: 0.0006 s/iter. Total: 0.0575 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 61/216. Dataloading: 0.0011 s/iter. Inference: 0.0555 s/iter. Eval: 0.0006 s/iter. Total: 0.0575 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 62/216. Dataloading: 0.0011 s/iter. Inference: 0.0555 s/iter. Eval: 0.0006 s/iter. Total: 0.0576 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 63/216. Dataloading: 0.0011 s/iter. Inference: 0.0556 s/iter. Eval: 0.0006 s/iter. Total: 0.0577 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 64/216. Dataloading: 0.0011 s/iter. Inference: 0.0556 s/iter. Eval: 0.0006 s/iter. Total: 0.0577 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 65/216. Dataloading: 0.0011 s/iter. Inference: 0.0556 s/iter. Eval: 0.0006 s/iter. Total: 0.0577 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 66/216. Dataloading: 0.0011 s/iter. Inference: 0.0557 s/iter. Eval: 0.0006 s/iter. Total: 0.0577 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 67/216. Dataloading: 0.0011 s/iter. Inference: 0.0557 s/iter. Eval: 0.0006 s/iter. Total: 0.0578 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 68/216. Dataloading: 0.0011 s/iter. Inference: 0.0557 s/iter. Eval: 0.0006 s/iter. Total: 0.0578 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 69/216. Dataloading: 0.0011 s/iter. Inference: 0.0557 s/iter. Eval: 0.0006 s/iter. Total: 0.0578 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 70/216. Dataloading: 0.0011 s/iter. Inference: 0.0558 s/iter. Eval: 0.0006 s/iter. Total: 0.0578 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 71/216. Dataloading: 0.0011 s/iter. Inference: 0.0558 s/iter. Eval: 0.0006 s/iter. Total: 0.0579 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 72/216. Dataloading: 0.0011 s/iter. Inference: 0.0558 s/iter. Eval: 0.0006 s/iter. Total: 0.0579 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 73/216. Dataloading: 0.0011 s/iter. Inference: 0.0558 s/iter. Eval: 0.0006 s/iter. Total: 0.0579 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 74/216. Dataloading: 0.0011 s/iter. Inference: 0.0559 s/iter. Eval: 0.0006 s/iter. Total: 0.0579 s/iter. ETA=0:00:08
[07/07 15:43:41] cvalgorithms INFO: Inference done 75/216. Dataloading: 0.0011 s/iter. Inference: 0.0559 s/iter. Eval: 0.0006 s/iter. Total: 0.0579 s/iter. ETA=0:00:08
[07/07 15:43:41] cvalgorithms INFO: Inference done 76/216. Dataloading: 0.0011 s/iter. Inference: 0.0559 s/iter. Eval: 0.0006 s/iter. Total: 0.0580 s/iter. ETA=0:00:08
[07/07 15:43:41] cvalgorithms INFO: Inference done 77/216. Dataloading: 0.0011 s/iter. Inference: 0.0559 s/iter. Eval: 0.0006 s/iter. Total: 0.0580 s/iter. ETA=0:00:08
[07/07 15:43:41] cvalgorithms INFO: Inference done 78/216. Dataloading: 0.0011 s/iter. Inference: 0.0559 s/iter. Eval: 0.0006 s/iter. Total: 0.0580 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 79/216. Dataloading: 0.0011 s/iter. Inference: 0.0559 s/iter. Eval: 0.0006 s/iter. Total: 0.0580 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 80/216. Dataloading: 0.0011 s/iter. Inference: 0.0559 s/iter. Eval: 0.0006 s/iter. Total: 0.0580 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 81/216. Dataloading: 0.0011 s/iter. Inference: 0.0559 s/iter. Eval: 0.0006 s/iter. Total: 0.0580 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 82/216. Dataloading: 0.0011 s/iter. Inference: 0.0559 s/iter. Eval: 0.0006 s/iter. Total: 0.0580 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 83/216. Dataloading: 0.0011 s/iter. Inference: 0.0560 s/iter. Eval: 0.0006 s/iter. Total: 0.0581 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 84/216. Dataloading: 0.0011 s/iter. Inference: 0.0560 s/iter. Eval: 0.0006 s/iter. Total: 0.0581 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 85/216. Dataloading: 0.0011 s/iter. Inference: 0.0560 s/iter. Eval: 0.0006 s/iter. Total: 0.0581 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 86/216. Dataloading: 0.0011 s/iter. Inference: 0.0560 s/iter. Eval: 0.0006 s/iter. Total: 0.0581 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 87/216. Dataloading: 0.0011 s/iter. Inference: 0.0560 s/iter. Eval: 0.0006 s/iter. Total: 0.0581 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 88/216. Dataloading: 0.0011 s/iter. Inference: 0.0560 s/iter. Eval: 0.0006 s/iter. Total: 0.0581 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 89/216. Dataloading: 0.0011 s/iter. Inference: 0.0561 s/iter. Eval: 0.0006 s/iter. Total: 0.0582 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 90/216. Dataloading: 0.0011 s/iter. Inference: 0.0561 s/iter. Eval: 0.0006 s/iter. Total: 0.0582 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 91/216. Dataloading: 0.0011 s/iter. Inference: 0.0561 s/iter. Eval: 0.0006 s/iter. Total: 0.0582 s/iter. ETA=0:00:07
[07/07 15:43:42] cvalgorithms INFO: Inference done 92/216. Dataloading: 0.0011 s/iter. Inference: 0.0561 s/iter. Eval: 0.0006 s/iter. Total: 0.0582 s/iter. ETA=0:00:07
[07/07 15:43:42] cvalgorithms INFO: Inference done 93/216. Dataloading: 0.0011 s/iter. Inference: 0.0561 s/iter. Eval: 0.0006 s/iter. Total: 0.0582 s/iter. ETA=0:00:07
[07/07 15:43:42] cvalgorithms INFO: Inference done 94/216. Dataloading: 0.0011 s/iter. Inference: 0.0561 s/iter. Eval: 0.0006 s/iter. Total: 0.0582 s/iter. ETA=0:00:07
[07/07 15:43:42] cvalgorithms INFO: Inference done 95/216. Dataloading: 0.0011 s/iter. Inference: 0.0562 s/iter. Eval: 0.0006 s/iter. Total: 0.0582 s/iter. ETA=0:00:07
[07/07 15:43:42] cvalgorithms INFO: Inference done 96/216. Dataloading: 0.0011 s/iter. Inference: 0.0562 s/iter. Eval: 0.0006 s/iter. Total: 0.0582 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 97/216. Dataloading: 0.0011 s/iter. Inference: 0.0562 s/iter. Eval: 0.0006 s/iter. Total: 0.0583 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 98/216. Dataloading: 0.0011 s/iter. Inference: 0.0562 s/iter. Eval: 0.0006 s/iter. Total: 0.0583 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 99/216. Dataloading: 0.0011 s/iter. Inference: 0.0562 s/iter. Eval: 0.0006 s/iter. Total: 0.0583 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 100/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0583 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 101/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 102/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 103/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 104/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 105/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 106/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 107/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 108/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:43] cvalgorithms INFO: Inference done 109/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:43] cvalgorithms INFO: Inference done 110/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:43] cvalgorithms INFO: Inference done 111/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0585 s/iter. ETA=0:00:06
[07/07 15:43:43] cvalgorithms INFO: Inference done 112/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0585 s/iter. ETA=0:00:06
[07/07 15:43:43] cvalgorithms INFO: Inference done 113/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0585 s/iter. ETA=0:00:06
[07/07 15:43:43] cvalgorithms INFO: Inference done 114/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0585 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 115/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0585 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 116/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0585 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 117/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0585 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 118/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0585 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 119/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0585 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 120/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0586 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 121/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0586 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 122/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0586 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 123/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0586 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 124/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0586 s/iter. ETA=0:00:05
[07/07 15:43:44] cvalgorithms INFO: Inference done 125/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0586 s/iter. ETA=0:00:05
[07/07 15:43:44] cvalgorithms INFO: Inference done 126/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0586 s/iter. ETA=0:00:05
[07/07 15:43:44] cvalgorithms INFO: Inference done 127/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0587 s/iter. ETA=0:00:05
[07/07 15:43:44] cvalgorithms INFO: Inference done 128/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0587 s/iter. ETA=0:00:05
[07/07 15:43:44] cvalgorithms INFO: Inference done 129/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0587 s/iter. ETA=0:00:05
[07/07 15:43:44] cvalgorithms INFO: Inference done 130/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0587 s/iter. ETA=0:00:05
[07/07 15:43:44] cvalgorithms INFO: Inference done 131/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0587 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 132/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0587 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 133/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 134/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 135/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 136/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 137/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 138/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 139/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 140/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 141/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:45] cvalgorithms INFO: Inference done 142/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:45] cvalgorithms INFO: Inference done 143/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:45] cvalgorithms INFO: Inference done 144/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:45] cvalgorithms INFO: Inference done 145/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:45] cvalgorithms INFO: Inference done 146/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:45] cvalgorithms INFO: Inference done 147/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:45] cvalgorithms INFO: Inference done 148/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 149/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 150/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 151/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 152/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 153/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 154/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 155/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 156/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 157/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 158/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:46] cvalgorithms INFO: Inference done 159/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:46] cvalgorithms INFO: Inference done 160/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:46] cvalgorithms INFO: Inference done 161/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:46] cvalgorithms INFO: Inference done 162/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:46] cvalgorithms INFO: Inference done 163/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:46] cvalgorithms INFO: Inference done 164/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:46] cvalgorithms INFO: Inference done 165/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:46] cvalgorithms INFO: Inference done 166/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:02
[07/07 15:43:46] cvalgorithms INFO: Inference done 167/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:46] cvalgorithms INFO: Inference done 168/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:46] cvalgorithms INFO: Inference done 169/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:46] cvalgorithms INFO: Inference done 170/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:46] cvalgorithms INFO: Inference done 171/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:46] cvalgorithms INFO: Inference done 172/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:46] cvalgorithms INFO: Inference done 173/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:46] cvalgorithms INFO: Inference done 174/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:46] cvalgorithms INFO: Inference done 175/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:47] cvalgorithms INFO: Inference done 176/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:47] cvalgorithms INFO: Inference done 177/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:47] cvalgorithms INFO: Inference done 178/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:47] cvalgorithms INFO: Inference done 179/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:47] cvalgorithms INFO: Inference done 180/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:47] cvalgorithms INFO: Inference done 181/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:47] cvalgorithms INFO: Inference done 182/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:47] cvalgorithms INFO: Inference done 183/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:01
[07/07 15:43:47] cvalgorithms INFO: Inference done 184/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:01
[07/07 15:43:47] cvalgorithms INFO: Inference done 185/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:01
[07/07 15:43:47] cvalgorithms INFO: Inference done 186/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:01
[07/07 15:43:47] cvalgorithms INFO: Inference done 187/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:01
[07/07 15:43:47] cvalgorithms INFO: Inference done 188/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:01
[07/07 15:43:47] cvalgorithms INFO: Inference done 189/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:01
[07/07 15:43:47] cvalgorithms INFO: Inference done 190/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:01
[07/07 15:43:47] cvalgorithms INFO: Inference done 191/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:01
[07/07 15:43:48] cvalgorithms INFO: Inference done 192/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:01
[07/07 15:43:48] cvalgorithms INFO: Inference done 193/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:01
[07/07 15:43:48] cvalgorithms INFO: Inference done 194/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:01
[07/07 15:43:48] cvalgorithms INFO: Inference done 195/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:01
[07/07 15:43:48] cvalgorithms INFO: Inference done 196/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:01
[07/07 15:43:48] cvalgorithms INFO: Inference done 197/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:01
[07/07 15:43:48] cvalgorithms INFO: Inference done 198/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:01
[07/07 15:43:48] cvalgorithms INFO: Inference done 199/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:01
[07/07 15:43:48] cvalgorithms INFO: Inference done 200/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:00
[07/07 15:43:48] cvalgorithms INFO: Inference done 201/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:48] cvalgorithms INFO: Inference done 202/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:48] cvalgorithms INFO: Inference done 203/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:48] cvalgorithms INFO: Inference done 204/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:48] cvalgorithms INFO: Inference done 205/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:48] cvalgorithms INFO: Inference done 206/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:48] cvalgorithms INFO: Inference done 207/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:48] cvalgorithms INFO: Inference done 208/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:49] cvalgorithms INFO: Inference done 209/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:49] cvalgorithms INFO: Inference done 210/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:49] cvalgorithms INFO: Inference done 211/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:49] cvalgorithms INFO: Inference done 212/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:49] cvalgorithms INFO: Inference done 213/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:49] cvalgorithms INFO: Inference done 214/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:49] cvalgorithms INFO: Inference done 215/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:49] cvalgorithms INFO: Inference done 216/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:45:50] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 15:45:51] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 15:46:21] cvalgorithms INFO: Starting training from iteration 0
[07/07 15:46:25] cvalgorithms INFO:  iter: 1  total_loss: 694.2  decode.loss_seg: -0.0005078  aux_0.loss: 3.833e-05  cnt.cnt_loss: 347.1  loss: 347.1  data_time: 0.0474  lr: 0.00090451  max_mem: 3221M
[07/07 15:46:25] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 568.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 284.1  loss: 284.1  time: 0.3594  data_time: 0.0260  lr: 0.00034549  max_mem: 3221M
[07/07 15:46:26] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 504.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 252  loss: 252  time: 0.3617  data_time: 0.0188  lr: 0.001  max_mem: 3221M
[07/07 15:46:27] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 329.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 164.5  loss: 164.5  time: 0.3628  data_time: 0.0154  lr: 0.00065451  max_mem: 3221M
[07/07 15:46:28] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 194.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 97.05  loss: 97.05  time: 0.3634  data_time: 0.0133  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:46:28] cvalgorithms INFO:  eta: 0:00:32  iter: 11  total_loss: 182.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 91.13  loss: 91.13  time: 0.3656  data_time: 0.0119  lr: 0.00090451  max_mem: 3221M
[07/07 15:46:29] cvalgorithms INFO:  eta: 0:00:31  iter: 13  total_loss: 162.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 81.47  loss: 81.47  time: 0.3665  data_time: 0.0109  lr: 0.00034549  max_mem: 3221M
[07/07 15:46:30] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 142.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 71.35  loss: 71.35  time: 0.3667  data_time: 0.0101  lr: 0.001  max_mem: 3221M
[07/07 15:46:31] cvalgorithms INFO:  eta: 0:00:30  iter: 17  total_loss: 116  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 57.98  loss: 57.98  time: 0.3682  data_time: 0.0096  lr: 0.00065451  max_mem: 3221M
[07/07 15:46:31] cvalgorithms INFO: Start inference on 216 batches
[07/07 15:50:19] cvalgorithms INFO: Total inference time: 0:03:15.161025 (0.924934 s / iter per device, on 1 devices)
[07/07 15:50:21] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.057290 s / iter per device, on 1 devices)
[07/07 15:54:43] cvalgorithms INFO:  eta: 0:00:29  iter: 19  total_loss: 87.23  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.61  loss: 43.61  time: 0.3696  data_time: 0.0091  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:54:44] cvalgorithms INFO:  eta: 0:00:28  iter: 21  total_loss: 74.01  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.01  loss: 37.01  time: 0.3766  data_time: 0.0051  lr: 0.00090451  max_mem: 3221M
[07/07 15:54:45] cvalgorithms INFO:  eta: 0:00:27  iter: 23  total_loss: 41.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 20.99  loss: 20.99  time: 0.3751  data_time: 0.0051  lr: 0.00034549  max_mem: 3221M
[07/07 15:54:46] cvalgorithms INFO:  eta: 0:00:27  iter: 25  total_loss: 33.96  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.98  loss: 16.98  time: 0.3736  data_time: 0.0052  lr: 0.001  max_mem: 3221M
[07/07 15:54:47] cvalgorithms INFO:  eta: 0:00:26  iter: 27  total_loss: 33.96  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.98  loss: 16.98  time: 0.3725  data_time: 0.0051  lr: 0.00065451  max_mem: 3221M
[07/07 15:55:14] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 15:55:14] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 15:55:43] cvalgorithms INFO: Starting training from iteration 0
[07/07 15:55:46] cvalgorithms INFO:  iter: 1  total_loss: 395.5  decode.loss_seg: 1.627e-07  aux_0.loss: -2.386e-06  cnt.cnt_loss: 197.7  loss: 197.7  data_time: 0.0430  lr: 0.00090451  max_mem: 3221M
[07/07 15:55:47] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 178.6  decode.loss_seg: 0  aux_0.loss: -3.361e-08  cnt.cnt_loss: 89.31  loss: 89.31  time: 0.3608  data_time: 0.0236  lr: 0.00034549  max_mem: 3221M
[07/07 15:55:48] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 139.3  decode.loss_seg: 0  aux_0.loss: -3.361e-08  cnt.cnt_loss: 69.67  loss: 69.67  time: 0.3583  data_time: 0.0172  lr: 0.001  max_mem: 3221M
[07/07 15:55:49] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 139.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 69.67  loss: 69.67  time: 0.3582  data_time: 0.0139  lr: 0.00065451  max_mem: 3221M
[07/07 15:55:49] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 106.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 53.39  loss: 53.39  time: 0.3579  data_time: 0.0121  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:55:50] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 89.11  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 44.55  loss: 44.55  time: 0.3588  data_time: 0.0109  lr: 0.00090451  max_mem: 3221M
[07/07 15:55:51] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 70.98  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.49  loss: 35.49  time: 0.3584  data_time: 0.0099  lr: 0.00034549  max_mem: 3221M
[07/07 15:55:51] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 70.98  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.49  loss: 35.49  time: 0.3582  data_time: 0.0093  lr: 0.001  max_mem: 3221M
[07/07 15:55:52] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 70.98  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.49  loss: 35.49  time: 0.3582  data_time: 0.0087  lr: 0.00065451  max_mem: 3221M
[07/07 15:55:53] cvalgorithms INFO: Start inference on 216 batches
[07/07 16:17:54] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 16:17:54] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 16:18:22] cvalgorithms INFO: Starting training from iteration 0
[07/07 16:18:26] cvalgorithms INFO:  iter: 1  total_loss: 550.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 275.2  loss: 275.2  data_time: 0.0499  lr: 0.00090451  max_mem: 3221M
[07/07 16:18:26] cvalgorithms INFO:  eta: 0:00:36  iter: 3  total_loss: 335.9  decode.loss_seg: 0  aux_0.loss: -3.49e-07  cnt.cnt_loss: 168  loss: 168  time: 0.3821  data_time: 0.0278  lr: 0.00034549  max_mem: 3221M
[07/07 16:18:27] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 100  decode.loss_seg: 0  aux_0.loss: -3.49e-07  cnt.cnt_loss: 50.02  loss: 50.02  time: 0.3711  data_time: 0.0201  lr: 0.001  max_mem: 3221M
[07/07 16:18:28] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 81.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 40.7  loss: 40.7  time: 0.3657  data_time: 0.0162  lr: 0.00065451  max_mem: 3221M
[07/07 16:18:29] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 78.82  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.41  loss: 39.41  time: 0.3630  data_time: 0.0138  lr: 9.5492e-05  max_mem: 3221M
[07/07 16:18:29] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 78.82  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.41  loss: 39.41  time: 0.3611  data_time: 0.0122  lr: 0.00090451  max_mem: 3221M
[07/07 16:18:30] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 75.08  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.54  loss: 37.54  time: 0.3604  data_time: 0.0111  lr: 0.00034549  max_mem: 3221M
[07/07 16:18:31] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 62.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 31.38  loss: 31.38  time: 0.3595  data_time: 0.0102  lr: 0.001  max_mem: 3221M
[07/07 16:18:31] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 47.16  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.58  loss: 23.58  time: 0.3591  data_time: 0.0096  lr: 0.00065451  max_mem: 3221M
[07/07 16:18:32] cvalgorithms INFO: Start inference on 216 batches
[07/07 17:09:48] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 17:09:48] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 17:10:16] cvalgorithms INFO: Starting training from iteration 0
[07/07 17:10:20] cvalgorithms INFO:  iter: 1  total_loss: 125.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 62.9  loss: 62.9  data_time: 0.0332  lr: 0.00090451  max_mem: 3221M
[07/07 17:10:21] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 39.87  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 19.94  loss: 19.94  time: 0.3540  data_time: 0.0188  lr: 0.00034549  max_mem: 3221M
[07/07 17:10:21] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 68.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.38  loss: 34.38  time: 0.3550  data_time: 0.0140  lr: 0.001  max_mem: 3221M
[07/07 17:10:22] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 101.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.81  loss: 50.81  time: 0.3566  data_time: 0.0117  lr: 0.00065451  max_mem: 3221M
[07/07 17:10:23] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 101.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.81  loss: 50.81  time: 0.3563  data_time: 0.0103  lr: 9.5492e-05  max_mem: 3221M
[07/07 17:10:24] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 68.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.38  loss: 34.38  time: 0.3565  data_time: 0.0093  lr: 0.00090451  max_mem: 3221M
[07/07 17:10:24] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 101.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.81  loss: 50.81  time: 0.3564  data_time: 0.0086  lr: 0.00034549  max_mem: 3221M
[07/07 17:10:25] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 101.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.81  loss: 50.81  time: 0.3562  data_time: 0.0081  lr: 0.001  max_mem: 3221M
[07/07 17:10:26] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 95.49  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 47.74  loss: 47.74  time: 0.3564  data_time: 0.0077  lr: 0.00065451  max_mem: 3221M
[07/07 17:10:26] cvalgorithms INFO: Start inference on 216 batches
[07/07 17:11:09] cvalgorithms INFO: Total inference time: 0:00:12.445983 (0.058986 s / iter per device, on 1 devices)
[07/07 17:11:09] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.053773 s / iter per device, on 1 devices)
[07/07 17:16:43] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 17:16:43] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 17:17:12] cvalgorithms INFO: Starting training from iteration 0
[07/07 17:17:16] cvalgorithms INFO:  iter: 1  total_loss: 281.6  decode.loss_seg: -0.0009238  aux_0.loss: -4.712e-06  cnt.cnt_loss: 140.8  loss: 140.8  data_time: 0.0446  lr: 0.00090451  max_mem: 3221M
[07/07 17:17:17] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 228.3  decode.loss_seg: -2.138e-05  aux_0.loss: -1.839e-06  cnt.cnt_loss: 114.1  loss: 114.1  time: 0.3574  data_time: 0.0247  lr: 0.00034549  max_mem: 3221M
[07/07 17:17:17] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 122.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 61.03  loss: 61.03  time: 0.3556  data_time: 0.0179  lr: 0.001  max_mem: 3221M
[07/07 17:17:18] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 122.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 61.03  loss: 61.03  time: 0.3568  data_time: 0.0144  lr: 0.00065451  max_mem: 3221M
[07/07 17:17:19] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 122.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 61.03  loss: 61.03  time: 0.3578  data_time: 0.0125  lr: 9.5492e-05  max_mem: 3221M
[07/07 17:17:20] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 166.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 83.22  loss: 83.22  time: 0.3579  data_time: 0.0112  lr: 0.00090451  max_mem: 3221M
[07/07 17:17:20] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 122.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 61.03  loss: 61.03  time: 0.3582  data_time: 0.0102  lr: 0.00034549  max_mem: 3221M
[07/07 17:17:21] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 95.28  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 47.64  loss: 47.64  time: 0.3587  data_time: 0.0095  lr: 0.001  max_mem: 3221M
[07/07 17:17:22] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 71.55  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.78  loss: 35.78  time: 0.3585  data_time: 0.0089  lr: 0.00065451  max_mem: 3221M
[07/07 17:17:22] cvalgorithms INFO: Start inference on 216 batches
[07/07 17:18:04] cvalgorithms INFO: Total inference time: 0:00:12.638635 (0.059899 s / iter per device, on 1 devices)
[07/07 17:18:04] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.055145 s / iter per device, on 1 devices)
[07/07 17:22:05] cvalgorithms INFO: Preparing results for LEVIR-CD format ...
[07/14 11:21:56] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/14 11:21:56] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/14 11:22:26] cvalgorithms INFO: Starting training from iteration 0
[07/14 11:22:35] cvalgorithms INFO:  iter: 1  total_loss: 294.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 147.2  loss: 147.2  data_time: 0.0911  lr: 0.00090451  max_mem: 3221M
[07/14 11:22:36] cvalgorithms INFO:  eta: 0:00:39  iter: 3  total_loss: 220.6  decode.loss_seg: 0  aux_0.loss: 9.127e-08  cnt.cnt_loss: 110.3  loss: 110.3  time: 0.4094  data_time: 0.0660  lr: 0.00034549  max_mem: 3221M
[07/14 11:22:37] cvalgorithms INFO:  eta: 0:00:38  iter: 5  total_loss: 175.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 87.95  loss: 87.95  time: 0.4012  data_time: 0.0510  lr: 0.001  max_mem: 3221M
[07/14 11:22:37] cvalgorithms INFO:  eta: 0:00:36  iter: 7  total_loss: 133  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 66.52  loss: 66.52  time: 0.3924  data_time: 0.0395  lr: 0.00065451  max_mem: 3221M
[07/14 11:22:38] cvalgorithms INFO:  eta: 0:00:34  iter: 9  total_loss: 175.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 87.95  loss: 87.95  time: 0.3885  data_time: 0.0325  lr: 9.5492e-05  max_mem: 3221M
[07/14 11:22:39] cvalgorithms INFO:  eta: 0:00:33  iter: 11  total_loss: 133  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 66.52  loss: 66.52  time: 0.3857  data_time: 0.0279  lr: 0.00090451  max_mem: 3221M
[07/14 11:22:40] cvalgorithms INFO:  eta: 0:00:32  iter: 13  total_loss: 95.72  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 47.86  loss: 47.86  time: 0.3850  data_time: 0.0247  lr: 0.00034549  max_mem: 3221M
[07/14 11:22:41] cvalgorithms INFO:  eta: 0:00:31  iter: 15  total_loss: 87.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.55  loss: 43.55  time: 0.3864  data_time: 0.0223  lr: 0.001  max_mem: 3221M
[07/14 11:22:41] cvalgorithms INFO:  eta: 0:00:31  iter: 17  total_loss: 77.89  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 38.94  loss: 38.94  time: 0.3877  data_time: 0.0204  lr: 0.00065451  max_mem: 3221M
[07/14 11:22:42] cvalgorithms INFO: Start inference on 216 batches
[07/14 11:23:31] cvalgorithms INFO: Total inference time: 0:00:13.185775 (0.062492 s / iter per device, on 1 devices)
[07/14 11:23:31] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056625 s / iter per device, on 1 devices)
