[06/27 17:58:19] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[06/27 17:58:19] cvalgorithms INFO: pretrained checkpoint is loaded.
[06/27 17:58:25] cvalgorithms INFO: Starting training from iteration 0
[06/27 17:58:29] cvalgorithms INFO:  iter: 0  total_loss: 118.6  decode.loss_seg: -5.333e-06  aux_0.loss: 1.415e-06  cnt.cnt_loss: 59.3  loss: 59.3  data_time: 0.0816  lr: N/A  max_mem: 3221M
[06/27 17:58:30] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 345, in _get_eta
    eta_seconds = storage.history("time").median(1000) * (self._max_iter - iteration - 1)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 207, in history
    raise KeyError("No history metric available for {}!".format(name))
KeyError: 'No history metric available for time!'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 122, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 144, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 301, in after_step
    writer.write()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 378, in write
    eta_string = self._get_eta(storage)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 353, in _get_eta
    iteration - self._last_write[0]
ZeroDivisionError: float division by zero
[06/27 18:56:52] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[06/27 18:56:52] cvalgorithms INFO: pretrained checkpoint is loaded.
[06/27 18:57:13] cvalgorithms INFO: Starting training from iteration 0
[06/28 18:41:40] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[06/28 18:41:41] cvalgorithms INFO: pretrained checkpoint is loaded.
[06/30 17:43:03] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[06/30 17:43:03] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 14:44:14] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/01 14:44:14] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 14:49:39] cvalgorithms INFO: Starting training from iteration 0
[07/01 16:18:02] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/01 16:18:02] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 16:18:46] cvalgorithms INFO: Starting training from iteration 0
[07/01 16:19:06] cvalgorithms INFO: Starting training from iteration 0
[07/01 16:40:45] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/01 16:40:45] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 16:40:55] cvalgorithms INFO: Starting training from iteration 0
[07/01 17:01:10] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/01 17:01:10] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 17:04:01] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/01 17:04:01] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 17:04:02] cvalgorithms INFO: Starting training from iteration 0
[07/01 17:04:06] cvalgorithms INFO:  iter: 0  total_loss: 259.1  decode.loss_seg: 8.504e-06  aux_0.loss: -6.991e-06  cnt.cnt_loss: 129.6  loss: 129.6  data_time: 0.0964  lr: N/A  max_mem: 3221M
[07/01 17:04:06] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 345, in _get_eta
    eta_seconds = storage.history("time").median(1000) * (self._max_iter - iteration - 1)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 207, in history
    raise KeyError("No history metric available for {}!".format(name))
KeyError: 'No history metric available for time!'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 122, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 144, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 301, in after_step
    writer.write()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 378, in write
    eta_string = self._get_eta(storage)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 353, in _get_eta
    iteration - self._last_write[0]
ZeroDivisionError: float division by zero
[07/01 17:05:09] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/01 17:05:09] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 17:05:10] cvalgorithms INFO: Starting training from iteration 0
[07/01 17:08:07] cvalgorithms INFO:  iter: 0  total_loss: 337.1  decode.loss_seg: -0.001191  aux_0.loss: 4.829e-06  cnt.cnt_loss: 168.6  loss: 168.6  data_time: 0.0845  lr: N/A  max_mem: 3221M
[07/05 10:26:48] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 10:26:48] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 10:26:50] cvalgorithms INFO: Starting training from iteration 0
[07/05 10:27:49] cvalgorithms INFO:  iter: 0  total_loss: 151.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 75.9  loss: 75.9  data_time: 0.0901  lr: N/A  max_mem: 3221M
[07/05 10:36:53] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 10:36:53] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 10:36:54] cvalgorithms INFO: Starting training from iteration 0
[07/05 10:39:40] cvalgorithms INFO:  iter: 0  total_loss: 311  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 155.5  loss: 155.5  data_time: 0.0870  lr: N/A  max_mem: 3221M
[07/05 10:39:41] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 345, in _get_eta
    eta_seconds = storage.history("time").median(1000) * (self._max_iter - iteration - 1)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 207, in history
    raise KeyError("No history metric available for {}!".format(name))
KeyError: 'No history metric available for time!'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 122, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 144, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 303, in after_step
    writer.write()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 378, in write
    eta_string = self._get_eta(storage)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 353, in _get_eta
    iteration - self._last_write[0]
ZeroDivisionError: float division by zero
[07/05 10:46:03] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 10:46:03] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 11:05:42] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 11:05:42] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 11:05:42] cvalgorithms INFO: Starting training from iteration 0
[07/05 11:05:45] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 118, in train
    self.before_train()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 132, in before_train
    h.before_train()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 319, in before_train
    self._optimizer = self._optimizer or self.trainer.optimizer
AttributeError: 'TrainerContainer' object has no attribute 'optimizer'
[07/05 11:05:45] cvalgorithms INFO:  iter: 0    lr: N/A  max_mem: 0M
[07/05 11:07:46] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 11:07:47] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 11:07:47] cvalgorithms INFO: Starting training from iteration 0
[07/05 11:07:51] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 121, in train
    self.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 133, in run_step
    self._trainer.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 208, in run_step
    loss_dict = self.model(_img, ground_truth=_ground_truth, return_metrics=True)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 305, in forward
    metrics = self.forward_train(inputs, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 211, in forward_train
    x = self.extract_feat(inputs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 57, in extract_feat
    features_n, features_g = self.backbone(inputs_switch), self.backbone(inputs_g)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\base\backbone\convnext.py", line 83, in forward
    x = self.downsample_layers[i](x)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\container.py", line 119, in forward
    input = module(input)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\conv.py", line 399, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\conv.py", line 396, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same
[07/05 11:07:51] cvalgorithms INFO:  iter: 0    lr: N/A  max_mem: 17M
[07/05 11:09:03] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 11:09:03] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 11:09:04] cvalgorithms INFO: Starting training from iteration 0
[07/05 11:09:10] cvalgorithms INFO:  iter: 0  total_loss: 135.5  decode.loss_seg: -0.002456  aux_0.loss: -1.628e-05  cnt.cnt_loss: 67.74  loss: 67.73  data_time: 0.0854  lr: 0.00090451  max_mem: 3221M
[07/05 11:09:11] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 345, in _get_eta
    eta_seconds = storage.history("time").median(1000) * (self._max_iter - iteration - 1)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 207, in history
    raise KeyError("No history metric available for {}!".format(name))
KeyError: 'No history metric available for time!'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 122, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 144, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 303, in after_step
    writer.write()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 378, in write
    eta_string = self._get_eta(storage)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 353, in _get_eta
    iteration - self._last_write[0]
ZeroDivisionError: float division by zero
[07/05 11:14:09] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 11:14:09] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 11:14:10] cvalgorithms INFO: Starting training from iteration 0
[07/05 11:43:56] cvalgorithms INFO:  iter: 0  total_loss: 486.3  decode.loss_seg: 0.0006568  aux_0.loss: 1.233e-06  cnt.cnt_loss: 243.1  loss: 243.1  data_time: 0.1017  lr: 0.00090451  max_mem: 3221M
[07/05 11:44:11] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 345, in _get_eta
    eta_seconds = storage.history("time").median(1000) * (self._max_iter - iteration - 1)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 207, in history
    raise KeyError("No history metric available for {}!".format(name))
KeyError: 'No history metric available for time!'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 122, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 144, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 303, in after_step
    writer.write()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 378, in write
    eta_string = self._get_eta(storage)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 353, in _get_eta
    iteration - self._last_write[0]
ZeroDivisionError: float division by zero
[07/05 12:19:02] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 12:19:02] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 12:19:03] cvalgorithms INFO: Starting training from iteration 0
[07/05 13:15:18] cvalgorithms INFO:  iter: 0  total_loss: 238.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 119.3  loss: 119.3  data_time: 0.1068  lr: 0.00090451  max_mem: 3221M
[07/05 13:22:25] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 13:22:25] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 13:22:26] cvalgorithms INFO: Starting training from iteration 0
[07/05 13:23:44] cvalgorithms INFO:  iter: 0  total_loss: 220.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 110.1  loss: 110.1  data_time: 0.0851  lr: 0.00090451  max_mem: 3221M
[07/05 13:23:51] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 345, in _get_eta
    eta_seconds = storage.history("time").median(1000) * (self._max_iter - iteration - 1)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 207, in history
    raise KeyError("No history metric available for {}!".format(name))
KeyError: 'No history metric available for time!'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 122, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 144, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 303, in after_step
    writer.write()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 378, in write
    eta_string = self._get_eta(storage)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 353, in _get_eta
    iteration - self._last_write[0]
ZeroDivisionError: float division by zero
[07/05 13:35:37] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 13:35:37] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 13:35:38] cvalgorithms INFO: Starting training from iteration 0
[07/05 13:40:17] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 13:40:17] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 13:40:18] cvalgorithms INFO: Starting training from iteration 0
[07/05 13:40:47] cvalgorithms INFO:  iter: 1  total_loss: 459.5  decode.loss_seg: 0.0008303  aux_0.loss: 4.342e-06  cnt.cnt_loss: 229.7  loss: 229.8  data_time: 0.1050  lr: 0.00090451  max_mem: 3221M
[07/05 13:40:52] cvalgorithms INFO:  eta: 0:01:01  iter: 3  total_loss: 284.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 142.1  loss: 142.1  time: 0.6388  data_time: 0.0899  lr: 0.00034549  max_mem: 3221M
[07/05 13:40:53] cvalgorithms INFO:  eta: 0:00:49  iter: 5  total_loss: 145.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.76  loss: 72.76  time: 0.5316  data_time: 0.0832  lr: 0.001  max_mem: 3221M
[07/05 13:40:53] cvalgorithms INFO:  eta: 0:00:39  iter: 7  total_loss: 111.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 55.7  loss: 55.7  time: 0.4963  data_time: 0.0804  lr: 0.00065451  max_mem: 3221M
[07/05 13:40:54] cvalgorithms INFO:  eta: 0:00:38  iter: 9  total_loss: 88.96  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 44.48  loss: 44.48  time: 0.4782  data_time: 0.0791  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:40:55] cvalgorithms INFO:  eta: 0:00:37  iter: 11  total_loss: 88.96  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 44.48  loss: 44.48  time: 0.4650  data_time: 0.0767  lr: 0.00090451  max_mem: 3221M
[07/05 13:40:56] cvalgorithms INFO:  eta: 0:00:36  iter: 13  total_loss: 71.86  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.93  loss: 35.93  time: 0.4566  data_time: 0.0751  lr: 0.00034549  max_mem: 3221M
[07/05 13:40:57] cvalgorithms INFO:  eta: 0:00:35  iter: 15  total_loss: 70.47  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.24  loss: 35.24  time: 0.4500  data_time: 0.0736  lr: 0.001  max_mem: 3221M
[07/05 13:40:58] cvalgorithms INFO:  eta: 0:00:34  iter: 17  total_loss: 66.16  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.08  loss: 33.08  time: 0.4455  data_time: 0.0728  lr: 0.00065451  max_mem: 3221M
[07/05 13:40:58] cvalgorithms INFO:  eta: 0:00:33  iter: 19  total_loss: 65.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.92  loss: 32.92  time: 0.4440  data_time: 0.0736  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:40:59] cvalgorithms INFO:  eta: 0:00:32  iter: 21  total_loss: 53.66  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 26.83  loss: 26.83  time: 0.4411  data_time: 0.0698  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:00] cvalgorithms INFO:  eta: 0:00:31  iter: 23  total_loss: 38.56  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 19.28  loss: 19.28  time: 0.4401  data_time: 0.0703  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:01] cvalgorithms INFO:  eta: 0:00:30  iter: 25  total_loss: 35.45  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.73  loss: 17.73  time: 0.4382  data_time: 0.0701  lr: 0.001  max_mem: 3221M
[07/05 13:41:02] cvalgorithms INFO:  eta: 0:00:29  iter: 27  total_loss: 30.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 15.15  loss: 15.15  time: 0.4369  data_time: 0.0702  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:03] cvalgorithms INFO:  eta: 0:00:29  iter: 29  total_loss: 27.34  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 13.67  loss: 13.67  time: 0.4359  data_time: 0.0699  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:03] cvalgorithms INFO:  eta: 0:00:28  iter: 31  total_loss: 24.31  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.16  loss: 12.16  time: 0.4347  data_time: 0.0702  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:04] cvalgorithms INFO:  eta: 0:00:27  iter: 33  total_loss: 22.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 11.1  loss: 11.1  time: 0.4341  data_time: 0.0712  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:05] cvalgorithms INFO:  eta: 0:00:26  iter: 35  total_loss: 18.89  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 9.447  loss: 9.447  time: 0.4330  data_time: 0.0714  lr: 0.001  max_mem: 3221M
[07/05 13:41:06] cvalgorithms INFO:  eta: 0:00:25  iter: 37  total_loss: 15.22  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.611  loss: 7.611  time: 0.4322  data_time: 0.0715  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:07] cvalgorithms INFO:  eta: 0:00:25  iter: 39  total_loss: 14.29  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.143  loss: 7.143  time: 0.4320  data_time: 0.0707  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:08] cvalgorithms INFO:  eta: 0:00:24  iter: 41  total_loss: 11.99  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.995  loss: 5.995  time: 0.4320  data_time: 0.0719  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:09] cvalgorithms INFO:  eta: 0:00:23  iter: 43  total_loss: 11.13  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.566  loss: 5.566  time: 0.4315  data_time: 0.0708  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:09] cvalgorithms INFO:  eta: 0:00:22  iter: 45  total_loss: 8.259  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.13  loss: 4.13  time: 0.4314  data_time: 0.0709  lr: 0.001  max_mem: 3221M
[07/05 13:41:10] cvalgorithms INFO:  eta: 0:00:21  iter: 47  total_loss: 6.297  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.148  loss: 3.148  time: 0.4313  data_time: 0.0707  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:11] cvalgorithms INFO:  eta: 0:00:20  iter: 49  total_loss: 5.63  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.815  loss: 2.815  time: 0.4312  data_time: 0.0710  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:12] cvalgorithms INFO:  eta: 0:00:20  iter: 51  total_loss: 4.95  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.475  loss: 2.475  time: 0.4309  data_time: 0.0714  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:13] cvalgorithms INFO:  eta: 0:00:19  iter: 53  total_loss: 4.61  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.305  loss: 2.305  time: 0.4309  data_time: 0.0715  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:14] cvalgorithms INFO:  eta: 0:00:18  iter: 55  total_loss: 4.215  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.108  loss: 2.108  time: 0.4311  data_time: 0.0729  lr: 0.001  max_mem: 3221M
[07/05 13:41:15] cvalgorithms INFO:  eta: 0:00:17  iter: 57  total_loss: 4.214  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.107  loss: 2.107  time: 0.4309  data_time: 0.0734  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:16] cvalgorithms INFO:  eta: 0:00:16  iter: 59  total_loss: 3.629  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.814  loss: 1.814  time: 0.4313  data_time: 0.0733  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:16] cvalgorithms INFO:  eta: 0:00:15  iter: 61  total_loss: 3.466  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.733  loss: 1.733  time: 0.4320  data_time: 0.0734  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:17] cvalgorithms INFO:  eta: 0:00:15  iter: 63  total_loss: 3.26  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.63  loss: 1.63  time: 0.4333  data_time: 0.0752  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:18] cvalgorithms INFO:  eta: 0:00:14  iter: 65  total_loss: 2.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.415  loss: 1.415  time: 0.4332  data_time: 0.0754  lr: 0.001  max_mem: 3221M
[07/05 13:41:19] cvalgorithms INFO:  eta: 0:00:13  iter: 67  total_loss: 2.461  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.231  loss: 1.231  time: 0.4331  data_time: 0.0749  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:20] cvalgorithms INFO:  eta: 0:00:12  iter: 69  total_loss: 2.461  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.231  loss: 1.231  time: 0.4330  data_time: 0.0745  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:21] cvalgorithms INFO:  eta: 0:00:11  iter: 71  total_loss: 1.452  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.726  loss: 0.726  time: 0.4329  data_time: 0.0742  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:22] cvalgorithms INFO:  eta: 0:00:11  iter: 73  total_loss: 1.43  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7149  loss: 0.7149  time: 0.4332  data_time: 0.0749  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:23] cvalgorithms INFO:  eta: 0:00:10  iter: 75  total_loss: 1.187  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5937  loss: 0.5937  time: 0.4331  data_time: 0.0740  lr: 0.001  max_mem: 3221M
[07/05 13:41:24] cvalgorithms INFO:  eta: 0:00:09  iter: 77  total_loss: 1.187  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5937  loss: 0.5937  time: 0.4334  data_time: 0.0748  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:24] cvalgorithms INFO:  eta: 0:00:08  iter: 79  total_loss: 2.12  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.06  loss: 1.06  time: 0.4334  data_time: 0.0748  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:25] cvalgorithms INFO:  eta: 0:00:07  iter: 81  total_loss: 2.12  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.06  loss: 1.06  time: 0.4336  data_time: 0.0739  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:26] cvalgorithms INFO:  eta: 0:00:06  iter: 83  total_loss: 1.43  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7149  loss: 0.7149  time: 0.4338  data_time: 0.0722  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:27] cvalgorithms INFO:  eta: 0:00:05  iter: 85  total_loss: 1.187  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5937  loss: 0.5937  time: 0.4341  data_time: 0.0726  lr: 0.001  max_mem: 3221M
[07/05 13:41:28] cvalgorithms INFO:  eta: 0:00:05  iter: 87  total_loss: 1.187  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5937  loss: 0.5937  time: 0.4345  data_time: 0.0732  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:29] cvalgorithms INFO:  eta: 0:00:04  iter: 89  total_loss: 1.121  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5606  loss: 0.5606  time: 0.4347  data_time: 0.0732  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:30] cvalgorithms INFO:  eta: 0:00:03  iter: 91  total_loss: 1.367  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6835  loss: 0.6835  time: 0.4351  data_time: 0.0736  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:31] cvalgorithms INFO:  eta: 0:00:02  iter: 93  total_loss: 1.703  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8517  loss: 0.8517  time: 0.4362  data_time: 0.0747  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:32] cvalgorithms INFO:  eta: 0:00:01  iter: 95  total_loss: 1.703  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8517  loss: 0.8517  time: 0.4370  data_time: 0.0767  lr: 0.001  max_mem: 3221M
[07/05 13:41:33] cvalgorithms INFO:  eta: 0:00:00  iter: 97  total_loss: 1.611  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8055  loss: 0.8055  time: 0.4375  data_time: 0.0759  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:34] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.09  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5449  loss: 0.5449  time: 0.4379  data_time: 0.0767  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:34] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.09  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5449  loss: 0.5449  time: 0.4379  data_time: 0.0767  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:12] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 13:43:12] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 13:43:13] cvalgorithms INFO: Starting training from iteration 0
[07/05 13:43:16] cvalgorithms INFO:  iter: 1  total_loss: 442  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 221  loss: 221  data_time: 0.0733  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:17] cvalgorithms INFO:  eta: 0:00:40  iter: 3  total_loss: 264.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 132.3  loss: 132.3  time: 0.4224  data_time: 0.0703  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:18] cvalgorithms INFO:  eta: 0:00:39  iter: 5  total_loss: 192.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 96.25  loss: 96.25  time: 0.4211  data_time: 0.0680  lr: 0.001  max_mem: 3221M
[07/05 13:43:19] cvalgorithms INFO:  eta: 0:00:38  iter: 7  total_loss: 177  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 88.49  loss: 88.49  time: 0.4222  data_time: 0.0681  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:20] cvalgorithms INFO:  eta: 0:00:37  iter: 9  total_loss: 160.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 80.45  loss: 80.45  time: 0.4210  data_time: 0.0673  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:20] cvalgorithms INFO:  eta: 0:00:37  iter: 11  total_loss: 160.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 80.45  loss: 80.45  time: 0.4222  data_time: 0.0682  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:21] cvalgorithms INFO:  eta: 0:00:35  iter: 13  total_loss: 152.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.1  loss: 76.1  time: 0.4209  data_time: 0.0669  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:22] cvalgorithms INFO:  eta: 0:00:35  iter: 15  total_loss: 144.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.4  loss: 72.4  time: 0.4215  data_time: 0.0655  lr: 0.001  max_mem: 3221M
[07/05 13:43:23] cvalgorithms INFO:  eta: 0:00:34  iter: 17  total_loss: 140.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 70.38  loss: 70.38  time: 0.4220  data_time: 0.0652  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:24] cvalgorithms INFO:  eta: 0:00:33  iter: 19  total_loss: 137  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 68.51  loss: 68.51  time: 0.4228  data_time: 0.0658  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:25] cvalgorithms INFO:  eta: 0:00:32  iter: 21  total_loss: 71.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.92  loss: 35.92  time: 0.4228  data_time: 0.0641  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:26] cvalgorithms INFO:  eta: 0:00:32  iter: 23  total_loss: 60.87  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 30.44  loss: 30.44  time: 0.4253  data_time: 0.0645  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:26] cvalgorithms INFO:  eta: 0:00:31  iter: 25  total_loss: 56.48  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.24  loss: 28.24  time: 0.4264  data_time: 0.0645  lr: 0.001  max_mem: 3221M
[07/05 13:43:27] cvalgorithms INFO:  eta: 0:00:30  iter: 27  total_loss: 44.49  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 22.24  loss: 22.24  time: 0.4281  data_time: 0.0649  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:28] cvalgorithms INFO:  eta: 0:00:29  iter: 29  total_loss: 33.24  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.62  loss: 16.62  time: 0.4296  data_time: 0.0657  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:29] cvalgorithms INFO:  eta: 0:00:29  iter: 31  total_loss: 24.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.15  loss: 12.15  time: 0.4310  data_time: 0.0652  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:30] cvalgorithms INFO:  eta: 0:00:28  iter: 33  total_loss: 20.39  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 10.19  loss: 10.19  time: 0.4323  data_time: 0.0661  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:31] cvalgorithms INFO:  eta: 0:00:27  iter: 35  total_loss: 17.71  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 8.853  loss: 8.853  time: 0.4348  data_time: 0.0685  lr: 0.001  max_mem: 3221M
[07/05 13:43:32] cvalgorithms INFO:  eta: 0:00:26  iter: 37  total_loss: 15.56  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.779  loss: 7.779  time: 0.4355  data_time: 0.0693  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:33] cvalgorithms INFO:  eta: 0:00:26  iter: 39  total_loss: 13.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.605  loss: 6.605  time: 0.4362  data_time: 0.0686  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:34] cvalgorithms INFO:  eta: 0:00:25  iter: 41  total_loss: 10.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.406  loss: 5.406  time: 0.4366  data_time: 0.0693  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:35] cvalgorithms INFO:  eta: 0:00:24  iter: 43  total_loss: 9.898  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.949  loss: 4.949  time: 0.4381  data_time: 0.0703  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:36] cvalgorithms INFO:  eta: 0:00:23  iter: 45  total_loss: 7.13  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.565  loss: 3.565  time: 0.4388  data_time: 0.0710  lr: 0.001  max_mem: 3221M
[07/05 13:43:37] cvalgorithms INFO:  eta: 0:00:22  iter: 47  total_loss: 5.412  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.706  loss: 2.706  time: 0.4396  data_time: 0.0706  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:37] cvalgorithms INFO:  eta: 0:00:22  iter: 49  total_loss: 4.628  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.314  loss: 2.314  time: 0.4403  data_time: 0.0705  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:38] cvalgorithms INFO:  eta: 0:00:21  iter: 51  total_loss: 4.048  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.024  loss: 2.024  time: 0.4411  data_time: 0.0710  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:39] cvalgorithms INFO:  eta: 0:00:20  iter: 53  total_loss: 3.775  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.887  loss: 1.887  time: 0.4419  data_time: 0.0710  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:40] cvalgorithms INFO:  eta: 0:00:19  iter: 55  total_loss: 3.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.8  loss: 1.8  time: 0.4423  data_time: 0.0693  lr: 0.001  max_mem: 3221M
[07/05 13:43:41] cvalgorithms INFO:  eta: 0:00:18  iter: 57  total_loss: 3.161  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.581  loss: 1.581  time: 0.4427  data_time: 0.0692  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:42] cvalgorithms INFO:  eta: 0:00:17  iter: 59  total_loss: 3.419  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.71  loss: 1.71  time: 0.4434  data_time: 0.0703  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:43] cvalgorithms INFO:  eta: 0:00:16  iter: 61  total_loss: 2.944  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.472  loss: 1.472  time: 0.4435  data_time: 0.0710  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:44] cvalgorithms INFO:  eta: 0:00:16  iter: 63  total_loss: 2.754  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.377  loss: 1.377  time: 0.4441  data_time: 0.0707  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:45] cvalgorithms INFO:  eta: 0:00:15  iter: 65  total_loss: 2.05  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.025  loss: 1.025  time: 0.4451  data_time: 0.0717  lr: 0.001  max_mem: 3221M
[07/05 13:43:46] cvalgorithms INFO:  eta: 0:00:14  iter: 67  total_loss: 1.675  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8376  loss: 0.8376  time: 0.4461  data_time: 0.0736  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:47] cvalgorithms INFO:  eta: 0:00:13  iter: 69  total_loss: 1.675  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8376  loss: 0.8376  time: 0.4471  data_time: 0.0755  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:48] cvalgorithms INFO:  eta: 0:00:12  iter: 71  total_loss: 1.413  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7065  loss: 0.7065  time: 0.4474  data_time: 0.0754  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:49] cvalgorithms INFO:  eta: 0:00:11  iter: 73  total_loss: 2.085  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.043  loss: 1.043  time: 0.4482  data_time: 0.0769  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:50] cvalgorithms INFO:  eta: 0:00:10  iter: 75  total_loss: 2.862  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.431  loss: 1.431  time: 0.4487  data_time: 0.0781  lr: 0.001  max_mem: 3221M
[07/05 13:43:51] cvalgorithms INFO:  eta: 0:00:09  iter: 77  total_loss: 3.105  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.553  loss: 1.553  time: 0.4491  data_time: 0.0784  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:51] cvalgorithms INFO:  eta: 0:00:09  iter: 79  total_loss: 2.231  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.115  loss: 1.115  time: 0.4495  data_time: 0.0782  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:52] cvalgorithms INFO:  eta: 0:00:08  iter: 81  total_loss: 2.22  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.11  loss: 1.11  time: 0.4497  data_time: 0.0781  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:53] cvalgorithms INFO:  eta: 0:00:07  iter: 83  total_loss: 2.45  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.225  loss: 1.225  time: 0.4507  data_time: 0.0797  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:54] cvalgorithms INFO:  eta: 0:00:06  iter: 85  total_loss: 3.105  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.553  loss: 1.553  time: 0.4511  data_time: 0.0799  lr: 0.001  max_mem: 3221M
[07/05 13:43:55] cvalgorithms INFO:  eta: 0:00:05  iter: 87  total_loss: 3.116  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.558  loss: 1.558  time: 0.4516  data_time: 0.0792  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:56] cvalgorithms INFO:  eta: 0:00:04  iter: 89  total_loss: 2.45  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.225  loss: 1.225  time: 0.4526  data_time: 0.0794  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:57] cvalgorithms INFO:  eta: 0:00:03  iter: 91  total_loss: 2.45  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.225  loss: 1.225  time: 0.4527  data_time: 0.0794  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:58] cvalgorithms INFO:  eta: 0:00:02  iter: 93  total_loss: 1.504  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7518  loss: 0.7518  time: 0.4531  data_time: 0.0784  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:59] cvalgorithms INFO:  eta: 0:00:01  iter: 95  total_loss: 1.504  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7518  loss: 0.7518  time: 0.4537  data_time: 0.0787  lr: 0.001  max_mem: 3221M
[07/05 13:44:00] cvalgorithms INFO:  eta: 0:00:00  iter: 97  total_loss: 1.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9152  loss: 0.9152  time: 0.4541  data_time: 0.0799  lr: 0.00065451  max_mem: 3221M
[07/05 13:44:01] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9152  loss: 0.9152  time: 0.4543  data_time: 0.0805  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:44:01] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9152  loss: 0.9152  time: 0.4543  data_time: 0.0805  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:48:03] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 13:48:03] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 13:48:04] cvalgorithms INFO: Starting training from iteration 0
[07/05 14:00:06] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 14:00:06] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 14:00:08] cvalgorithms INFO: Starting training from iteration 0
[07/05 14:04:21] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 14:04:21] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 14:04:23] cvalgorithms INFO: Starting training from iteration 0
[07/05 14:12:58] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 14:12:58] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 14:13:00] cvalgorithms INFO: Starting training from iteration 0
[07/05 14:13:26] cvalgorithms INFO:  iter: 1  total_loss: 200.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 100.2  loss: 100.2  data_time: 0.0677  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:27] cvalgorithms INFO:  eta: 22:14:18  iter: 3  total_loss: 158.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 79.23  loss: 79.23  time: 0.4003  data_time: 0.0597  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:28] cvalgorithms INFO:  eta: 22:29:54  iter: 5  total_loss: 161.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 80.82  loss: 80.82  time: 0.4059  data_time: 0.0609  lr: 0.001  max_mem: 3221M
[07/05 14:13:29] cvalgorithms INFO:  eta: 22:29:24  iter: 7  total_loss: 146.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 73.16  loss: 73.16  time: 0.4042  data_time: 0.0594  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:30] cvalgorithms INFO:  eta: 22:29:23  iter: 9  total_loss: 110  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 54.99  loss: 54.99  time: 0.4032  data_time: 0.0579  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:31] cvalgorithms INFO:  eta: 22:34:41  iter: 11  total_loss: 64.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.41  loss: 32.41  time: 0.4052  data_time: 0.0591  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:31] cvalgorithms INFO:  eta: 22:30:02  iter: 13  total_loss: 79.92  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.96  loss: 39.96  time: 0.4042  data_time: 0.0582  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:32] cvalgorithms INFO:  eta: 22:33:37  iter: 15  total_loss: 64.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.41  loss: 32.41  time: 0.4056  data_time: 0.0591  lr: 0.001  max_mem: 3221M
[07/05 14:13:33] cvalgorithms INFO:  eta: 22:33:37  iter: 17  total_loss: 52.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 26.35  loss: 26.35  time: 0.4064  data_time: 0.0589  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:34] cvalgorithms INFO:  eta: 22:34:38  iter: 19  total_loss: 47.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.87  loss: 23.87  time: 0.4098  data_time: 0.0606  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:35] cvalgorithms INFO:  eta: 22:37:13  iter: 21  total_loss: 37.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 18.55  loss: 18.55  time: 0.4121  data_time: 0.0609  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:36] cvalgorithms INFO:  eta: 22:43:48  iter: 23  total_loss: 24.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.37  loss: 12.37  time: 0.4129  data_time: 0.0616  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:36] cvalgorithms INFO:  eta: 22:54:13  iter: 25  total_loss: 21.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 10.6  loss: 10.6  time: 0.4132  data_time: 0.0614  lr: 0.001  max_mem: 3221M
[07/05 14:13:37] cvalgorithms INFO:  eta: 22:58:51  iter: 27  total_loss: 19.15  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 9.574  loss: 9.574  time: 0.4132  data_time: 0.0622  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:38] cvalgorithms INFO:  eta: 23:00:18  iter: 29  total_loss: 16.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 8.201  loss: 8.201  time: 0.4136  data_time: 0.0632  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:39] cvalgorithms INFO:  eta: 22:58:49  iter: 31  total_loss: 16.15  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 8.076  loss: 8.076  time: 0.4125  data_time: 0.0613  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:40] cvalgorithms INFO:  eta: 22:54:00  iter: 33  total_loss: 15.45  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.728  loss: 7.727  time: 0.4122  data_time: 0.0614  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:41] cvalgorithms INFO:  eta: 22:55:48  iter: 35  total_loss: 13.17  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.586  loss: 6.586  time: 0.4123  data_time: 0.0605  lr: 0.001  max_mem: 3221M
[07/05 14:13:41] cvalgorithms INFO:  eta: 22:58:47  iter: 37  total_loss: 12.02  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.012  loss: 6.012  time: 0.4126  data_time: 0.0610  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:42] cvalgorithms INFO:  eta: 23:00:13  iter: 39  total_loss: 11.79  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.897  loss: 5.897  time: 0.4140  data_time: 0.0616  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:43] cvalgorithms INFO:  eta: 23:03:12  iter: 41  total_loss: 8.557  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.278  loss: 4.278  time: 0.4145  data_time: 0.0601  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:44] cvalgorithms INFO:  eta: 23:06:30  iter: 43  total_loss: 8.097  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.048  loss: 4.048  time: 0.4152  data_time: 0.0610  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:45] cvalgorithms INFO:  eta: 23:07:12  iter: 45  total_loss: 7.98  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.99  loss: 3.99  time: 0.4165  data_time: 0.0631  lr: 0.001  max_mem: 3221M
[07/05 14:13:46] cvalgorithms INFO:  eta: 23:07:44  iter: 47  total_loss: 7.158  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.579  loss: 3.579  time: 0.4174  data_time: 0.0645  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:47] cvalgorithms INFO:  eta: 23:08:41  iter: 49  total_loss: 5.558  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.779  loss: 2.779  time: 0.4178  data_time: 0.0648  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:48] cvalgorithms INFO:  eta: 23:09:47  iter: 51  total_loss: 4.833  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.416  loss: 2.416  time: 0.4181  data_time: 0.0663  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:48] cvalgorithms INFO:  eta: 23:10:23  iter: 53  total_loss: 4.691  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.345  loss: 2.345  time: 0.4187  data_time: 0.0681  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:49] cvalgorithms INFO:  eta: 23:10:22  iter: 55  total_loss: 4.178  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.089  loss: 2.089  time: 0.4185  data_time: 0.0684  lr: 0.001  max_mem: 3221M
[07/05 14:13:50] cvalgorithms INFO:  eta: 23:09:44  iter: 57  total_loss: 2.736  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.368  loss: 1.368  time: 0.4182  data_time: 0.0679  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:51] cvalgorithms INFO:  eta: 23:08:37  iter: 59  total_loss: 2.552  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.276  loss: 1.276  time: 0.4181  data_time: 0.0656  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:52] cvalgorithms INFO:  eta: 23:09:42  iter: 61  total_loss: 2.426  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.213  loss: 1.213  time: 0.4187  data_time: 0.0683  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:53] cvalgorithms INFO:  eta: 23:10:19  iter: 63  total_loss: 2.254  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.127  loss: 1.127  time: 0.4189  data_time: 0.0677  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:53] cvalgorithms INFO:  eta: 23:09:41  iter: 65  total_loss: 1.953  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9767  loss: 0.9767  time: 0.4184  data_time: 0.0645  lr: 0.001  max_mem: 3221M
[07/05 14:13:54] cvalgorithms INFO:  eta: 23:10:17  iter: 67  total_loss: 2.254  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.127  loss: 1.127  time: 0.4185  data_time: 0.0633  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:55] cvalgorithms INFO:  eta: 23:10:17  iter: 69  total_loss: 2.297  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.148  loss: 1.148  time: 0.4185  data_time: 0.0624  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:56] cvalgorithms INFO:  eta: 23:11:08  iter: 71  total_loss: 1.802  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9009  loss: 0.9009  time: 0.4187  data_time: 0.0625  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:57] cvalgorithms INFO:  eta: 23:10:15  iter: 73  total_loss: 1.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6052  loss: 0.6052  time: 0.4184  data_time: 0.0604  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:58] cvalgorithms INFO:  eta: 23:10:14  iter: 75  total_loss: 1.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6052  loss: 0.6052  time: 0.4184  data_time: 0.0602  lr: 0.001  max_mem: 3221M
[07/05 14:13:58] cvalgorithms INFO:  eta: 23:11:05  iter: 77  total_loss: 1.568  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.784  loss: 0.784  time: 0.4186  data_time: 0.0611  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:59] cvalgorithms INFO:  eta: 23:12:53  iter: 79  total_loss: 1.987  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9934  loss: 0.9934  time: 0.4188  data_time: 0.0616  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:00] cvalgorithms INFO:  eta: 23:12:53  iter: 81  total_loss: 2.136  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.068  loss: 1.068  time: 0.4187  data_time: 0.0590  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:01] cvalgorithms INFO:  eta: 23:14:00  iter: 83  total_loss: 1.757  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8786  loss: 0.8786  time: 0.4189  data_time: 0.0588  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:02] cvalgorithms INFO:  eta: 23:13:59  iter: 85  total_loss: 1.917  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9583  loss: 0.9583  time: 0.4190  data_time: 0.0596  lr: 0.001  max_mem: 3221M
[07/05 14:14:03] cvalgorithms INFO:  eta: 23:13:58  iter: 87  total_loss: 1.741  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8706  loss: 0.8706  time: 0.4190  data_time: 0.0585  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:04] cvalgorithms INFO:  eta: 23:13:57  iter: 89  total_loss: 1.552  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7761  loss: 0.7761  time: 0.4191  data_time: 0.0592  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:04] cvalgorithms INFO:  eta: 23:13:56  iter: 91  total_loss: 1.757  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8786  loss: 0.8786  time: 0.4193  data_time: 0.0593  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:05] cvalgorithms INFO:  eta: 23:14:03  iter: 93  total_loss: 2.136  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.068  loss: 1.068  time: 0.4200  data_time: 0.0633  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:06] cvalgorithms INFO:  eta: 23:15:20  iter: 95  total_loss: 2.136  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.068  loss: 1.068  time: 0.4202  data_time: 0.0637  lr: 0.001  max_mem: 3221M
[07/05 14:14:07] cvalgorithms INFO:  eta: 23:16:52  iter: 97  total_loss: 2.099  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.05  loss: 1.05  time: 0.4206  data_time: 0.0638  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:08] cvalgorithms INFO:  eta: 23:16:51  iter: 99  total_loss: 1.906  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.953  loss: 0.953  time: 0.4206  data_time: 0.0632  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:09] cvalgorithms INFO:  eta: 23:19:21  iter: 101  total_loss: 1.741  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8706  loss: 0.8706  time: 0.4211  data_time: 0.0651  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:10] cvalgorithms INFO:  eta: 23:19:20  iter: 103  total_loss: 1.923  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9613  loss: 0.9613  time: 0.4212  data_time: 0.0647  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:11] cvalgorithms INFO:  eta: 23:22:55  iter: 105  total_loss: 1.923  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9613  loss: 0.9613  time: 0.4216  data_time: 0.0649  lr: 0.001  max_mem: 3221M
[07/05 14:14:11] cvalgorithms INFO:  eta: 23:24:22  iter: 107  total_loss: 2.028  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.014  loss: 1.014  time: 0.4218  data_time: 0.0664  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:12] cvalgorithms INFO:  eta: 23:24:31  iter: 109  total_loss: 2.028  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.014  loss: 1.014  time: 0.4220  data_time: 0.0662  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:13] cvalgorithms INFO:  eta: 23:24:38  iter: 111  total_loss: 1.897  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9486  loss: 0.9486  time: 0.4221  data_time: 0.0651  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:14] cvalgorithms INFO:  eta: 23:24:50  iter: 113  total_loss: 1.897  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9486  loss: 0.9486  time: 0.4224  data_time: 0.0626  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:15] cvalgorithms INFO:  eta: 23:25:16  iter: 115  total_loss: 1.897  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9486  loss: 0.9486  time: 0.4226  data_time: 0.0621  lr: 0.001  max_mem: 3221M
[07/05 14:14:16] cvalgorithms INFO:  eta: 23:25:31  iter: 117  total_loss: 1.897  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9486  loss: 0.9486  time: 0.4232  data_time: 0.0632  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:17] cvalgorithms INFO:  eta: 23:25:37  iter: 119  total_loss: 2.07  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.035  loss: 1.035  time: 0.4233  data_time: 0.0631  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:18] cvalgorithms INFO:  eta: 23:25:51  iter: 121  total_loss: 2.07  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.035  loss: 1.035  time: 0.4235  data_time: 0.0621  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:19] cvalgorithms INFO:  eta: 23:26:40  iter: 123  total_loss: 2.41  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.205  loss: 1.205  time: 0.4241  data_time: 0.0642  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:19] cvalgorithms INFO:  eta: 23:27:49  iter: 125  total_loss: 2.41  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.205  loss: 1.205  time: 0.4246  data_time: 0.0646  lr: 0.001  max_mem: 3221M
[07/05 14:14:20] cvalgorithms INFO:  eta: 23:30:30  iter: 127  total_loss: 2.704  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.352  loss: 1.352  time: 0.4256  data_time: 0.0654  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:21] cvalgorithms INFO:  eta: 23:32:55  iter: 129  total_loss: 2.952  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.476  loss: 1.476  time: 0.4267  data_time: 0.0680  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:22] cvalgorithms INFO:  eta: 23:33:11  iter: 131  total_loss: 2.733  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.367  loss: 1.367  time: 0.4274  data_time: 0.0703  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:23] cvalgorithms INFO:  eta: 23:33:36  iter: 133  total_loss: 2.504  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.252  loss: 1.252  time: 0.4280  data_time: 0.0698  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:24] cvalgorithms INFO:  eta: 23:33:57  iter: 135  total_loss: 2.504  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.252  loss: 1.252  time: 0.4288  data_time: 0.0710  lr: 0.001  max_mem: 3221M
[07/05 14:14:25] cvalgorithms INFO:  eta: 23:35:04  iter: 137  total_loss: 2.619  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.31  loss: 1.31  time: 0.4298  data_time: 0.0717  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:26] cvalgorithms INFO:  eta: 23:36:31  iter: 139  total_loss: 2.296  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.148  loss: 1.148  time: 0.4304  data_time: 0.0729  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:27] cvalgorithms INFO:  eta: 23:37:15  iter: 141  total_loss: 2.296  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.148  loss: 1.148  time: 0.4308  data_time: 0.0736  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:28] cvalgorithms INFO:  eta: 23:37:53  iter: 143  total_loss: 2.07  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.035  loss: 1.035  time: 0.4314  data_time: 0.0740  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:29] cvalgorithms INFO:  eta: 23:38:23  iter: 145  total_loss: 2.07  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.035  loss: 1.035  time: 0.4321  data_time: 0.0753  lr: 0.001  max_mem: 3221M
[07/05 14:14:30] cvalgorithms INFO:  eta: 23:39:03  iter: 147  total_loss: 1.789  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8943  loss: 0.8943  time: 0.4325  data_time: 0.0748  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:31] cvalgorithms INFO:  eta: 23:39:33  iter: 149  total_loss: 1.665  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8324  loss: 0.8324  time: 0.4330  data_time: 0.0729  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:32] cvalgorithms INFO:  eta: 23:39:57  iter: 151  total_loss: 1.358  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6791  loss: 0.6791  time: 0.4335  data_time: 0.0728  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:33] cvalgorithms INFO:  eta: 23:40:22  iter: 153  total_loss: 1.358  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6791  loss: 0.6791  time: 0.4343  data_time: 0.0753  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:34] cvalgorithms INFO:  eta: 23:41:03  iter: 155  total_loss: 1.358  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6791  loss: 0.6791  time: 0.4352  data_time: 0.0778  lr: 0.001  max_mem: 3221M
[07/05 14:14:35] cvalgorithms INFO:  eta: 23:42:25  iter: 157  total_loss: 1.355  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6773  loss: 0.6773  time: 0.4357  data_time: 0.0779  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:36] cvalgorithms INFO:  eta: 23:44:19  iter: 159  total_loss: 1.034  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5172  loss: 0.5172  time: 0.4362  data_time: 0.0788  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:37] cvalgorithms INFO:  eta: 23:47:06  iter: 161  total_loss: 0.8461  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.423  loss: 0.423  time: 0.4371  data_time: 0.0801  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:38] cvalgorithms INFO:  eta: 23:48:50  iter: 163  total_loss: 0.9006  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4503  loss: 0.4503  time: 0.4379  data_time: 0.0820  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:39] cvalgorithms INFO:  eta: 23:49:50  iter: 165  total_loss: 0.8461  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.423  loss: 0.423  time: 0.4382  data_time: 0.0817  lr: 0.001  max_mem: 3221M
[07/05 14:14:40] cvalgorithms INFO:  eta: 23:51:04  iter: 167  total_loss: 0.8443  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4221  loss: 0.4221  time: 0.4384  data_time: 0.0815  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:41] cvalgorithms INFO:  eta: 23:51:42  iter: 169  total_loss: 0.9809  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4904  loss: 0.4904  time: 0.4390  data_time: 0.0813  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:42] cvalgorithms INFO:  eta: 23:52:56  iter: 171  total_loss: 1.376  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6878  loss: 0.6878  time: 0.4393  data_time: 0.0816  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:43] cvalgorithms INFO:  eta: 23:55:26  iter: 173  total_loss: 1.376  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6878  loss: 0.6878  time: 0.4396  data_time: 0.0803  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:44] cvalgorithms INFO:  eta: 23:58:23  iter: 175  total_loss: 0.8669  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4334  loss: 0.4334  time: 0.4403  data_time: 0.0786  lr: 0.001  max_mem: 3221M
[07/05 14:14:45] cvalgorithms INFO:  eta: 1 day, 0:01:40  iter: 177  total_loss: 0.9472  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4736  loss: 0.4736  time: 0.4414  data_time: 0.0802  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:46] cvalgorithms INFO:  eta: 1 day, 0:04:50  iter: 179  total_loss: 1.145  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5724  loss: 0.5724  time: 0.4419  data_time: 0.0812  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:47] cvalgorithms INFO:  eta: 1 day, 0:06:21  iter: 181  total_loss: 1.512  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7562  loss: 0.7562  time: 0.4420  data_time: 0.0789  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:47] cvalgorithms INFO:  eta: 1 day, 0:06:58  iter: 183  total_loss: 1.17  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.585  loss: 0.585  time: 0.4424  data_time: 0.0763  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:48] cvalgorithms INFO:  eta: 1 day, 0:08:53  iter: 185  total_loss: 1.401  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7003  loss: 0.7003  time: 0.4429  data_time: 0.0763  lr: 0.001  max_mem: 3221M
[07/05 14:14:49] cvalgorithms INFO:  eta: 1 day, 0:10:43  iter: 187  total_loss: 1.17  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.585  loss: 0.585  time: 0.4430  data_time: 0.0761  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:50] cvalgorithms INFO:  eta: 1 day, 0:11:08  iter: 189  total_loss: 1.04  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5198  loss: 0.5198  time: 0.4432  data_time: 0.0770  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:51] cvalgorithms INFO:  eta: 1 day, 0:11:29  iter: 191  total_loss: 1.17  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.585  loss: 0.585  time: 0.4434  data_time: 0.0765  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:52] cvalgorithms INFO:  eta: 1 day, 0:12:35  iter: 193  total_loss: 1.17  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.585  loss: 0.585  time: 0.4437  data_time: 0.0777  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:53] cvalgorithms INFO:  eta: 1 day, 0:14:19  iter: 195  total_loss: 1.739  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8695  loss: 0.8695  time: 0.4440  data_time: 0.0765  lr: 0.001  max_mem: 3221M
[07/05 14:14:54] cvalgorithms INFO:  eta: 1 day, 0:15:19  iter: 197  total_loss: 1.623  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8117  loss: 0.8117  time: 0.4442  data_time: 0.0731  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:55] cvalgorithms INFO:  eta: 1 day, 0:17:44  iter: 199  total_loss: 1.623  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8117  loss: 0.8117  time: 0.4446  data_time: 0.0718  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:56] cvalgorithms INFO:  eta: 1 day, 0:20:07  iter: 201  total_loss: 1.79  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8951  loss: 0.8951  time: 0.4449  data_time: 0.0738  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:57] cvalgorithms INFO:  eta: 1 day, 0:22:41  iter: 203  total_loss: 1.79  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8951  loss: 0.8951  time: 0.4450  data_time: 0.0734  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:58] cvalgorithms INFO:  eta: 1 day, 0:25:16  iter: 205  total_loss: 1.791  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8953  loss: 0.8953  time: 0.4456  data_time: 0.0748  lr: 0.001  max_mem: 3221M
[07/05 14:14:59] cvalgorithms INFO:  eta: 1 day, 0:26:01  iter: 207  total_loss: 1.791  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8953  loss: 0.8953  time: 0.4458  data_time: 0.0759  lr: 0.00065451  max_mem: 3221M
[07/05 14:15:00] cvalgorithms INFO:  eta: 1 day, 0:26:38  iter: 209  total_loss: 1.791  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8953  loss: 0.8953  time: 0.4460  data_time: 0.0755  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:15:01] cvalgorithms INFO:  eta: 1 day, 0:27:39  iter: 211  total_loss: 1.727  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8637  loss: 0.8637  time: 0.4465  data_time: 0.0771  lr: 0.00090451  max_mem: 3221M
[07/05 14:15:02] cvalgorithms INFO:  eta: 1 day, 0:28:35  iter: 213  total_loss: 1.727  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8637  loss: 0.8637  time: 0.4467  data_time: 0.0760  lr: 0.00034549  max_mem: 3221M
[07/05 14:15:03] cvalgorithms INFO:  eta: 1 day, 0:30:02  iter: 215  total_loss: 1.727  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8637  loss: 0.8637  time: 0.4467  data_time: 0.0762  lr: 0.001  max_mem: 3221M
[07/05 14:15:04] cvalgorithms INFO:  eta: 1 day, 0:31:38  iter: 217  total_loss: 1.697  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8484  loss: 0.8484  time: 0.4468  data_time: 0.0759  lr: 0.00065451  max_mem: 3221M
[07/05 14:15:05] cvalgorithms INFO:  eta: 1 day, 0:33:38  iter: 219  total_loss: 1.565  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7826  loss: 0.7826  time: 0.4469  data_time: 0.0761  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:15:05] cvalgorithms INFO:  eta: 1 day, 0:36:10  iter: 221  total_loss: 1.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.605  loss: 0.605  time: 0.4471  data_time: 0.0759  lr: 0.00090451  max_mem: 3221M
[07/05 14:15:06] cvalgorithms INFO:  eta: 1 day, 0:36:10  iter: 223  total_loss: 1.351  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6757  loss: 0.6757  time: 0.4473  data_time: 0.0772  lr: 0.00034549  max_mem: 3221M
[07/05 14:15:07] cvalgorithms INFO:  eta: 1 day, 0:38:34  iter: 225  total_loss: 1.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.605  loss: 0.605  time: 0.4474  data_time: 0.0745  lr: 0.001  max_mem: 3221M
[07/05 14:15:08] cvalgorithms INFO:  eta: 1 day, 0:40:36  iter: 227  total_loss: 1.118  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.559  loss: 0.559  time: 0.4476  data_time: 0.0738  lr: 0.00065451  max_mem: 3221M
[07/05 14:15:09] cvalgorithms INFO:  eta: 1 day, 0:41:20  iter: 229  total_loss: 1.118  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.559  loss: 0.559  time: 0.4478  data_time: 0.0753  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:15:10] cvalgorithms INFO:  eta: 1 day, 0:43:22  iter: 231  total_loss: 0.9972  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4986  loss: 0.4986  time: 0.4479  data_time: 0.0729  lr: 0.00090451  max_mem: 3221M
[07/05 14:15:11] cvalgorithms INFO:  eta: 1 day, 0:45:27  iter: 233  total_loss: 1.045  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5223  loss: 0.5223  time: 0.4480  data_time: 0.0727  lr: 0.00034549  max_mem: 3221M
[07/05 14:15:12] cvalgorithms INFO:  eta: 1 day, 0:46:23  iter: 235  total_loss: 0.9972  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4986  loss: 0.4986  time: 0.4480  data_time: 0.0725  lr: 0.001  max_mem: 3221M
[07/05 14:15:13] cvalgorithms INFO:  eta: 1 day, 0:47:11  iter: 237  total_loss: 0.9705  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4852  loss: 0.4852  time: 0.4482  data_time: 0.0736  lr: 0.00065451  max_mem: 3221M
[07/05 14:15:14] cvalgorithms INFO:  eta: 1 day, 0:48:25  iter: 239  total_loss: 1.116  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5582  loss: 0.5582  time: 0.4484  data_time: 0.0736  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:15:15] cvalgorithms INFO:  eta: 1 day, 0:48:24  iter: 241  total_loss: 1.116  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5582  loss: 0.5582  time: 0.4484  data_time: 0.0723  lr: 0.00090451  max_mem: 3221M
[07/05 14:15:16] cvalgorithms INFO:  eta: 1 day, 0:49:28  iter: 243  total_loss: 1.116  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5582  loss: 0.5582  time: 0.4485  data_time: 0.0718  lr: 0.00034549  max_mem: 3221M
[07/05 14:15:17] cvalgorithms INFO:  eta: 1 day, 0:49:27  iter: 245  total_loss: 1.08  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5398  loss: 0.5398  time: 0.4485  data_time: 0.0717  lr: 0.001  max_mem: 3221M
[07/05 14:15:18] cvalgorithms INFO:  eta: 1 day, 0:50:02  iter: 247  total_loss: 1.417  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7083  loss: 0.7083  time: 0.4489  data_time: 0.0724  lr: 0.00065451  max_mem: 3221M
[07/05 14:15:19] cvalgorithms INFO:  eta: 1 day, 0:50:44  iter: 249  total_loss: 1.417  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7083  loss: 0.7083  time: 0.4493  data_time: 0.0735  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:15:20] cvalgorithms INFO:  eta: 1 day, 0:51:21  iter: 251  total_loss: 1.711  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8556  loss: 0.8556  time: 0.4496  data_time: 0.0752  lr: 0.00090451  max_mem: 3221M
[07/05 14:15:21] cvalgorithms INFO:  eta: 1 day, 0:52:01  iter: 253  total_loss: 1.473  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7364  loss: 0.7364  time: 0.4498  data_time: 0.0762  lr: 0.00034549  max_mem: 3221M
[07/05 14:15:21] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 123, in train
    self.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 133, in run_step
    self._trainer.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 204, in run_step
    data = next(self._data_loader_iter)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\utils\data\dataloader.py", line 517, in __next__
    data = self._next_data()
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\utils\data\dataloader.py", line 556, in _next_data
    index = self._next_index()  # may raise StopIteration
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\utils\data\dataloader.py", line 508, in _next_index
    return next(self._sampler_iter)  # may raise StopIteration
StopIteration
[07/05 14:15:21] cvalgorithms INFO:  eta: 1 day, 0:52:00  iter: 254  total_loss: 1.473  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7364  loss: 0.7364  time: 0.4498  data_time: 0.0762  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:06] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 14:56:07] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 14:56:08] cvalgorithms INFO: Starting training from iteration 0
[07/05 14:56:11] cvalgorithms INFO:  iter: 1  total_loss: 34.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.1  loss: 17.1  data_time: 0.0554  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:12] cvalgorithms INFO:  eta: 22:53:32  iter: 3  total_loss: 35.38  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.69  loss: 17.69  time: 0.4121  data_time: 0.0606  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:13] cvalgorithms INFO:  eta: 22:24:58  iter: 5  total_loss: 35.44  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.72  loss: 17.72  time: 0.4060  data_time: 0.0581  lr: 0.001  max_mem: 3221M
[07/05 14:56:13] cvalgorithms INFO:  eta: 22:24:57  iter: 7  total_loss: 35.44  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.72  loss: 17.72  time: 0.4045  data_time: 0.0575  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:14] cvalgorithms INFO:  eta: 22:15:45  iter: 9  total_loss: 35.44  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.72  loss: 17.72  time: 0.4028  data_time: 0.0560  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:15] cvalgorithms INFO:  eta: 22:15:44  iter: 11  total_loss: 34.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.4  loss: 17.4  time: 0.4028  data_time: 0.0559  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:16] cvalgorithms INFO:  eta: 22:15:43  iter: 13  total_loss: 35.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.55  loss: 17.55  time: 0.4028  data_time: 0.0556  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:17] cvalgorithms INFO:  eta: 22:15:42  iter: 15  total_loss: 35.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.55  loss: 17.55  time: 0.4028  data_time: 0.0556  lr: 0.001  max_mem: 3221M
[07/05 14:56:18] cvalgorithms INFO:  eta: 22:11:37  iter: 17  total_loss: 35.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.55  loss: 17.55  time: 0.4022  data_time: 0.0547  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:18] cvalgorithms INFO:  eta: 22:10:19  iter: 19  total_loss: 34.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.4  loss: 17.4  time: 0.4015  data_time: 0.0541  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:19] cvalgorithms INFO:  eta: 22:10:18  iter: 21  total_loss: 33.63  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.81  loss: 16.81  time: 0.4018  data_time: 0.0539  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:20] cvalgorithms INFO:  eta: 22:11:34  iter: 23  total_loss: 28.61  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 14.31  loss: 14.31  time: 0.4032  data_time: 0.0543  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:21] cvalgorithms INFO:  eta: 22:10:16  iter: 25  total_loss: 24.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.05  loss: 12.05  time: 0.4028  data_time: 0.0540  lr: 0.001  max_mem: 3221M
[07/05 14:56:22] cvalgorithms INFO:  eta: 22:11:33  iter: 27  total_loss: 19.57  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 9.786  loss: 9.786  time: 0.4032  data_time: 0.0544  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:22] cvalgorithms INFO:  eta: 22:10:15  iter: 29  total_loss: 13.59  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.797  loss: 6.797  time: 0.4028  data_time: 0.0544  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:23] cvalgorithms INFO:  eta: 22:11:31  iter: 31  total_loss: 11.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.919  loss: 5.919  time: 0.4032  data_time: 0.0545  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:24] cvalgorithms INFO:  eta: 22:13:33  iter: 33  total_loss: 9.939  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.97  loss: 4.97  time: 0.4032  data_time: 0.0538  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:25] cvalgorithms INFO:  eta: 22:16:46  iter: 35  total_loss: 7.695  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.848  loss: 3.848  time: 0.4034  data_time: 0.0537  lr: 0.001  max_mem: 3221M
[07/05 14:56:26] cvalgorithms INFO:  eta: 22:16:45  iter: 37  total_loss: 6.557  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.279  loss: 3.279  time: 0.4033  data_time: 0.0541  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:26] cvalgorithms INFO:  eta: 22:18:46  iter: 39  total_loss: 5.221  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.61  loss: 2.61  time: 0.4036  data_time: 0.0549  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:27] cvalgorithms INFO:  eta: 22:19:53  iter: 41  total_loss: 4.31  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.155  loss: 2.155  time: 0.4039  data_time: 0.0554  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:28] cvalgorithms INFO:  eta: 22:21:58  iter: 43  total_loss: 2.69  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.345  loss: 1.345  time: 0.4042  data_time: 0.0542  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:29] cvalgorithms INFO:  eta: 22:23:00  iter: 45  total_loss: 2.672  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.336  loss: 1.336  time: 0.4044  data_time: 0.0549  lr: 0.001  max_mem: 3221M
[07/05 14:56:30] cvalgorithms INFO:  eta: 22:22:59  iter: 47  total_loss: 2.451  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.226  loss: 1.226  time: 0.4044  data_time: 0.0541  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:31] cvalgorithms INFO:  eta: 22:24:34  iter: 49  total_loss: 2.277  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.139  loss: 1.139  time: 0.4050  data_time: 0.0558  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:31] cvalgorithms INFO:  eta: 22:24:34  iter: 51  total_loss: 2.277  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.139  loss: 1.139  time: 0.4054  data_time: 0.0559  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:32] cvalgorithms INFO:  eta: 22:26:09  iter: 53  total_loss: 2.277  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.139  loss: 1.139  time: 0.4056  data_time: 0.0566  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:33] cvalgorithms INFO:  eta: 22:26:45  iter: 55  total_loss: 2.137  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.069  loss: 1.069  time: 0.4056  data_time: 0.0565  lr: 0.001  max_mem: 3221M
[07/05 14:56:34] cvalgorithms INFO:  eta: 22:28:33  iter: 57  total_loss: 1.885  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9427  loss: 0.9427  time: 0.4060  data_time: 0.0571  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:35] cvalgorithms INFO:  eta: 22:28:32  iter: 59  total_loss: 1.64  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8199  loss: 0.8199  time: 0.4059  data_time: 0.0567  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:36] cvalgorithms INFO:  eta: 22:29:51  iter: 61  total_loss: 2.128  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.064  loss: 1.064  time: 0.4067  data_time: 0.0583  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:36] cvalgorithms INFO:  eta: 22:30:13  iter: 63  total_loss: 2.128  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.064  loss: 1.064  time: 0.4069  data_time: 0.0585  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:37] cvalgorithms INFO:  eta: 22:31:01  iter: 65  total_loss: 1.64  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8199  loss: 0.8199  time: 0.4074  data_time: 0.0598  lr: 0.001  max_mem: 3221M
[07/05 14:56:38] cvalgorithms INFO:  eta: 22:31:45  iter: 67  total_loss: 1.64  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8199  loss: 0.8199  time: 0.4083  data_time: 0.0607  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:39] cvalgorithms INFO:  eta: 22:33:10  iter: 69  total_loss: 1.794  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.897  loss: 0.897  time: 0.4086  data_time: 0.0600  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:40] cvalgorithms INFO:  eta: 22:34:31  iter: 71  total_loss: 1.508  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7539  loss: 0.7539  time: 0.4097  data_time: 0.0600  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:41] cvalgorithms INFO:  eta: 22:36:18  iter: 73  total_loss: 1.508  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7539  loss: 0.7539  time: 0.4110  data_time: 0.0624  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:42] cvalgorithms INFO:  eta: 22:37:58  iter: 75  total_loss: 1.794  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.897  loss: 0.897  time: 0.4118  data_time: 0.0637  lr: 0.001  max_mem: 3221M
[07/05 14:56:43] cvalgorithms INFO:  eta: 22:38:09  iter: 77  total_loss: 1.794  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.897  loss: 0.897  time: 0.4122  data_time: 0.0641  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:43] cvalgorithms INFO:  eta: 22:38:44  iter: 79  total_loss: 1.662  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.831  loss: 0.831  time: 0.4129  data_time: 0.0651  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:44] cvalgorithms INFO:  eta: 22:39:23  iter: 81  total_loss: 1.662  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.831  loss: 0.831  time: 0.4133  data_time: 0.0640  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:45] cvalgorithms INFO:  eta: 22:40:46  iter: 83  total_loss: 1.662  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.831  loss: 0.831  time: 0.4136  data_time: 0.0640  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:46] cvalgorithms INFO:  eta: 22:43:46  iter: 85  total_loss: 1.662  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.831  loss: 0.831  time: 0.4146  data_time: 0.0641  lr: 0.001  max_mem: 3221M
[07/05 14:56:47] cvalgorithms INFO:  eta: 22:46:06  iter: 87  total_loss: 1.662  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.831  loss: 0.831  time: 0.4151  data_time: 0.0636  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:48] cvalgorithms INFO:  eta: 22:47:42  iter: 89  total_loss: 1.822  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9111  loss: 0.9111  time: 0.4154  data_time: 0.0638  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:49] cvalgorithms INFO:  eta: 22:50:45  iter: 91  total_loss: 1.961  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9803  loss: 0.9803  time: 0.4161  data_time: 0.0649  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:50] cvalgorithms INFO:  eta: 22:54:05  iter: 93  total_loss: 1.822  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9111  loss: 0.9111  time: 0.4167  data_time: 0.0634  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:50] cvalgorithms INFO:  eta: 22:57:05  iter: 95  total_loss: 1.649  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8244  loss: 0.8244  time: 0.4172  data_time: 0.0630  lr: 0.001  max_mem: 3221M
[07/05 14:56:51] cvalgorithms INFO:  eta: 22:58:55  iter: 97  total_loss: 1.649  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8244  loss: 0.8244  time: 0.4179  data_time: 0.0633  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:52] cvalgorithms INFO:  eta: 22:59:32  iter: 99  total_loss: 1.822  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9111  loss: 0.9111  time: 0.4187  data_time: 0.0639  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:53] cvalgorithms INFO:  eta: 23:00:03  iter: 101  total_loss: 1.649  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8244  loss: 0.8244  time: 0.4194  data_time: 0.0635  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:54] cvalgorithms INFO:  eta: 23:01:48  iter: 103  total_loss: 1.822  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9111  loss: 0.9111  time: 0.4200  data_time: 0.0646  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:55] cvalgorithms INFO:  eta: 23:05:00  iter: 105  total_loss: 1.717  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8583  loss: 0.8583  time: 0.4205  data_time: 0.0634  lr: 0.001  max_mem: 3221M
[07/05 14:56:56] cvalgorithms INFO:  eta: 23:06:34  iter: 107  total_loss: 1.649  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8244  loss: 0.8244  time: 0.4211  data_time: 0.0645  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:57] cvalgorithms INFO:  eta: 23:08:57  iter: 109  total_loss: 1.532  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7659  loss: 0.7659  time: 0.4215  data_time: 0.0648  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:58] cvalgorithms INFO:  eta: 23:11:45  iter: 111  total_loss: 1.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7998  loss: 0.7998  time: 0.4222  data_time: 0.0648  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:59] cvalgorithms INFO:  eta: 23:13:57  iter: 113  total_loss: 1.803  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9013  loss: 0.9013  time: 0.4229  data_time: 0.0654  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:00] cvalgorithms INFO:  eta: 23:15:50  iter: 115  total_loss: 1.931  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9653  loss: 0.9653  time: 0.4235  data_time: 0.0658  lr: 0.001  max_mem: 3221M
[07/05 14:57:01] cvalgorithms INFO:  eta: 23:15:59  iter: 117  total_loss: 1.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9851  loss: 0.9851  time: 0.4238  data_time: 0.0653  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:01] cvalgorithms INFO:  eta: 23:19:41  iter: 119  total_loss: 1.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9851  loss: 0.9851  time: 0.4243  data_time: 0.0648  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:02] cvalgorithms INFO:  eta: 23:23:26  iter: 121  total_loss: 1.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9851  loss: 0.9851  time: 0.4247  data_time: 0.0655  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:03] cvalgorithms INFO:  eta: 23:23:39  iter: 123  total_loss: 1.803  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9013  loss: 0.9013  time: 0.4252  data_time: 0.0650  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:04] cvalgorithms INFO:  eta: 23:23:58  iter: 125  total_loss: 1.912  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9559  loss: 0.9559  time: 0.4258  data_time: 0.0667  lr: 0.001  max_mem: 3221M
[07/05 14:57:05] cvalgorithms INFO:  eta: 23:24:17  iter: 127  total_loss: 1.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9851  loss: 0.9851  time: 0.4263  data_time: 0.0669  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:06] cvalgorithms INFO:  eta: 23:24:33  iter: 129  total_loss: 2.184  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.092  loss: 1.092  time: 0.4267  data_time: 0.0674  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:07] cvalgorithms INFO:  eta: 23:25:53  iter: 131  total_loss: 1.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9851  loss: 0.9851  time: 0.4272  data_time: 0.0681  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:08] cvalgorithms INFO:  eta: 23:31:23  iter: 133  total_loss: 2.071  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.035  loss: 1.035  time: 0.4277  data_time: 0.0680  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:09] cvalgorithms INFO:  eta: 23:36:49  iter: 135  total_loss: 1.422  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7109  loss: 0.7109  time: 0.4282  data_time: 0.0684  lr: 0.001  max_mem: 3221M
[07/05 14:57:10] cvalgorithms INFO:  eta: 23:39:44  iter: 137  total_loss: 0.8319  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.416  loss: 0.416  time: 0.4286  data_time: 0.0693  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:11] cvalgorithms INFO:  eta: 23:47:20  iter: 139  total_loss: 0.7416  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.3708  loss: 0.3708  time: 0.4288  data_time: 0.0694  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:11] cvalgorithms INFO:  eta: 23:53:26  iter: 141  total_loss: 0.7416  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.3708  loss: 0.3708  time: 0.4292  data_time: 0.0689  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:12] cvalgorithms INFO:  eta: 23:57:25  iter: 143  total_loss: 0.9877  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4938  loss: 0.4938  time: 0.4297  data_time: 0.0701  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:13] cvalgorithms INFO:  eta: 1 day, 0:02:11  iter: 145  total_loss: 0.9877  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4938  loss: 0.4938  time: 0.4300  data_time: 0.0688  lr: 0.001  max_mem: 3221M
[07/05 14:57:14] cvalgorithms INFO:  eta: 1 day, 0:03:44  iter: 147  total_loss: 0.7543  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.3772  loss: 0.3772  time: 0.4304  data_time: 0.0684  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:15] cvalgorithms INFO:  eta: 1 day, 0:04:37  iter: 149  total_loss: 0.6161  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.308  loss: 0.308  time: 0.4308  data_time: 0.0682  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:16] cvalgorithms INFO:  eta: 1 day, 0:05:44  iter: 151  total_loss: 0.772  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.386  loss: 0.386  time: 0.4311  data_time: 0.0674  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:17] cvalgorithms INFO:  eta: 1 day, 0:07:14  iter: 153  total_loss: 0.9041  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4521  loss: 0.4521  time: 0.4317  data_time: 0.0688  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:18] cvalgorithms INFO:  eta: 1 day, 0:08:33  iter: 155  total_loss: 0.9041  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4521  loss: 0.4521  time: 0.4321  data_time: 0.0689  lr: 0.001  max_mem: 3221M
[07/05 14:57:19] cvalgorithms INFO:  eta: 1 day, 0:09:26  iter: 157  total_loss: 0.976  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.488  loss: 0.488  time: 0.4325  data_time: 0.0700  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:20] cvalgorithms INFO:  eta: 1 day, 0:10:11  iter: 159  total_loss: 0.9812  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4906  loss: 0.4906  time: 0.4328  data_time: 0.0705  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:21] cvalgorithms INFO:  eta: 1 day, 0:11:24  iter: 161  total_loss: 0.9283  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4641  loss: 0.4641  time: 0.4331  data_time: 0.0705  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:22] cvalgorithms INFO:  eta: 1 day, 0:15:27  iter: 163  total_loss: 0.9088  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4544  loss: 0.4544  time: 0.4333  data_time: 0.0699  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:23] cvalgorithms INFO:  eta: 1 day, 0:19:21  iter: 165  total_loss: 0.9088  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4544  loss: 0.4544  time: 0.4337  data_time: 0.0713  lr: 0.001  max_mem: 3221M
[07/05 14:57:24] cvalgorithms INFO:  eta: 1 day, 0:20:51  iter: 167  total_loss: 0.9812  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4906  loss: 0.4906  time: 0.4340  data_time: 0.0719  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:24] cvalgorithms INFO:  eta: 1 day, 0:22:34  iter: 169  total_loss: 1.262  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6311  loss: 0.6311  time: 0.4343  data_time: 0.0719  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:25] cvalgorithms INFO:  eta: 1 day, 0:23:35  iter: 171  total_loss: 1.262  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6311  loss: 0.6311  time: 0.4345  data_time: 0.0717  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:26] cvalgorithms INFO:  eta: 1 day, 0:25:04  iter: 173  total_loss: 1.013  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5063  loss: 0.5063  time: 0.4347  data_time: 0.0698  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:27] cvalgorithms INFO:  eta: 1 day, 0:27:51  iter: 175  total_loss: 0.914  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.457  loss: 0.457  time: 0.4349  data_time: 0.0693  lr: 0.001  max_mem: 3221M
[07/05 14:57:28] cvalgorithms INFO:  eta: 1 day, 0:30:18  iter: 177  total_loss: 0.8884  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4442  loss: 0.4442  time: 0.4351  data_time: 0.0678  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:29] cvalgorithms INFO:  eta: 1 day, 0:31:17  iter: 179  total_loss: 0.7602  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.3801  loss: 0.3801  time: 0.4354  data_time: 0.0682  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:30] cvalgorithms INFO:  eta: 1 day, 0:32:10  iter: 181  total_loss: 0.5918  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.2959  loss: 0.2959  time: 0.4357  data_time: 0.0683  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:31] cvalgorithms INFO:  eta: 1 day, 0:33:40  iter: 183  total_loss: 0.5797  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.2898  loss: 0.2898  time: 0.4360  data_time: 0.0684  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:32] cvalgorithms INFO:  eta: 1 day, 0:34:56  iter: 185  total_loss: 0.5595  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.2797  loss: 0.2797  time: 0.4364  data_time: 0.0676  lr: 0.001  max_mem: 3221M
[07/05 14:57:33] cvalgorithms INFO:  eta: 1 day, 0:37:24  iter: 187  total_loss: 0.5595  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.2797  loss: 0.2797  time: 0.4367  data_time: 0.0674  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:34] cvalgorithms INFO:  eta: 1 day, 0:40:10  iter: 189  total_loss: 0.5506  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.2753  loss: 0.2753  time: 0.4368  data_time: 0.0672  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:35] cvalgorithms INFO:  eta: 1 day, 0:41:35  iter: 191  total_loss: 0.5506  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.2753  loss: 0.2753  time: 0.4371  data_time: 0.0676  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:36] cvalgorithms INFO:  eta: 1 day, 0:43:21  iter: 193  total_loss: 0.5761  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.288  loss: 0.288  time: 0.4376  data_time: 0.0703  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:37] cvalgorithms INFO:  eta: 1 day, 0:44:38  iter: 195  total_loss: 0.7816  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.3908  loss: 0.3908  time: 0.4378  data_time: 0.0709  lr: 0.001  max_mem: 3221M
[07/05 14:57:37] cvalgorithms INFO:  eta: 1 day, 0:46:16  iter: 197  total_loss: 1.492  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7461  loss: 0.7461  time: 0.4380  data_time: 0.0715  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:38] cvalgorithms INFO:  eta: 1 day, 0:48:27  iter: 199  total_loss: 1.848  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.924  loss: 0.924  time: 0.4382  data_time: 0.0713  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:39] cvalgorithms INFO:  eta: 1 day, 0:49:10  iter: 201  total_loss: 1.995  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9974  loss: 0.9974  time: 0.4383  data_time: 0.0708  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:40] cvalgorithms INFO:  eta: 1 day, 0:49:46  iter: 203  total_loss: 1.848  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.924  loss: 0.924  time: 0.4385  data_time: 0.0695  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:41] cvalgorithms INFO:  eta: 1 day, 0:49:45  iter: 205  total_loss: 1.995  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9974  loss: 0.9974  time: 0.4386  data_time: 0.0690  lr: 0.001  max_mem: 3221M
[07/05 14:57:42] cvalgorithms INFO:  eta: 1 day, 0:50:27  iter: 207  total_loss: 1.848  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.924  loss: 0.924  time: 0.4388  data_time: 0.0690  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:43] cvalgorithms INFO:  eta: 1 day, 0:50:54  iter: 209  total_loss: 1.995  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9974  loss: 0.9974  time: 0.4390  data_time: 0.0692  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:44] cvalgorithms INFO:  eta: 1 day, 0:51:14  iter: 211  total_loss: 2.009  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.005  loss: 1.005  time: 0.4394  data_time: 0.0698  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:45] cvalgorithms INFO:  eta: 1 day, 0:51:33  iter: 213  total_loss: 1.847  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9235  loss: 0.9235  time: 0.4397  data_time: 0.0678  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:46] cvalgorithms INFO:  eta: 1 day, 0:51:32  iter: 215  total_loss: 1.688  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.844  loss: 0.844  time: 0.4399  data_time: 0.0679  lr: 0.001  max_mem: 3221M
[07/05 14:57:47] cvalgorithms INFO:  eta: 1 day, 0:51:53  iter: 217  total_loss: 1.358  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6791  loss: 0.6791  time: 0.4402  data_time: 0.0685  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:48] cvalgorithms INFO:  eta: 1 day, 0:51:58  iter: 219  total_loss: 1.358  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6791  loss: 0.6791  time: 0.4404  data_time: 0.0681  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:49] cvalgorithms INFO:  eta: 1 day, 0:52:04  iter: 221  total_loss: 1.314  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6569  loss: 0.6569  time: 0.4407  data_time: 0.0698  lr: 0.00090451  max_mem: 3221M
[07/05 15:55:36] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 15:55:36] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 15:56:05] cvalgorithms INFO: Starting training from iteration 0
[07/05 15:56:09] cvalgorithms INFO:  iter: 1  total_loss: 180.8  decode.loss_seg: 0.0004736  aux_0.loss: -8.928e-07  cnt.cnt_loss: 90.38  loss: 90.38  data_time: 0.0535  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:09] cvalgorithms INFO:  eta: 19:34:01  iter: 3  total_loss: 124.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 62.4  loss: 62.4  time: 0.3522  data_time: 0.0293  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:10] cvalgorithms INFO:  eta: 19:34:00  iter: 5  total_loss: 87.05  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.53  loss: 43.53  time: 0.3521  data_time: 0.0212  lr: 0.001  max_mem: 3221M
[07/05 15:56:11] cvalgorithms INFO:  eta: 19:34:00  iter: 7  total_loss: 87.05  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.53  loss: 43.53  time: 0.3520  data_time: 0.0170  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:12] cvalgorithms INFO:  eta: 19:32:51  iter: 9  total_loss: 87.05  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.53  loss: 43.53  time: 0.3516  data_time: 0.0145  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:12] cvalgorithms INFO:  eta: 19:33:30  iter: 11  total_loss: 75.08  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.54  loss: 37.54  time: 0.3518  data_time: 0.0128  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:13] cvalgorithms INFO:  eta: 19:33:30  iter: 13  total_loss: 62.39  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 31.19  loss: 31.19  time: 0.3517  data_time: 0.0115  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:14] cvalgorithms INFO:  eta: 19:33:32  iter: 15  total_loss: 49.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 24.6  loss: 24.6  time: 0.3518  data_time: 0.0106  lr: 0.001  max_mem: 3221M
[07/05 15:56:14] cvalgorithms INFO:  eta: 19:33:56  iter: 17  total_loss: 45.06  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 22.53  loss: 22.53  time: 0.3524  data_time: 0.0099  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:15] cvalgorithms INFO:  eta: 19:34:11  iter: 19  total_loss: 41.33  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 20.67  loss: 20.67  time: 0.3526  data_time: 0.0094  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:16] cvalgorithms INFO:  eta: 19:34:16  iter: 21  total_loss: 32.46  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.23  loss: 16.23  time: 0.3527  data_time: 0.0045  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:17] cvalgorithms INFO:  eta: 19:34:15  iter: 23  total_loss: 25.34  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.67  loss: 12.67  time: 0.3527  data_time: 0.0044  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:17] cvalgorithms INFO:  eta: 19:34:15  iter: 25  total_loss: 22.69  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 11.34  loss: 11.34  time: 0.3527  data_time: 0.0044  lr: 0.001  max_mem: 3221M
[07/05 15:56:18] cvalgorithms INFO:  eta: 19:34:48  iter: 27  total_loss: 19.19  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 9.597  loss: 9.597  time: 0.3529  data_time: 0.0044  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:19] cvalgorithms INFO:  eta: 19:35:36  iter: 29  total_loss: 15.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.649  loss: 7.649  time: 0.3532  data_time: 0.0044  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:19] cvalgorithms INFO:  eta: 19:35:53  iter: 31  total_loss: 13.63  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.813  loss: 6.813  time: 0.3540  data_time: 0.0044  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:20] cvalgorithms INFO:  eta: 19:36:05  iter: 33  total_loss: 10.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.07  loss: 5.07  time: 0.3543  data_time: 0.0045  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:21] cvalgorithms INFO:  eta: 19:36:19  iter: 35  total_loss: 8.058  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.029  loss: 4.029  time: 0.3546  data_time: 0.0045  lr: 0.001  max_mem: 3221M
[07/05 15:56:22] cvalgorithms INFO:  eta: 19:36:31  iter: 37  total_loss: 5.769  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.885  loss: 2.885  time: 0.3547  data_time: 0.0045  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:22] cvalgorithms INFO:  eta: 19:37:14  iter: 39  total_loss: 4.631  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.316  loss: 2.316  time: 0.3550  data_time: 0.0045  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:23] cvalgorithms INFO:  eta: 19:37:19  iter: 41  total_loss: 4.116  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.058  loss: 2.058  time: 0.3550  data_time: 0.0044  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:24] cvalgorithms INFO:  eta: 19:38:20  iter: 43  total_loss: 3.716  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.858  loss: 1.858  time: 0.3550  data_time: 0.0044  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:24] cvalgorithms INFO:  eta: 19:39:04  iter: 45  total_loss: 3.487  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.744  loss: 1.744  time: 0.3551  data_time: 0.0044  lr: 0.001  max_mem: 3221M
[07/05 15:56:25] cvalgorithms INFO:  eta: 19:39:58  iter: 47  total_loss: 3.171  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.586  loss: 1.586  time: 0.3552  data_time: 0.0044  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:26] cvalgorithms INFO:  eta: 19:40:49  iter: 49  total_loss: 3.171  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.586  loss: 1.586  time: 0.3553  data_time: 0.0044  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:27] cvalgorithms INFO:  eta: 19:41:39  iter: 51  total_loss: 3.171  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.586  loss: 1.586  time: 0.3554  data_time: 0.0044  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:27] cvalgorithms INFO:  eta: 19:42:34  iter: 53  total_loss: 3.038  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.519  loss: 1.519  time: 0.3555  data_time: 0.0044  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:28] cvalgorithms INFO:  eta: 19:43:04  iter: 55  total_loss: 2.708  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.354  loss: 1.354  time: 0.3555  data_time: 0.0045  lr: 0.001  max_mem: 3221M
[07/05 15:56:29] cvalgorithms INFO:  eta: 19:44:02  iter: 57  total_loss: 1.608  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8042  loss: 0.8042  time: 0.3557  data_time: 0.0045  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:30] cvalgorithms INFO:  eta: 19:44:58  iter: 59  total_loss: 1.608  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8042  loss: 0.8042  time: 0.3557  data_time: 0.0045  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:30] cvalgorithms INFO:  eta: 19:45:15  iter: 61  total_loss: 2.883  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.442  loss: 1.442  time: 0.3559  data_time: 0.0046  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:31] cvalgorithms INFO:  eta: 19:45:57  iter: 63  total_loss: 2.483  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.242  loss: 1.242  time: 0.3559  data_time: 0.0046  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:32] cvalgorithms INFO:  eta: 19:46:37  iter: 65  total_loss: 1.894  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9472  loss: 0.9472  time: 0.3561  data_time: 0.0046  lr: 0.001  max_mem: 3221M
[07/05 15:56:32] cvalgorithms INFO:  eta: 19:47:10  iter: 67  total_loss: 2.847  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.423  loss: 1.423  time: 0.3562  data_time: 0.0046  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:33] cvalgorithms INFO:  eta: 19:47:40  iter: 69  total_loss: 2.847  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.423  loss: 1.423  time: 0.3572  data_time: 0.0046  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:34] cvalgorithms INFO:  eta: 19:47:55  iter: 71  total_loss: 2.847  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.423  loss: 1.423  time: 0.3574  data_time: 0.0047  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:35] cvalgorithms INFO:  eta: 19:48:16  iter: 73  total_loss: 2.589  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.295  loss: 1.295  time: 0.3575  data_time: 0.0046  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:35] cvalgorithms INFO:  eta: 19:48:31  iter: 75  total_loss: 2.306  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.153  loss: 1.153  time: 0.3576  data_time: 0.0046  lr: 0.001  max_mem: 3221M
[07/05 15:56:36] cvalgorithms INFO:  eta: 19:48:41  iter: 77  total_loss: 2.589  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.295  loss: 1.295  time: 0.3577  data_time: 0.0045  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:37] cvalgorithms INFO:  eta: 19:49:08  iter: 79  total_loss: 2.306  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.153  loss: 1.153  time: 0.3582  data_time: 0.0045  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:38] cvalgorithms INFO:  eta: 19:49:52  iter: 81  total_loss: 2.306  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.153  loss: 1.153  time: 0.3586  data_time: 0.0045  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:38] cvalgorithms INFO:  eta: 19:50:34  iter: 83  total_loss: 2.122  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.061  loss: 1.061  time: 0.3590  data_time: 0.0045  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:39] cvalgorithms INFO:  eta: 19:50:57  iter: 85  total_loss: 2.122  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.061  loss: 1.061  time: 0.3596  data_time: 0.0046  lr: 0.001  max_mem: 3221M
[07/05 15:56:40] cvalgorithms INFO:  eta: 19:51:04  iter: 87  total_loss: 1.793  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8967  loss: 0.8967  time: 0.3601  data_time: 0.0047  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:41] cvalgorithms INFO:  eta: 19:51:39  iter: 89  total_loss: 1.156  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5781  loss: 0.5781  time: 0.3606  data_time: 0.0047  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:41] cvalgorithms INFO:  eta: 19:52:08  iter: 91  total_loss: 1.156  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5781  loss: 0.5781  time: 0.3611  data_time: 0.0047  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:42] cvalgorithms INFO:  eta: 19:52:33  iter: 93  total_loss: 1.483  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7414  loss: 0.7414  time: 0.3614  data_time: 0.0048  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:43] cvalgorithms INFO:  eta: 19:53:03  iter: 95  total_loss: 1.741  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8703  loss: 0.8703  time: 0.3622  data_time: 0.0048  lr: 0.001  max_mem: 3221M
[07/05 15:56:44] cvalgorithms INFO:  eta: 19:53:20  iter: 97  total_loss: 1.799  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8993  loss: 0.8993  time: 0.3626  data_time: 0.0048  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:45] cvalgorithms INFO:  eta: 19:53:32  iter: 99  total_loss: 1.782  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.891  loss: 0.891  time: 0.3628  data_time: 0.0048  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:45] cvalgorithms INFO:  eta: 19:53:40  iter: 101  total_loss: 1.469  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7343  loss: 0.7343  time: 0.3631  data_time: 0.0048  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:46] cvalgorithms INFO:  eta: 19:54:05  iter: 103  total_loss: 1.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9199  loss: 0.9199  time: 0.3635  data_time: 0.0049  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:47] cvalgorithms INFO:  eta: 19:54:25  iter: 105  total_loss: 1.853  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9265  loss: 0.9265  time: 0.3638  data_time: 0.0047  lr: 0.001  max_mem: 3221M
[07/05 15:56:48] cvalgorithms INFO:  eta: 19:54:54  iter: 107  total_loss: 1.941  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9704  loss: 0.9704  time: 0.3642  data_time: 0.0048  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:48] cvalgorithms INFO:  eta: 19:55:44  iter: 109  total_loss: 1.941  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9704  loss: 0.9704  time: 0.3646  data_time: 0.0047  lr: 9.5492e-05  max_mem: 3221M
[07/05 16:11:10] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 16:11:10] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 16:13:12] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 16:13:12] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 16:14:43] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 16:14:43] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 16:16:10] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 16:16:10] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 16:17:21] cvalgorithms INFO: Starting training from iteration 0
[07/05 16:17:24] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 114, in after_step
    next_epoch = self.trainer.epoch + 1
AttributeError: 'TrainerContainer' object has no attribute 'epoch'
[07/05 16:17:24] cvalgorithms INFO:  iter: 0  total_loss: 139.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 69.76  loss: 69.76  data_time: 0.0119  lr: 0.001  max_mem: 3221M
[07/06 11:05:06] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 11:05:07] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 11:05:39] cvalgorithms INFO: Starting training from iteration 0
[07/06 11:05:43] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 147, in after_step
    if self._period > 0 and next_iter % self._period == 0:
TypeError: '>' not supported between instances of 'Config' and 'int'
[07/06 11:05:43] cvalgorithms INFO:  iter: 0  total_loss: 420  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 210  loss: 210  data_time: 0.0642  lr: 0.001  max_mem: 3221M
[07/06 11:21:36] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 11:21:36] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 11:22:04] cvalgorithms INFO: Starting training from iteration 0
[07/06 13:04:51] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 13:04:51] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 13:05:21] cvalgorithms INFO: Starting training from iteration 0
[07/06 13:12:37] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 13:12:37] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 13:13:07] cvalgorithms INFO: Starting training from iteration 0
[07/06 13:13:34] cvalgorithms INFO:  iter: 1  total_loss: 207.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 103.7  loss: 103.7  data_time: 0.0301  lr: 0.00090451  max_mem: 3221M
[07/06 13:13:37] cvalgorithms INFO:  eta: 0:00:48  iter: 3  total_loss: 202.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 101.3  loss: 101.3  time: 0.5032  data_time: 0.0177  lr: 0.00034549  max_mem: 3221M
[07/06 13:13:39] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 116.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 58.2  loss: 58.2  time: 0.4324  data_time: 0.0136  lr: 0.001  max_mem: 3221M
[07/06 13:13:41] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 116.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 58.06  loss: 58.06  time: 0.4079  data_time: 0.0115  lr: 0.00065451  max_mem: 3221M
[07/06 13:13:42] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 84.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 42.37  loss: 42.37  time: 0.3976  data_time: 0.0101  lr: 9.5492e-05  max_mem: 3221M
[07/06 13:13:44] cvalgorithms INFO:  eta: 0:00:32  iter: 11  total_loss: 82.26  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.13  loss: 41.13  time: 0.3938  data_time: 0.0093  lr: 0.00090451  max_mem: 3221M
[07/06 13:17:33] cvalgorithms INFO:  eta: 0:00:31  iter: 13  total_loss: 73.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 36.57  loss: 36.57  time: 0.3880  data_time: 0.0087  lr: 0.00034549  max_mem: 3221M
[07/06 13:22:15] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 13:22:15] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 13:22:43] cvalgorithms INFO: Starting training from iteration 0
[07/06 13:23:05] cvalgorithms INFO:  iter: 1  total_loss: 435.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 217.9  loss: 217.9  data_time: 0.0315  lr: 0.00090451  max_mem: 3221M
[07/06 13:23:06] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 252.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 126.2  loss: 126.2  time: 0.3554  data_time: 0.0179  lr: 0.00034549  max_mem: 3221M
[07/06 13:23:07] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 204.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 102.1  loss: 102.1  time: 0.3578  data_time: 0.0136  lr: 0.001  max_mem: 3221M
[07/06 13:23:08] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 160  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 80.02  loss: 80.02  time: 0.3581  data_time: 0.0114  lr: 0.00065451  max_mem: 3221M
[07/06 13:23:08] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 160  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 80.02  loss: 80.02  time: 0.3578  data_time: 0.0100  lr: 9.5492e-05  max_mem: 3221M
[07/06 13:23:09] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 114.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 57.44  loss: 57.44  time: 0.3577  data_time: 0.0090  lr: 0.00090451  max_mem: 3221M
[07/06 13:23:10] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 77.22  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 38.61  loss: 38.61  time: 0.3575  data_time: 0.0083  lr: 0.00034549  max_mem: 3221M
[07/06 13:23:11] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 73.77  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 36.88  loss: 36.88  time: 0.3574  data_time: 0.0079  lr: 0.001  max_mem: 3221M
[07/06 13:23:11] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 68.42  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.21  loss: 34.21  time: 0.3574  data_time: 0.0075  lr: 0.00065451  max_mem: 3221M
[07/06 13:23:20] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 89, in test_and_save_results
    self._last_eval_results = self._eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 199, in _eval
    bar = ProgressBar(len(self.val_dataloader))
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\utils\data\dataloader.py", line 391, in __len__
    length = self._IterableDataset_len_called = len(self.dataset)  # type: ignore
  File "C:\Users\user1\PycharmProjects\cvalgorithms\datasets\builder.py", line 71, in __len__
    return len(self.sampler)
TypeError: object of type 'TrainingSampler' has no len()
[07/06 13:24:05] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 13:24:05] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 13:24:35] cvalgorithms INFO: Starting training from iteration 0
[07/06 13:24:38] cvalgorithms INFO:  iter: 1  total_loss: 298.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 149.4  loss: 149.4  data_time: 0.0354  lr: 0.00090451  max_mem: 3221M
[07/06 13:24:39] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 130.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 65.33  loss: 65.33  time: 0.3604  data_time: 0.0199  lr: 0.00034549  max_mem: 3221M
[07/06 13:24:40] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 155.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 77.6  loss: 77.6  time: 0.3582  data_time: 0.0147  lr: 0.001  max_mem: 3221M
[07/06 13:24:40] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 155.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 77.6  loss: 77.6  time: 0.3585  data_time: 0.0121  lr: 0.00065451  max_mem: 3221M
[07/06 13:24:41] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 126.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 63.41  loss: 63.41  time: 0.3585  data_time: 0.0106  lr: 9.5492e-05  max_mem: 3221M
[07/06 13:24:42] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 126.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 63.41  loss: 63.41  time: 0.3585  data_time: 0.0095  lr: 0.00090451  max_mem: 3221M
[07/06 13:24:43] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 79.64  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.82  loss: 39.82  time: 0.3584  data_time: 0.0088  lr: 0.00034549  max_mem: 3221M
[07/06 13:24:43] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 59.24  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 29.62  loss: 29.62  time: 0.3584  data_time: 0.0082  lr: 0.001  max_mem: 3221M
[07/06 13:24:44] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 51.41  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 25.71  loss: 25.71  time: 0.3585  data_time: 0.0078  lr: 0.00065451  max_mem: 3221M
[07/06 13:45:40] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 13:45:40] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 13:46:08] cvalgorithms INFO: Starting training from iteration 0
[07/06 13:46:12] cvalgorithms INFO:  iter: 1  total_loss: 385.3  decode.loss_seg: -1.164e-07  aux_0.loss: 0  cnt.cnt_loss: 192.6  loss: 192.6  data_time: 0.0359  lr: 0.00090451  max_mem: 3221M
[07/06 13:46:12] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 334.5  decode.loss_seg: -1.164e-07  aux_0.loss: 0  cnt.cnt_loss: 167.3  loss: 167.3  time: 0.3595  data_time: 0.0202  lr: 0.00034549  max_mem: 3221M
[07/06 13:46:13] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 199.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 99.93  loss: 99.93  time: 0.3579  data_time: 0.0150  lr: 0.001  max_mem: 3221M
[07/06 13:46:14] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 189.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 94.59  loss: 94.59  time: 0.3571  data_time: 0.0123  lr: 0.00065451  max_mem: 3221M
[07/06 13:46:14] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 147.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 73.55  loss: 73.55  time: 0.3570  data_time: 0.0107  lr: 9.5492e-05  max_mem: 3221M
[07/06 13:46:15] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 118.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 59.08  loss: 59.08  time: 0.3575  data_time: 0.0096  lr: 0.00090451  max_mem: 3221M
[07/06 13:46:16] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 81.55  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 40.78  loss: 40.78  time: 0.3580  data_time: 0.0089  lr: 0.00034549  max_mem: 3221M
[07/06 13:46:17] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 79.15  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.58  loss: 39.58  time: 0.3583  data_time: 0.0084  lr: 0.001  max_mem: 3221M
[07/06 13:46:17] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 64.71  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.35  loss: 32.35  time: 0.3589  data_time: 0.0079  lr: 0.00065451  max_mem: 3221M
[07/06 13:47:41] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 89, in test_and_save_results
    self._last_eval_results = self._eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 203, in _eval
    _img, _ground_truth = data['images_collect']['img_']
KeyError: 'img_'
[07/06 13:47:41] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 58.37  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 29.18  loss: 29.18  time: 0.3595  data_time: 0.0076  lr: 9.5492e-05  max_mem: 3221M
[07/06 13:48:26] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 13:48:26] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 13:48:56] cvalgorithms INFO: Starting training from iteration 0
[07/06 13:48:59] cvalgorithms INFO:  iter: 1  total_loss: 80.65  decode.loss_seg: -0.007989  aux_0.loss: 3.926e-06  cnt.cnt_loss: 40.33  loss: 40.33  data_time: 0.0545  lr: 0.00090451  max_mem: 3221M
[07/06 13:49:00] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 80.65  decode.loss_seg: 0  aux_0.loss: 8.793e-08  cnt.cnt_loss: 40.33  loss: 40.33  time: 0.3614  data_time: 0.0295  lr: 0.00034549  max_mem: 3221M
[07/06 13:49:01] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 87.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.58  loss: 43.57  time: 0.3625  data_time: 0.0213  lr: 0.001  max_mem: 3221M
[07/06 13:49:02] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 87.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.58  loss: 43.57  time: 0.3626  data_time: 0.0172  lr: 0.00065451  max_mem: 3221M
[07/06 13:49:02] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 84.76  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 42.39  loss: 42.38  time: 0.3640  data_time: 0.0146  lr: 9.5492e-05  max_mem: 3221M
[07/06 13:49:03] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 84.76  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 42.39  loss: 42.38  time: 0.3634  data_time: 0.0129  lr: 0.00090451  max_mem: 3221M
[07/06 13:49:04] cvalgorithms INFO:  eta: 0:00:31  iter: 13  total_loss: 82.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.05  loss: 41.05  time: 0.3652  data_time: 0.0118  lr: 0.00034549  max_mem: 3221M
[07/06 13:49:05] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 77.99  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 38.99  loss: 38.99  time: 0.3656  data_time: 0.0110  lr: 0.001  max_mem: 3221M
[07/06 13:49:05] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 70.64  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.32  loss: 35.32  time: 0.3667  data_time: 0.0103  lr: 0.00065451  max_mem: 3221M
[07/06 14:04:36] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 14:04:36] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 14:05:08] cvalgorithms INFO: Starting training from iteration 0
[07/06 14:05:12] cvalgorithms INFO:  iter: 1  total_loss: 397.1  decode.loss_seg: 1.519e-07  aux_0.loss: -8.723e-07  cnt.cnt_loss: 198.5  loss: 198.5  data_time: 0.0411  lr: 0.00090451  max_mem: 3221M
[07/06 14:05:13] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 159.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 79.68  loss: 79.68  time: 0.3568  data_time: 0.0227  lr: 0.00034549  max_mem: 3221M
[07/06 14:05:13] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 111.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 55.57  loss: 55.57  time: 0.3582  data_time: 0.0167  lr: 0.001  max_mem: 3221M
[07/06 14:05:14] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 120  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 59.98  loss: 59.98  time: 0.3574  data_time: 0.0135  lr: 0.00065451  max_mem: 3221M
[07/06 14:05:15] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 110.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 55.05  loss: 55.05  time: 0.3580  data_time: 0.0118  lr: 9.5492e-05  max_mem: 3221M
[07/06 14:05:16] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 100.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.4  loss: 50.4  time: 0.3605  data_time: 0.0107  lr: 0.00090451  max_mem: 3221M
[07/06 14:05:16] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 93.27  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 46.64  loss: 46.64  time: 0.3621  data_time: 0.0098  lr: 0.00034549  max_mem: 3221M
[07/06 14:05:17] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 78.92  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.46  loss: 39.46  time: 0.3638  data_time: 0.0093  lr: 0.001  max_mem: 3221M
[07/06 14:05:18] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 70.19  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.09  loss: 35.09  time: 0.3641  data_time: 0.0088  lr: 0.00065451  max_mem: 3221M
[07/06 16:34:05] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 16:34:05] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 16:34:36] cvalgorithms INFO: Starting training from iteration 0
[07/06 16:34:40] cvalgorithms INFO:  iter: 1  total_loss: 271.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 135.9  loss: 135.9  data_time: 0.0344  lr: 0.00090451  max_mem: 3221M
[07/06 16:34:41] cvalgorithms INFO:  eta: 0:00:36  iter: 3  total_loss: 139.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 69.78  loss: 69.78  time: 0.3798  data_time: 0.0200  lr: 0.00034549  max_mem: 3221M
[07/06 16:34:41] cvalgorithms INFO:  eta: 0:00:35  iter: 5  total_loss: 119.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 59.62  loss: 59.62  time: 0.3720  data_time: 0.0150  lr: 0.001  max_mem: 3221M
[07/06 16:34:42] cvalgorithms INFO:  eta: 0:00:34  iter: 7  total_loss: 119.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 59.62  loss: 59.62  time: 0.3698  data_time: 0.0124  lr: 0.00065451  max_mem: 3221M
[07/06 16:34:43] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 90.67  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 45.33  loss: 45.33  time: 0.3674  data_time: 0.0108  lr: 9.5492e-05  max_mem: 3221M
[07/06 16:34:44] cvalgorithms INFO:  eta: 0:00:32  iter: 11  total_loss: 88.76  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 44.38  loss: 44.38  time: 0.3675  data_time: 0.0099  lr: 0.00090451  max_mem: 3221M
[07/06 16:34:44] cvalgorithms INFO:  eta: 0:00:31  iter: 13  total_loss: 72.88  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 36.44  loss: 36.44  time: 0.3685  data_time: 0.0092  lr: 0.00034549  max_mem: 3221M
[07/06 16:34:45] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 74.66  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.33  loss: 37.33  time: 0.3683  data_time: 0.0088  lr: 0.001  max_mem: 3221M
[07/06 16:34:46] cvalgorithms INFO:  eta: 0:00:30  iter: 17  total_loss: 72.88  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 36.44  loss: 36.44  time: 0.3681  data_time: 0.0084  lr: 0.00065451  max_mem: 3221M
[07/06 16:34:46] cvalgorithms INFO: Start inference on 216 batches
[07/06 17:54:26] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 17:54:27] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 17:54:54] cvalgorithms INFO: Starting training from iteration 0
[07/06 17:54:58] cvalgorithms INFO:  iter: 1  total_loss: 238  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 119  loss: 119  data_time: 0.0572  lr: 0.00090451  max_mem: 3221M
[07/06 17:54:59] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 142.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 71.12  loss: 71.12  time: 0.3554  data_time: 0.0312  lr: 0.00034549  max_mem: 3221M
[07/06 17:55:00] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 106.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 53.41  loss: 53.41  time: 0.3619  data_time: 0.0226  lr: 0.001  max_mem: 3221M
[07/06 17:55:00] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 67.08  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.54  loss: 33.54  time: 0.3590  data_time: 0.0181  lr: 0.00065451  max_mem: 3221M
[07/06 17:55:01] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 70.73  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.37  loss: 35.37  time: 0.3582  data_time: 0.0153  lr: 9.5492e-05  max_mem: 3221M
[07/06 17:55:02] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 54.44  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.22  loss: 27.22  time: 0.3582  data_time: 0.0136  lr: 0.00090451  max_mem: 3221M
[07/06 17:55:02] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 49.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 24.88  loss: 24.88  time: 0.3579  data_time: 0.0124  lr: 0.00034549  max_mem: 3221M
[07/06 17:55:03] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 49.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 24.88  loss: 24.88  time: 0.3574  data_time: 0.0114  lr: 0.001  max_mem: 3221M
[07/06 17:55:04] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 46.55  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.28  loss: 23.28  time: 0.3575  data_time: 0.0106  lr: 0.00065451  max_mem: 3221M
[07/06 17:55:05] cvalgorithms INFO: Start inference on 216 batches
[07/06 17:55:05] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 88, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 209, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluator)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 67, in inference_on_dataset
    evaluator.reset()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 38, in reset
    evaluator.reset()
TypeError: reset() missing 1 required positional argument: 'self'
[07/06 17:55:05] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 42.96  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 21.48  loss: 21.48  time: 0.3572  data_time: 0.0100  lr: 9.5492e-05  max_mem: 3221M
[07/06 17:56:37] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 17:56:37] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 17:57:06] cvalgorithms INFO: Starting training from iteration 0
[07/06 17:57:10] cvalgorithms INFO:  iter: 1  total_loss: 99.1  decode.loss_seg: -6.598e-09  aux_0.loss: 5.344e-07  cnt.cnt_loss: 49.55  loss: 49.55  data_time: 0.0666  lr: 0.00090451  max_mem: 3221M
[07/06 17:57:11] cvalgorithms INFO:  eta: 0:00:35  iter: 3  total_loss: 70.47  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.23  loss: 35.23  time: 0.3662  data_time: 0.0355  lr: 0.00034549  max_mem: 3221M
[07/06 17:57:12] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 70.47  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.23  loss: 35.23  time: 0.3613  data_time: 0.0252  lr: 0.001  max_mem: 3221M
[07/06 17:57:12] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 70.47  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.23  loss: 35.23  time: 0.3604  data_time: 0.0200  lr: 0.00065451  max_mem: 3221M
[07/06 17:57:13] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 47.26  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.63  loss: 23.63  time: 0.3592  data_time: 0.0168  lr: 9.5492e-05  max_mem: 3221M
[07/06 17:57:14] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 47.26  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.63  loss: 23.63  time: 0.3589  data_time: 0.0148  lr: 0.00090451  max_mem: 3221M
[07/06 17:57:14] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 28.68  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 14.34  loss: 14.34  time: 0.3585  data_time: 0.0133  lr: 0.00034549  max_mem: 3221M
[07/06 17:57:15] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 25.45  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.72  loss: 12.72  time: 0.3583  data_time: 0.0122  lr: 0.001  max_mem: 3221M
[07/06 17:57:16] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 24  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12  loss: 12  time: 0.3583  data_time: 0.0113  lr: 0.00065451  max_mem: 3221M
[07/06 17:57:17] cvalgorithms INFO: Start inference on 216 batches
[07/06 17:57:17] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 88, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 209, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluator)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 66, in inference_on_dataset
    evaluator.reset()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 37, in reset
    evaluator.reset()
TypeError: reset() missing 1 required positional argument: 'self'
[07/06 17:57:17] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 24.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.3  loss: 12.3  time: 0.3583  data_time: 0.0107  lr: 9.5492e-05  max_mem: 3221M
[07/06 17:58:09] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 17:58:09] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 17:58:39] cvalgorithms INFO: Starting training from iteration 0
[07/06 17:58:42] cvalgorithms INFO:  iter: 1  total_loss: 138.9  decode.loss_seg: -1.414e-08  aux_0.loss: 3.074e-07  cnt.cnt_loss: 69.46  loss: 69.46  data_time: 0.0685  lr: 0.00090451  max_mem: 3221M
[07/06 17:58:43] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 59.47  decode.loss_seg: -1.414e-08  aux_0.loss: 3.653e-08  cnt.cnt_loss: 29.73  loss: 29.73  time: 0.3589  data_time: 0.0364  lr: 0.00034549  max_mem: 3221M
[07/06 17:58:44] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 57.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.91  loss: 28.91  time: 0.3584  data_time: 0.0258  lr: 0.001  max_mem: 3221M
[07/06 17:58:45] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 65.91  decode.loss_seg: 0  aux_0.loss: 3.653e-08  cnt.cnt_loss: 32.95  loss: 32.95  time: 0.3584  data_time: 0.0205  lr: 0.00065451  max_mem: 3221M
[07/06 17:58:45] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 65.91  decode.loss_seg: 0  aux_0.loss: 3.653e-08  cnt.cnt_loss: 32.95  loss: 32.95  time: 0.3591  data_time: 0.0173  lr: 9.5492e-05  max_mem: 3221M
[07/06 17:58:46] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 57.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.91  loss: 28.91  time: 0.3592  data_time: 0.0152  lr: 0.00090451  max_mem: 3221M
[07/06 17:58:47] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 57.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.91  loss: 28.91  time: 0.3598  data_time: 0.0137  lr: 0.00034549  max_mem: 3221M
[07/06 17:58:48] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 57.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.91  loss: 28.91  time: 0.3618  data_time: 0.0125  lr: 0.001  max_mem: 3221M
[07/06 17:58:48] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 56.41  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.2  loss: 28.2  time: 0.3624  data_time: 0.0117  lr: 0.00065451  max_mem: 3221M
[07/06 17:58:54] cvalgorithms INFO: Start inference on 216 batches
[07/06 18:22:04] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 18:22:04] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 18:22:32] cvalgorithms INFO: Starting training from iteration 0
[07/06 18:22:36] cvalgorithms INFO:  iter: 1  total_loss: 147.3  decode.loss_seg: -0.001927  aux_0.loss: -6.447e-07  cnt.cnt_loss: 73.63  loss: 73.63  data_time: 0.0395  lr: 0.00090451  max_mem: 3221M
[07/06 18:22:37] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 87.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.9  loss: 43.9  time: 0.3514  data_time: 0.0223  lr: 0.00034549  max_mem: 3221M
[07/06 18:22:37] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 83.48  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.74  loss: 41.74  time: 0.3536  data_time: 0.0166  lr: 0.001  max_mem: 3221M
[07/06 18:22:38] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 83.48  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.74  loss: 41.74  time: 0.3534  data_time: 0.0136  lr: 0.00065451  max_mem: 3221M
[07/06 18:22:39] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 74.51  decode.loss_seg: 0  aux_0.loss: 5.809e-08  cnt.cnt_loss: 37.26  loss: 37.26  time: 0.3546  data_time: 0.0118  lr: 9.5492e-05  max_mem: 3221M
[07/06 18:22:39] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 67.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.99  loss: 33.98  time: 0.3541  data_time: 0.0106  lr: 0.00090451  max_mem: 3221M
[07/06 18:22:40] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 59.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 29.95  loss: 29.95  time: 0.3541  data_time: 0.0097  lr: 0.00034549  max_mem: 3221M
[07/06 18:22:41] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 47.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.92  loss: 23.92  time: 0.3554  data_time: 0.0091  lr: 0.001  max_mem: 3221M
[07/06 18:22:42] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 55.56  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.78  loss: 27.78  time: 0.3553  data_time: 0.0086  lr: 0.00065451  max_mem: 3221M
[07/06 18:22:46] cvalgorithms INFO: Start inference on 216 batches
[07/06 19:13:13] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 19:13:13] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 19:13:40] cvalgorithms INFO: Starting training from iteration 0
[07/06 19:13:45] cvalgorithms INFO:  iter: 1  total_loss: 238.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 119.3  loss: 119.3  data_time: 0.0849  lr: 0.00090451  max_mem: 3221M
[07/06 19:13:45] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 152.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.39  loss: 76.39  time: 0.3600  data_time: 0.0447  lr: 0.00034549  max_mem: 3221M
[07/06 19:13:46] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 84.15  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 42.07  loss: 42.07  time: 0.3601  data_time: 0.0315  lr: 0.001  max_mem: 3221M
[07/06 19:13:47] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 78.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.4  loss: 39.4  time: 0.3594  data_time: 0.0247  lr: 0.00065451  max_mem: 3221M
[07/06 19:13:47] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 54.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.35  loss: 27.35  time: 0.3587  data_time: 0.0207  lr: 9.5492e-05  max_mem: 3221M
[07/06 19:13:48] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 42.32  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 21.16  loss: 21.16  time: 0.3579  data_time: 0.0182  lr: 0.00090451  max_mem: 3221M
[07/06 19:13:49] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 54.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.35  loss: 27.35  time: 0.3577  data_time: 0.0162  lr: 0.00034549  max_mem: 3221M
[07/06 19:13:50] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 54.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.35  loss: 27.35  time: 0.3572  data_time: 0.0147  lr: 0.001  max_mem: 3221M
[07/06 19:13:50] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 54.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.35  loss: 27.35  time: 0.3570  data_time: 0.0136  lr: 0.00065451  max_mem: 3221M
[07/06 19:14:38] cvalgorithms INFO: Start inference on 216 batches
[07/06 19:15:50] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 19:15:50] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 19:16:19] cvalgorithms INFO: Starting training from iteration 0
[07/06 19:16:22] cvalgorithms INFO:  iter: 1  total_loss: 435  decode.loss_seg: 1.78e-07  aux_0.loss: -1.173e-06  cnt.cnt_loss: 217.5  loss: 217.5  data_time: 0.0502  lr: 0.00090451  max_mem: 3221M
[07/06 19:16:23] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 241.8  decode.loss_seg: 0  aux_0.loss: -3.339e-07  cnt.cnt_loss: 120.9  loss: 120.9  time: 0.3566  data_time: 0.0276  lr: 0.00034549  max_mem: 3221M
[07/06 19:16:24] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 100.7  decode.loss_seg: 0  aux_0.loss: -1.153e-07  cnt.cnt_loss: 50.35  loss: 50.35  time: 0.3579  data_time: 0.0200  lr: 0.001  max_mem: 3221M
[07/06 19:16:24] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 82.43  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.21  loss: 41.21  time: 0.3570  data_time: 0.0162  lr: 0.00065451  max_mem: 3221M
[07/06 19:16:25] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 69.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.6  loss: 34.6  time: 0.3564  data_time: 0.0139  lr: 9.5492e-05  max_mem: 3221M
[07/06 19:16:26] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 69.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.6  loss: 34.6  time: 0.3561  data_time: 0.0122  lr: 0.00090451  max_mem: 3221M
[07/06 19:16:27] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 65.46  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.73  loss: 32.73  time: 0.3559  data_time: 0.0111  lr: 0.00034549  max_mem: 3221M
[07/06 19:16:27] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 69.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.6  loss: 34.6  time: 0.3558  data_time: 0.0103  lr: 0.001  max_mem: 3221M
[07/06 19:16:28] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 66.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.05  loss: 33.05  time: 0.3563  data_time: 0.0097  lr: 0.00065451  max_mem: 3221M
[07/06 19:16:36] cvalgorithms INFO: Start inference on 216 batches
[07/06 19:16:49] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 88, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 209, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluator)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 66, in inference_on_dataset
    evaluator.reset()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 37, in reset
    evaluator.reset()
TypeError: reset() missing 1 required positional argument: 'self'
[07/06 19:16:49] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 65.46  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.73  loss: 32.73  time: 0.3563  data_time: 0.0091  lr: 9.5492e-05  max_mem: 3221M
[07/06 19:17:25] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/06 19:17:25] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/06 19:17:54] cvalgorithms INFO: Starting training from iteration 0
[07/06 19:17:58] cvalgorithms INFO:  iter: 1  total_loss: 144.8  decode.loss_seg: -4.354e-07  aux_0.loss: 0  cnt.cnt_loss: 72.42  loss: 72.42  data_time: 0.0766  lr: 0.00090451  max_mem: 3221M
[07/06 19:17:58] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 144.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.42  loss: 72.42  time: 0.3556  data_time: 0.0405  lr: 0.00034549  max_mem: 3221M
[07/06 19:17:59] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 144.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.42  loss: 72.42  time: 0.3559  data_time: 0.0285  lr: 0.001  max_mem: 3221M
[07/06 19:18:00] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 144.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.42  loss: 72.42  time: 0.3559  data_time: 0.0225  lr: 0.00065451  max_mem: 3221M
[07/06 19:18:00] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 189.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 94.63  loss: 94.63  time: 0.3563  data_time: 0.0188  lr: 9.5492e-05  max_mem: 3221M
[07/06 19:18:01] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 168.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 84.36  loss: 84.36  time: 0.3586  data_time: 0.0164  lr: 0.00090451  max_mem: 3221M
[07/06 19:18:02] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 153.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.56  loss: 76.56  time: 0.3587  data_time: 0.0148  lr: 0.00034549  max_mem: 3221M
[07/06 19:18:03] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 168.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 84.36  loss: 84.36  time: 0.3585  data_time: 0.0134  lr: 0.001  max_mem: 3221M
[07/06 19:18:03] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 153.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.56  loss: 76.56  time: 0.3586  data_time: 0.0125  lr: 0.00065451  max_mem: 3221M
[07/06 19:18:04] cvalgorithms INFO: Start inference on 216 batches
[07/07 10:29:43] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 10:29:43] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 10:30:10] cvalgorithms INFO: Starting training from iteration 0
[07/07 10:30:14] cvalgorithms INFO:  iter: 1  total_loss: 148.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 74.14  loss: 74.14  data_time: 0.0634  lr: 0.00090451  max_mem: 3221M
[07/07 10:30:14] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 198.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 99.47  loss: 99.47  time: 0.3499  data_time: 0.0339  lr: 0.00034549  max_mem: 3221M
[07/07 10:30:15] cvalgorithms INFO:  eta: 0:00:32  iter: 5  total_loss: 172.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 86.26  loss: 86.26  time: 0.3500  data_time: 0.0240  lr: 0.001  max_mem: 3221M
[07/07 10:30:16] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 129.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 64.84  loss: 64.84  time: 0.3506  data_time: 0.0192  lr: 0.00065451  max_mem: 3221M
[07/07 10:30:17] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 125.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 62.93  loss: 62.93  time: 0.3514  data_time: 0.0163  lr: 9.5492e-05  max_mem: 3221M
[07/07 10:30:17] cvalgorithms INFO:  eta: 0:00:30  iter: 11  total_loss: 125.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 62.93  loss: 62.93  time: 0.3516  data_time: 0.0144  lr: 0.00090451  max_mem: 3221M
[07/07 10:30:18] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 122  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 61.02  loss: 61.02  time: 0.3516  data_time: 0.0129  lr: 0.00034549  max_mem: 3221M
[07/07 10:30:19] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 105.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 52.81  loss: 52.81  time: 0.3517  data_time: 0.0119  lr: 0.001  max_mem: 3221M
[07/07 10:30:19] cvalgorithms INFO:  eta: 0:00:28  iter: 17  total_loss: 97.95  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 48.98  loss: 48.98  time: 0.3519  data_time: 0.0111  lr: 0.00065451  max_mem: 3221M
[07/07 10:31:39] cvalgorithms INFO: Start inference on 216 batches
[07/07 10:38:21] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 88, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 209, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluator)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 75, in inference_on_dataset
    stack.enter_context(inference_context(model))
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\contextlib.py", line 330, in enter_context
    result = _cm_type.__enter__(cm)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\contextlib.py", line 81, in __enter__
    return next(self.gen)
TypeError: 'NoneType' object is not an iterator
[07/07 10:38:21] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 76.91  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 38.46  loss: 38.46  time: 0.3519  data_time: 0.0104  lr: 9.5492e-05  max_mem: 3221M
[07/07 10:59:12] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 10:59:12] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 10:59:40] cvalgorithms INFO: Starting training from iteration 0
[07/07 10:59:44] cvalgorithms INFO:  iter: 1  total_loss: 428.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 214.3  loss: 214.3  data_time: 0.0356  lr: 0.00090451  max_mem: 3221M
[07/07 10:59:45] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 230.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 115.4  loss: 115.4  time: 0.3623  data_time: 0.0245  lr: 0.00034549  max_mem: 3221M
[07/07 10:59:46] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 244.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 122.4  loss: 122.4  time: 0.3588  data_time: 0.0180  lr: 0.001  max_mem: 3221M
[07/07 10:59:46] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 228.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 114.4  loss: 114.4  time: 0.3580  data_time: 0.0147  lr: 0.00065451  max_mem: 3221M
[07/07 10:59:47] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 214.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 107.4  loss: 107.4  time: 0.3568  data_time: 0.0126  lr: 9.5492e-05  max_mem: 3221M
[07/07 10:59:48] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 214.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 107.4  loss: 107.4  time: 0.3564  data_time: 0.0113  lr: 0.00090451  max_mem: 3221M
[07/07 10:59:49] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 155  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 77.48  loss: 77.48  time: 0.3563  data_time: 0.0103  lr: 0.00034549  max_mem: 3221M
[07/07 10:59:49] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 78.23  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.12  loss: 39.12  time: 0.3567  data_time: 0.0096  lr: 0.001  max_mem: 3221M
[07/07 10:59:50] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 54.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.07  loss: 27.07  time: 0.3571  data_time: 0.0091  lr: 0.00065451  max_mem: 3221M
[07/07 10:59:53] cvalgorithms INFO: Start inference on 216 batches
[07/07 11:09:20] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 11:09:20] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 11:09:50] cvalgorithms INFO: Starting training from iteration 0
[07/07 11:09:54] cvalgorithms INFO:  iter: 1  total_loss: 343  decode.loss_seg: 0.00135  aux_0.loss: 3.162e-06  cnt.cnt_loss: 171.5  loss: 171.5  data_time: 0.0704  lr: 0.00090451  max_mem: 3221M
[07/07 11:09:55] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 272.2  decode.loss_seg: 0  aux_0.loss: 1.089e-06  cnt.cnt_loss: 136.1  loss: 136.1  time: 0.3539  data_time: 0.0375  lr: 0.00034549  max_mem: 3221M
[07/07 11:09:56] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 224.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 112.1  loss: 112.1  time: 0.3555  data_time: 0.0265  lr: 0.001  max_mem: 3221M
[07/07 11:09:56] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 224.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 112.1  loss: 112.1  time: 0.3558  data_time: 0.0210  lr: 0.00065451  max_mem: 3221M
[07/07 11:09:57] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 146  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 73.02  loss: 73.02  time: 0.3560  data_time: 0.0177  lr: 9.5492e-05  max_mem: 3221M
[07/07 11:09:58] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 88.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 44.07  loss: 44.07  time: 0.3563  data_time: 0.0155  lr: 0.00090451  max_mem: 3221M
[07/07 11:09:58] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 75.46  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.73  loss: 37.73  time: 0.3561  data_time: 0.0139  lr: 0.00034549  max_mem: 3221M
[07/07 11:09:59] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 63.39  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 31.69  loss: 31.69  time: 0.3564  data_time: 0.0128  lr: 0.001  max_mem: 3221M
[07/07 11:10:00] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 49.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 24.95  loss: 24.95  time: 0.3573  data_time: 0.0119  lr: 0.00065451  max_mem: 3221M
[07/07 11:10:11] cvalgorithms INFO: Start inference on 216 batches
[07/07 11:14:52] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 11:14:52] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 11:15:21] cvalgorithms INFO: Starting training from iteration 0
[07/07 11:26:49] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 11:26:49] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 11:27:18] cvalgorithms INFO: Starting training from iteration 0
[07/07 11:27:22] cvalgorithms INFO:  iter: 1  total_loss: 371.6  decode.loss_seg: -0.0009106  aux_0.loss: 1.193e-06  cnt.cnt_loss: 185.8  loss: 185.8  data_time: 0.0482  lr: 0.00090451  max_mem: 3221M
[07/07 11:27:23] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 255.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 127.9  loss: 127.9  time: 0.3588  data_time: 0.0266  lr: 0.00034549  max_mem: 3221M
[07/07 11:27:24] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 159.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 79.84  loss: 79.84  time: 0.3588  data_time: 0.0193  lr: 0.001  max_mem: 3221M
[07/07 11:27:24] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 159.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 79.84  loss: 79.84  time: 0.3580  data_time: 0.0156  lr: 0.00065451  max_mem: 3221M
[07/07 11:27:25] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 122.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 61.26  loss: 61.26  time: 0.3589  data_time: 0.0134  lr: 9.5492e-05  max_mem: 3221M
[07/07 11:27:26] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 100.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.14  loss: 50.14  time: 0.3597  data_time: 0.0121  lr: 0.00090451  max_mem: 3221M
[07/07 11:27:26] cvalgorithms INFO:  eta: 0:00:31  iter: 13  total_loss: 79.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.8  loss: 39.8  time: 0.3597  data_time: 0.0111  lr: 0.00034549  max_mem: 3221M
[07/07 11:27:27] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 69.08  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.54  loss: 34.54  time: 0.3593  data_time: 0.0104  lr: 0.001  max_mem: 3221M
[07/07 11:27:28] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 67.79  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.89  loss: 33.89  time: 0.3588  data_time: 0.0097  lr: 0.00065451  max_mem: 3221M
[07/07 11:27:29] cvalgorithms INFO: Start inference on 216 batches
[07/07 11:32:22] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 11:32:22] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 11:32:52] cvalgorithms INFO: Starting training from iteration 0
[07/07 12:11:25] cvalgorithms INFO:  iter: 1  total_loss: 150.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 75.15  loss: 75.15  data_time: 1154.7110  lr: 0.00090451  max_mem: 3221M
[07/07 12:11:26] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 125.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 62.93  loss: 62.93  time: 0.3499  data_time: 577.3578  lr: 0.00034549  max_mem: 3221M
[07/07 12:11:27] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 92.85  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 46.42  loss: 46.42  time: 0.3524  data_time: 384.9067  lr: 0.001  max_mem: 3221M
[07/07 12:11:27] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 70.32  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.16  loss: 35.16  time: 0.3515  data_time: 288.6811  lr: 0.00065451  max_mem: 3221M
[07/07 12:11:28] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 70.32  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.16  loss: 35.16  time: 0.3520  data_time: 230.9458  lr: 9.5492e-05  max_mem: 3221M
[07/07 12:11:29] cvalgorithms INFO:  eta: 0:00:30  iter: 11  total_loss: 58.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 29.42  loss: 29.42  time: 0.3517  data_time: 192.4556  lr: 0.00090451  max_mem: 3221M
[07/07 12:11:30] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 47.55  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.78  loss: 23.78  time: 0.3519  data_time: 164.9625  lr: 0.00034549  max_mem: 3221M
[07/07 12:11:30] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 45.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 22.87  loss: 22.87  time: 0.3530  data_time: 144.3428  lr: 0.001  max_mem: 3221M
[07/07 12:11:31] cvalgorithms INFO:  eta: 0:00:28  iter: 17  total_loss: 35.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.6  loss: 17.6  time: 0.3542  data_time: 128.3053  lr: 0.00065451  max_mem: 3221M
[07/07 12:11:32] cvalgorithms INFO: Start inference on 216 batches
[07/07 12:28:35] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 12:28:35] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 12:29:03] cvalgorithms INFO: Starting training from iteration 0
[07/07 12:29:03] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 123, in train
    self.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 127, in run_step
    self._trainer.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 211, in run_step
    loss_dict = self.model(_img, ground_truth=_ground_truth, return_metrics=True)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 305, in forward
    metrics = self.forward_train(inputs, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 211, in forward_train
    x = self.extract_feat(inputs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 55, in extract_feat
    inputs_n, inputs_g = torch.chunk(inputs, 2, dim=1)
ValueError: not enough values to unpack (expected 2, got 1)
[07/07 12:29:03] cvalgorithms INFO:  iter: 0    lr: N/A  max_mem: 145M
[07/07 12:34:24] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 12:34:24] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 12:34:54] cvalgorithms INFO: Starting training from iteration 0
[07/07 12:37:14] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 12:37:14] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 12:37:43] cvalgorithms INFO: Starting training from iteration 0
[07/07 13:13:10] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 123, in train
    self.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 127, in run_step
    self._trainer.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 211, in run_step
    loss_dict = self.model(_img, ground_truth=_ground_truth, return_metrics=True)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 305, in forward
    metrics = self.forward_train(inputs, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 213, in forward_train
    loss_decode = self._decode_head_forward_train(x, ground_truth)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 106, in _decode_head_forward_train
    loss_decode = self.decode_head.forward_train(x, ground_truth)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\decode_heads\decode_head.py", line 197, in forward_train
    losses = self.losses(seg_logits, gt_semantic_seg)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\decode_heads\decode_head.py", line 231, in losses
    align_corners=self.align_corners)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\utils\warpper.py", line 28, in resize
    return F.interpolate(input, size, scale_factor, mode, align_corners)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\functional.py", line 3476, in interpolate
    "size shape must match input shape. " "Input is {}D, size is {}".format(dim, len(size))
ValueError: size shape must match input shape. Input is 2D, size is 1
[07/07 13:13:10] cvalgorithms INFO:  iter: 0    lr: N/A  max_mem: 3199M
[07/07 13:16:38] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 13:16:38] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 13:17:06] cvalgorithms INFO: Starting training from iteration 0
[07/07 13:19:27] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 13:19:27] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 13:19:56] cvalgorithms INFO: Starting training from iteration 0
[07/07 13:21:35] cvalgorithms INFO:  iter: 1  total_loss: 397.7  decode.loss_seg: 0.0003795  aux_0.loss: -9.253e-07  cnt.cnt_loss: 198.9  loss: 198.9  data_time: 45.8626  lr: 0.00090451  max_mem: 3221M
[07/07 13:21:35] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 199.3  decode.loss_seg: 8.243e-05  aux_0.loss: -5.912e-07  cnt.cnt_loss: 99.67  loss: 99.67  time: 0.3642  data_time: 22.9340  lr: 0.00034549  max_mem: 3221M
[07/07 13:21:36] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 148.9  decode.loss_seg: 0  aux_0.loss: -3.361e-08  cnt.cnt_loss: 74.47  loss: 74.47  time: 0.3613  data_time: 15.2910  lr: 0.001  max_mem: 3221M
[07/07 13:21:37] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 148.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 74.47  loss: 74.47  time: 0.3598  data_time: 11.4694  lr: 0.00065451  max_mem: 3221M
[07/07 13:21:37] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 160.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 80.2  loss: 80.2  time: 0.3586  data_time: 9.1765  lr: 9.5492e-05  max_mem: 3221M
[07/07 13:21:38] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 112.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 56.39  loss: 56.39  time: 0.3612  data_time: 7.6478  lr: 0.00090451  max_mem: 3221M
[07/07 13:21:39] cvalgorithms INFO:  eta: 0:00:31  iter: 13  total_loss: 97.19  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 48.6  loss: 48.6  time: 0.3618  data_time: 6.5562  lr: 0.00034549  max_mem: 3221M
[07/07 13:21:40] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 78.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.37  loss: 39.37  time: 0.3607  data_time: 5.7373  lr: 0.001  max_mem: 3221M
[07/07 13:21:40] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 68.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.25  loss: 34.25  time: 0.3599  data_time: 5.1003  lr: 0.00065451  max_mem: 3221M
[07/07 13:21:41] cvalgorithms INFO: Start inference on 216 batches
[07/07 13:22:09] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 88, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 165, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluator)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 89, in inference_on_dataset
    _img, _ground_truth = inputs['image'], inputs['ground_truth']
TypeError: list indices must be integers or slices, not str
[07/07 13:22:09] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 56.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.37  loss: 28.37  time: 0.3594  data_time: 4.5907  lr: 9.5492e-05  max_mem: 3221M
[07/07 13:23:02] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 13:23:02] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 13:23:32] cvalgorithms INFO: Starting training from iteration 0
[07/07 13:23:35] cvalgorithms INFO:  iter: 1  total_loss: 476.6  decode.loss_seg: -1.915e-07  aux_0.loss: 0  cnt.cnt_loss: 238.3  loss: 238.3  data_time: 0.0289  lr: 0.00090451  max_mem: 3221M
[07/07 13:23:36] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 202.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 101.1  loss: 101.1  time: 0.3589  data_time: 0.0166  lr: 0.00034549  max_mem: 3221M
[07/07 13:23:37] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 115.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 57.79  loss: 57.79  time: 0.3574  data_time: 0.0126  lr: 0.001  max_mem: 3221M
[07/07 13:23:37] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 115.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 57.79  loss: 57.79  time: 0.3601  data_time: 0.0105  lr: 0.00065451  max_mem: 3221M
[07/07 13:23:38] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 115.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 57.79  loss: 57.79  time: 0.3596  data_time: 0.0093  lr: 9.5492e-05  max_mem: 3221M
[07/07 13:23:39] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 62.08  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 31.04  loss: 31.04  time: 0.3594  data_time: 0.0085  lr: 0.00090451  max_mem: 3221M
[07/07 13:23:40] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 62.08  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 31.04  loss: 31.04  time: 0.3587  data_time: 0.0079  lr: 0.00034549  max_mem: 3221M
[07/07 13:23:40] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 48.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 24.37  loss: 24.37  time: 0.3588  data_time: 0.0075  lr: 0.001  max_mem: 3221M
[07/07 13:23:41] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 58.77  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 29.39  loss: 29.39  time: 0.3587  data_time: 0.0072  lr: 0.00065451  max_mem: 3221M
[07/07 13:23:42] cvalgorithms INFO: Start inference on 216 batches
[07/07 13:29:04] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 13:29:04] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 13:29:32] cvalgorithms INFO: Starting training from iteration 0
[07/07 13:29:36] cvalgorithms INFO:  iter: 1  total_loss: 273.8  decode.loss_seg: 0.0007726  aux_0.loss: 2.656e-05  cnt.cnt_loss: 136.9  loss: 136.9  data_time: 0.0638  lr: 0.00090451  max_mem: 3221M
[07/07 13:29:36] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 273.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 136.9  loss: 136.9  time: 0.3525  data_time: 0.0340  lr: 0.00034549  max_mem: 3221M
[07/07 13:29:37] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 202.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 101.2  loss: 101.2  time: 0.3520  data_time: 0.0242  lr: 0.001  max_mem: 3221M
[07/07 13:29:38] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 154  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.99  loss: 76.99  time: 0.3527  data_time: 0.0192  lr: 0.00065451  max_mem: 3221M
[07/07 13:29:38] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 151.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 75.6  loss: 75.6  time: 0.3536  data_time: 0.0162  lr: 9.5492e-05  max_mem: 3221M
[07/07 13:29:39] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 144.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.4  loss: 72.4  time: 0.3537  data_time: 0.0143  lr: 0.00090451  max_mem: 3221M
[07/07 13:29:40] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 128.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 64.11  loss: 64.11  time: 0.3541  data_time: 0.0128  lr: 0.00034549  max_mem: 3221M
[07/07 13:29:41] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 108.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 54.27  loss: 54.27  time: 0.3544  data_time: 0.0118  lr: 0.001  max_mem: 3221M
[07/07 13:29:41] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 90.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 45.37  loss: 45.37  time: 0.3559  data_time: 0.0110  lr: 0.00065451  max_mem: 3221M
[07/07 13:29:42] cvalgorithms INFO: Start inference on 216 batches
[07/07 13:30:10] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 88, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 165, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluator)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 95, in inference_on_dataset
    for key, value in _ground_truth.items():
KeyError: 'ground_truth'
[07/07 13:30:10] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 71.48  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.74  loss: 35.74  time: 0.3574  data_time: 0.0104  lr: 9.5492e-05  max_mem: 3221M
[07/07 13:31:01] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 13:31:01] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 13:31:30] cvalgorithms INFO: Starting training from iteration 0
[07/07 13:31:34] cvalgorithms INFO:  iter: 1  total_loss: 362.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 181.4  loss: 181.4  data_time: 0.0244  lr: 0.00090451  max_mem: 3221M
[07/07 13:31:35] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 320.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 160.3  loss: 160.3  time: 0.3587  data_time: 0.0143  lr: 0.00034549  max_mem: 3221M
[07/07 13:31:35] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 231.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 115.7  loss: 115.7  time: 0.3574  data_time: 0.0109  lr: 0.001  max_mem: 3221M
[07/07 13:31:36] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 144  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.02  loss: 72.02  time: 0.3577  data_time: 0.0092  lr: 0.00065451  max_mem: 3221M
[07/07 13:31:37] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 103  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 51.51  loss: 51.51  time: 0.3577  data_time: 0.0082  lr: 9.5492e-05  max_mem: 3221M
[07/07 13:31:37] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 88.19  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 44.09  loss: 44.09  time: 0.3584  data_time: 0.0075  lr: 0.00090451  max_mem: 3221M
[07/07 13:31:38] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 72.19  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 36.1  loss: 36.1  time: 0.3588  data_time: 0.0072  lr: 0.00034549  max_mem: 3221M
[07/07 13:31:39] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 53.89  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 26.95  loss: 26.95  time: 0.3587  data_time: 0.0068  lr: 0.001  max_mem: 3221M
[07/07 13:31:40] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 50.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 25.4  loss: 25.4  time: 0.3588  data_time: 0.0066  lr: 0.00065451  max_mem: 3221M
[07/07 13:31:40] cvalgorithms INFO: Start inference on 216 batches
[07/07 13:32:10] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 88, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 165, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluator)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 95, in inference_on_dataset
    for key, value in _ground_truth.items():
KeyError: 'ground_truth'
[07/07 13:32:10] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 50.23  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 25.12  loss: 25.12  time: 0.3584  data_time: 0.0063  lr: 9.5492e-05  max_mem: 3221M
[07/07 13:33:16] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 13:33:16] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 13:33:48] cvalgorithms INFO: Starting training from iteration 0
[07/07 13:33:52] cvalgorithms INFO:  iter: 1  total_loss: 303.9  decode.loss_seg: -0.0003229  aux_0.loss: -7.727e-07  cnt.cnt_loss: 152  loss: 152  data_time: 0.0679  lr: 0.00090451  max_mem: 3221M
[07/07 13:33:53] cvalgorithms INFO:  eta: 0:00:35  iter: 3  total_loss: 240  decode.loss_seg: -9.638e-05  aux_0.loss: -7.548e-07  cnt.cnt_loss: 120  loss: 120  time: 0.3670  data_time: 0.0367  lr: 0.00034549  max_mem: 3221M
[07/07 13:33:54] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 179.2  decode.loss_seg: 0  aux_0.loss: -1.128e-07  cnt.cnt_loss: 89.6  loss: 89.6  time: 0.3653  data_time: 0.0260  lr: 0.001  max_mem: 3221M
[07/07 13:33:55] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 240  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 120  loss: 120  time: 0.3678  data_time: 0.0210  lr: 0.00065451  max_mem: 3221M
[07/07 13:33:55] cvalgorithms INFO:  eta: 0:00:33  iter: 9  total_loss: 179.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 89.6  loss: 89.6  time: 0.3694  data_time: 0.0178  lr: 9.5492e-05  max_mem: 3221M
[07/07 13:33:56] cvalgorithms INFO:  eta: 0:00:32  iter: 11  total_loss: 137  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 68.51  loss: 68.51  time: 0.3712  data_time: 0.0158  lr: 0.00090451  max_mem: 3221M
[07/07 13:33:57] cvalgorithms INFO:  eta: 0:00:32  iter: 13  total_loss: 128.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 64.33  loss: 64.33  time: 0.3775  data_time: 0.0143  lr: 0.00034549  max_mem: 3221M
[07/07 13:33:58] cvalgorithms INFO:  eta: 0:00:31  iter: 15  total_loss: 112.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 56.11  loss: 56.11  time: 0.3811  data_time: 0.0133  lr: 0.001  max_mem: 3221M
[07/07 13:33:59] cvalgorithms INFO:  eta: 0:00:30  iter: 17  total_loss: 88.31  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 44.15  loss: 44.15  time: 0.3842  data_time: 0.0123  lr: 0.00065451  max_mem: 3221M
[07/07 13:33:59] cvalgorithms INFO: Start inference on 216 batches
[07/07 13:36:54] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 13:36:54] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 13:37:23] cvalgorithms INFO: Starting training from iteration 0
[07/07 13:37:27] cvalgorithms INFO:  iter: 1  total_loss: 125.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 62.81  loss: 62.81  data_time: 0.0782  lr: 0.00090451  max_mem: 3221M
[07/07 13:37:28] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 148.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 74.21  loss: 74.21  time: 0.3555  data_time: 0.0414  lr: 0.00034549  max_mem: 3221M
[07/07 13:37:28] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 75.09  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.55  loss: 37.55  time: 0.3555  data_time: 0.0290  lr: 0.001  max_mem: 3221M
[07/07 13:37:29] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 75.09  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.55  loss: 37.55  time: 0.3568  data_time: 0.0229  lr: 0.00065451  max_mem: 3221M
[07/07 13:37:30] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 75.09  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.55  loss: 37.55  time: 0.3571  data_time: 0.0192  lr: 9.5492e-05  max_mem: 3221M
[07/07 13:37:31] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 56.89  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.45  loss: 28.45  time: 0.3569  data_time: 0.0168  lr: 0.00090451  max_mem: 3221M
[07/07 13:37:31] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 46.47  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.23  loss: 23.23  time: 0.3585  data_time: 0.0151  lr: 0.00034549  max_mem: 3221M
[07/07 13:37:32] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 41.99  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 21  loss: 21  time: 0.3589  data_time: 0.0138  lr: 0.001  max_mem: 3221M
[07/07 13:37:33] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 39.16  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 19.58  loss: 19.58  time: 0.3590  data_time: 0.0128  lr: 0.00065451  max_mem: 3221M
[07/07 13:37:34] cvalgorithms INFO: Start inference on 216 batches
[07/07 14:07:59] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 14:07:59] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 14:08:27] cvalgorithms INFO: Starting training from iteration 0
[07/07 14:08:31] cvalgorithms INFO:  iter: 1  total_loss: 273.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 136.9  loss: 136.9  data_time: 0.0481  lr: 0.00090451  max_mem: 3221M
[07/07 14:08:32] cvalgorithms INFO:  eta: 0:00:35  iter: 3  total_loss: 128.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 64.11  loss: 64.11  time: 0.3675  data_time: 0.0264  lr: 0.00034549  max_mem: 3221M
[07/07 14:08:33] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 101.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.68  loss: 50.68  time: 0.3641  data_time: 0.0191  lr: 0.001  max_mem: 3221M
[07/07 14:08:33] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 78.88  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.44  loss: 39.44  time: 0.3608  data_time: 0.0154  lr: 0.00065451  max_mem: 3221M
[07/07 14:08:34] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 78.88  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.44  loss: 39.44  time: 0.3593  data_time: 0.0132  lr: 9.5492e-05  max_mem: 3221M
[07/07 14:08:35] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 80.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 40.37  loss: 40.37  time: 0.3587  data_time: 0.0117  lr: 0.00090451  max_mem: 3221M
[07/07 14:08:35] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 78.88  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.44  loss: 39.44  time: 0.3587  data_time: 0.0106  lr: 0.00034549  max_mem: 3221M
[07/07 14:08:36] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 69.73  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.86  loss: 34.86  time: 0.3590  data_time: 0.0098  lr: 0.001  max_mem: 3221M
[07/07 14:08:37] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 58.27  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 29.14  loss: 29.14  time: 0.3586  data_time: 0.0092  lr: 0.00065451  max_mem: 3221M
[07/07 14:08:38] cvalgorithms INFO: Start inference on 216 batches
[07/07 14:10:15] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 14:10:15] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 14:10:45] cvalgorithms INFO: Starting training from iteration 0
[07/07 14:10:48] cvalgorithms INFO:  iter: 1  total_loss: 46.51  decode.loss_seg: -0.002695  aux_0.loss: 1.465e-05  cnt.cnt_loss: 23.26  loss: 23.26  data_time: 0.0487  lr: 0.00090451  max_mem: 3221M
[07/07 14:10:49] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 96.61  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 48.31  loss: 48.3  time: 0.3595  data_time: 0.0266  lr: 0.00034549  max_mem: 3221M
[07/07 14:10:50] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 66.82  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.41  loss: 33.41  time: 0.3574  data_time: 0.0191  lr: 0.001  max_mem: 3221M
[07/07 14:10:51] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 67.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.57  loss: 33.57  time: 0.3577  data_time: 0.0154  lr: 0.00065451  max_mem: 3221M
[07/07 14:10:51] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 61.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 30.92  loss: 30.92  time: 0.3579  data_time: 0.0132  lr: 9.5492e-05  max_mem: 3221M
[07/07 14:10:52] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 61.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 30.92  loss: 30.92  time: 0.3611  data_time: 0.0118  lr: 0.00090451  max_mem: 3221M
[07/07 14:10:53] cvalgorithms INFO:  eta: 0:00:31  iter: 13  total_loss: 48.49  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 24.25  loss: 24.25  time: 0.3610  data_time: 0.0108  lr: 0.00034549  max_mem: 3221M
[07/07 14:10:54] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 33.67  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.84  loss: 16.84  time: 0.3611  data_time: 0.0100  lr: 0.001  max_mem: 3221M
[07/07 14:10:54] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 33.67  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.84  loss: 16.84  time: 0.3610  data_time: 0.0094  lr: 0.00065451  max_mem: 3221M
[07/07 14:10:55] cvalgorithms INFO: Start inference on 216 batches
[07/07 14:17:35] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 14:17:35] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 14:18:03] cvalgorithms INFO: Starting training from iteration 0
[07/07 14:18:07] cvalgorithms INFO:  iter: 1  total_loss: 128.4  decode.loss_seg: -2.106e-07  aux_0.loss: 0  cnt.cnt_loss: 64.21  loss: 64.21  data_time: 0.0522  lr: 0.00090451  max_mem: 3221M
[07/07 14:18:07] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 86.64  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.32  loss: 43.32  time: 0.3571  data_time: 0.0283  lr: 0.00034549  max_mem: 3221M
[07/07 14:18:08] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 83.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.87  loss: 41.87  time: 0.3554  data_time: 0.0204  lr: 0.001  max_mem: 3221M
[07/07 14:18:09] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 86.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.35  loss: 43.35  time: 0.3564  data_time: 0.0164  lr: 0.00065451  max_mem: 3221M
[07/07 14:18:10] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 86.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.35  loss: 43.35  time: 0.3572  data_time: 0.0139  lr: 9.5492e-05  max_mem: 3221M
[07/07 14:18:10] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 56.76  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.38  loss: 28.38  time: 0.3573  data_time: 0.0123  lr: 0.00090451  max_mem: 3221M
[07/07 14:18:11] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 51.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 25.75  loss: 25.75  time: 0.3571  data_time: 0.0112  lr: 0.00034549  max_mem: 3221M
[07/07 14:18:12] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 56.76  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.38  loss: 28.38  time: 0.3589  data_time: 0.0104  lr: 0.001  max_mem: 3221M
[07/07 14:18:12] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 51.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 25.75  loss: 25.75  time: 0.3589  data_time: 0.0098  lr: 0.00065451  max_mem: 3221M
[07/07 14:18:13] cvalgorithms INFO: Start inference on 216 batches
[07/07 14:38:02] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 14:38:02] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 14:38:29] cvalgorithms INFO: Starting training from iteration 0
[07/07 14:38:33] cvalgorithms INFO:  iter: 1  total_loss: 308.6  decode.loss_seg: 0.0005881  aux_0.loss: 4.011e-05  cnt.cnt_loss: 154.3  loss: 154.3  data_time: 0.0393  lr: 0.00090451  max_mem: 3221M
[07/07 14:38:34] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 143.6  decode.loss_seg: 0  aux_0.loss: -1.17e-06  cnt.cnt_loss: 71.8  loss: 71.8  time: 0.3545  data_time: 0.0220  lr: 0.00034549  max_mem: 3221M
[07/07 14:38:35] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 160.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 80.17  loss: 80.17  time: 0.3529  data_time: 0.0161  lr: 0.001  max_mem: 3221M
[07/07 14:38:35] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 136.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 68.24  loss: 68.24  time: 0.3549  data_time: 0.0132  lr: 0.00065451  max_mem: 3221M
[07/07 14:38:36] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 126.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 63.32  loss: 63.32  time: 0.3552  data_time: 0.0115  lr: 9.5492e-05  max_mem: 3221M
[07/07 14:38:37] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 111.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 55.64  loss: 55.64  time: 0.3562  data_time: 0.0103  lr: 0.00090451  max_mem: 3221M
[07/07 14:38:38] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 100.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.39  loss: 50.39  time: 0.3571  data_time: 0.0095  lr: 0.00034549  max_mem: 3221M
[07/07 14:38:38] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 84.03  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 42.02  loss: 42.02  time: 0.3574  data_time: 0.0089  lr: 0.001  max_mem: 3221M
[07/07 14:38:39] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 67.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.55  loss: 33.55  time: 0.3573  data_time: 0.0084  lr: 0.00065451  max_mem: 3221M
[07/07 14:38:40] cvalgorithms INFO: Start inference on 216 batches
[07/07 15:28:35] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 15:28:35] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 15:29:02] cvalgorithms INFO: Starting training from iteration 0
[07/07 15:29:07] cvalgorithms INFO:  iter: 1  total_loss: 31.46  decode.loss_seg: -8.698e-06  aux_0.loss: 1.266e-05  cnt.cnt_loss: 15.73  loss: 15.73  data_time: 0.0235  lr: 0.00090451  max_mem: 3221M
[07/07 15:29:07] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 63.19  decode.loss_seg: -8.698e-06  aux_0.loss: 0  cnt.cnt_loss: 31.6  loss: 31.6  time: 0.3584  data_time: 0.0140  lr: 0.00034549  max_mem: 3221M
[07/07 15:29:08] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 61.48  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 30.74  loss: 30.74  time: 0.3582  data_time: 0.0109  lr: 0.001  max_mem: 3221M
[07/07 15:29:09] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 82.01  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.01  loss: 41.01  time: 0.3583  data_time: 0.0094  lr: 0.00065451  max_mem: 3221M
[07/07 15:29:09] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 77.29  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 38.64  loss: 38.64  time: 0.3569  data_time: 0.0085  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:29:10] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 63.77  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 31.88  loss: 31.88  time: 0.3563  data_time: 0.0079  lr: 0.00090451  max_mem: 3221M
[07/07 15:29:11] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 63.87  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 31.94  loss: 31.94  time: 0.3559  data_time: 0.0073  lr: 0.00034549  max_mem: 3221M
[07/07 15:29:12] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 60.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 30.05  loss: 30.05  time: 0.3561  data_time: 0.0069  lr: 0.001  max_mem: 3221M
[07/07 15:29:12] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 56.23  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.11  loss: 28.11  time: 0.3565  data_time: 0.0066  lr: 0.00065451  max_mem: 3221M
[07/07 15:29:13] cvalgorithms INFO: Start inference on 216 batches
[07/07 15:29:42] cvalgorithms INFO: Inference done 11/216. Dataloading: 0.0008 s/iter. Inference: 0.0520 s/iter. Eval: 0.0005 s/iter. Total: 0.0534 s/iter. ETA=0:00:10
[07/07 15:29:42] cvalgorithms INFO: Inference done 12/216. Dataloading: 0.0008 s/iter. Inference: 0.0520 s/iter. Eval: 0.0005 s/iter. Total: 0.0535 s/iter. ETA=0:00:10
[07/07 15:29:42] cvalgorithms INFO: Inference done 13/216. Dataloading: 0.0009 s/iter. Inference: 0.0520 s/iter. Eval: 0.0005 s/iter. Total: 0.0536 s/iter. ETA=0:00:10
[07/07 15:29:42] cvalgorithms INFO: Inference done 14/216. Dataloading: 0.0009 s/iter. Inference: 0.0521 s/iter. Eval: 0.0005 s/iter. Total: 0.0536 s/iter. ETA=0:00:10
[07/07 15:29:42] cvalgorithms INFO: Inference done 15/216. Dataloading: 0.0009 s/iter. Inference: 0.0521 s/iter. Eval: 0.0005 s/iter. Total: 0.0537 s/iter. ETA=0:00:10
[07/07 15:29:42] cvalgorithms INFO: Inference done 16/216. Dataloading: 0.0009 s/iter. Inference: 0.0524 s/iter. Eval: 0.0006 s/iter. Total: 0.0540 s/iter. ETA=0:00:10
[07/07 15:29:42] cvalgorithms INFO: Inference done 17/216. Dataloading: 0.0009 s/iter. Inference: 0.0526 s/iter. Eval: 0.0006 s/iter. Total: 0.0543 s/iter. ETA=0:00:10
[07/07 15:29:42] cvalgorithms INFO: Inference done 18/216. Dataloading: 0.0010 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:10
[07/07 15:29:42] cvalgorithms INFO: Inference done 19/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 20/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 21/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 22/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 23/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 24/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 25/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 26/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 27/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 28/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 29/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0551 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 30/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 31/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 32/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 33/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 34/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 35/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:10
[07/07 15:29:43] cvalgorithms INFO: Inference done 36/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:09
[07/07 15:29:43] cvalgorithms INFO: Inference done 37/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0555 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 38/216. Dataloading: 0.0011 s/iter. Inference: 0.0535 s/iter. Eval: 0.0006 s/iter. Total: 0.0556 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 39/216. Dataloading: 0.0011 s/iter. Inference: 0.0535 s/iter. Eval: 0.0006 s/iter. Total: 0.0556 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 40/216. Dataloading: 0.0011 s/iter. Inference: 0.0535 s/iter. Eval: 0.0006 s/iter. Total: 0.0556 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 41/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0555 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 42/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0555 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 43/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0555 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 44/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 45/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 46/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 47/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 48/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 49/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 50/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 51/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 52/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:09
[07/07 15:29:44] cvalgorithms INFO: Inference done 53/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:08
[07/07 15:29:44] cvalgorithms INFO: Inference done 54/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:08
[07/07 15:29:44] cvalgorithms INFO: Inference done 55/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0551 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 56/216. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0551 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 57/216. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0551 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 58/216. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0551 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 59/216. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 60/216. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 61/216. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 62/216. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 63/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 64/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 65/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 66/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 67/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 68/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 69/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 70/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:08
[07/07 15:29:45] cvalgorithms INFO: Inference done 71/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:07
[07/07 15:29:45] cvalgorithms INFO: Inference done 72/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:07
[07/07 15:29:45] cvalgorithms INFO: Inference done 73/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:07
[07/07 15:29:45] cvalgorithms INFO: Inference done 74/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 75/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 76/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 77/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 78/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 79/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 80/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 81/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 82/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 83/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 84/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 85/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 86/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 87/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 88/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:07
[07/07 15:29:46] cvalgorithms INFO: Inference done 89/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:06
[07/07 15:29:46] cvalgorithms INFO: Inference done 90/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:06
[07/07 15:29:46] cvalgorithms INFO: Inference done 91/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:06
[07/07 15:29:46] cvalgorithms INFO: Inference done 92/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 93/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 94/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 95/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 96/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 97/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 98/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 99/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 100/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 101/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 102/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 103/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 104/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 105/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 106/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:06
[07/07 15:29:47] cvalgorithms INFO: Inference done 107/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:47] cvalgorithms INFO: Inference done 108/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:47] cvalgorithms INFO: Inference done 109/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:47] cvalgorithms INFO: Inference done 110/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 111/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 112/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 113/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 114/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 115/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 116/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 117/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0547 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 118/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 119/216. Dataloading: 0.0011 s/iter. Inference: 0.0527 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 120/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 121/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 122/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 123/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 124/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:05
[07/07 15:29:48] cvalgorithms INFO: Inference done 125/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:04
[07/07 15:29:48] cvalgorithms INFO: Inference done 126/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:04
[07/07 15:29:48] cvalgorithms INFO: Inference done 127/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:04
[07/07 15:29:48] cvalgorithms INFO: Inference done 128/216. Dataloading: 0.0011 s/iter. Inference: 0.0528 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 129/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 130/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 131/216. Dataloading: 0.0011 s/iter. Inference: 0.0529 s/iter. Eval: 0.0006 s/iter. Total: 0.0549 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 132/216. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0551 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 133/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 134/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 135/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 136/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 137/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 138/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 139/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 140/216. Dataloading: 0.0011 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 141/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 142/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 143/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:04
[07/07 15:29:49] cvalgorithms INFO: Inference done 144/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:03
[07/07 15:29:49] cvalgorithms INFO: Inference done 145/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 146/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 147/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 148/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 149/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 150/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 151/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0554 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 152/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 153/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 154/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 155/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 156/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 157/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 158/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 159/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 160/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 161/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:03
[07/07 15:29:50] cvalgorithms INFO: Inference done 162/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:50] cvalgorithms INFO: Inference done 163/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:50] cvalgorithms INFO: Inference done 164/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 165/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 166/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 167/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 168/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 169/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 170/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 171/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 172/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 173/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 174/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 175/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 176/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 177/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 178/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 179/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:02
[07/07 15:29:51] cvalgorithms INFO: Inference done 180/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:51] cvalgorithms INFO: Inference done 181/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:51] cvalgorithms INFO: Inference done 182/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 183/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 184/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 185/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 186/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 187/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 188/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 189/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 190/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 191/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 192/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 193/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 194/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 195/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 196/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 197/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:01
[07/07 15:29:52] cvalgorithms INFO: Inference done 198/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:52] cvalgorithms INFO: Inference done 199/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:52] cvalgorithms INFO: Inference done 200/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 201/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 202/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 203/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 204/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 205/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 206/216. Dataloading: 0.0011 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 207/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 208/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 209/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 210/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 211/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 212/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 213/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 214/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 215/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:53] cvalgorithms INFO: Inference done 216/216. Dataloading: 0.0011 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0552 s/iter. ETA=0:00:00
[07/07 15:29:54] cvalgorithms INFO: Total inference time: 0:00:12.333969 (0.058455 s / iter per device, on 1 devices)
[07/07 15:29:54] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.053119 s / iter per device, on 1 devices)
[07/07 15:32:29] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 15:32:29] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 15:33:01] cvalgorithms INFO: Starting training from iteration 0
[07/07 15:33:04] cvalgorithms INFO:  iter: 1  total_loss: 85.46  decode.loss_seg: 0.000409  aux_0.loss: 2.792e-07  cnt.cnt_loss: 42.73  loss: 42.73  data_time: 0.0620  lr: 0.00090451  max_mem: 3221M
[07/07 15:33:05] cvalgorithms INFO:  eta: 0:00:37  iter: 3  total_loss: 133.2  decode.loss_seg: 0  aux_0.loss: 2.792e-07  cnt.cnt_loss: 66.6  loss: 66.6  time: 0.3900  data_time: 0.0340  lr: 0.00034549  max_mem: 3221M
[07/07 15:33:06] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 88.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 44.05  loss: 44.05  time: 0.3749  data_time: 0.0243  lr: 0.001  max_mem: 3221M
[07/07 15:33:06] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 83.89  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.94  loss: 41.94  time: 0.3694  data_time: 0.0194  lr: 0.00065451  max_mem: 3221M
[07/07 15:33:07] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 60.18  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 30.09  loss: 30.09  time: 0.3668  data_time: 0.0165  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:33:08] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 57.69  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.85  loss: 28.85  time: 0.3648  data_time: 0.0145  lr: 0.00090451  max_mem: 3221M
[07/07 15:33:09] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 55.05  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.52  loss: 27.52  time: 0.3632  data_time: 0.0130  lr: 0.00034549  max_mem: 3221M
[07/07 15:33:09] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 52.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 26.37  loss: 26.37  time: 0.3629  data_time: 0.0119  lr: 0.001  max_mem: 3221M
[07/07 15:33:10] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 46.58  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.29  loss: 23.29  time: 0.3624  data_time: 0.0111  lr: 0.00065451  max_mem: 3221M
[07/07 15:33:11] cvalgorithms INFO: Start inference on 216 batches
[07/07 15:33:42] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 88, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 165, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluator)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 108, in inference_on_dataset
    log_every_n_seconds(
NameError: name 'log_every_n_seconds' is not defined
[07/07 15:33:42] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 40.71  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 20.35  loss: 20.35  time: 0.3622  data_time: 0.0105  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:35:49] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 15:35:49] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 15:36:19] cvalgorithms INFO: Starting training from iteration 0
[07/07 15:36:23] cvalgorithms INFO:  iter: 1  total_loss: 246.9  decode.loss_seg: 2.834e-07  aux_0.loss: -4.866e-07  cnt.cnt_loss: 123.4  loss: 123.4  data_time: 0.0471  lr: 0.00090451  max_mem: 3221M
[07/07 15:36:24] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 172.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 86.08  loss: 86.08  time: 0.3592  data_time: 0.0258  lr: 0.00034549  max_mem: 3221M
[07/07 15:36:24] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 152.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.32  loss: 76.32  time: 0.3587  data_time: 0.0188  lr: 0.001  max_mem: 3221M
[07/07 15:36:25] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 152.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.32  loss: 76.32  time: 0.3580  data_time: 0.0152  lr: 0.00065451  max_mem: 3221M
[07/07 15:36:26] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 152.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.32  loss: 76.32  time: 0.3577  data_time: 0.0131  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:36:26] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 152.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.32  loss: 76.32  time: 0.3576  data_time: 0.0117  lr: 0.00090451  max_mem: 3221M
[07/07 15:36:27] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 123.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 61.95  loss: 61.95  time: 0.3577  data_time: 0.0106  lr: 0.00034549  max_mem: 3221M
[07/07 15:36:28] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 105.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 52.86  loss: 52.86  time: 0.3576  data_time: 0.0098  lr: 0.001  max_mem: 3221M
[07/07 15:36:29] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 97.79  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 48.9  loss: 48.9  time: 0.3578  data_time: 0.0092  lr: 0.00065451  max_mem: 3221M
[07/07 15:36:29] cvalgorithms INFO: Start inference on 216 batches
[07/07 15:37:16] cvalgorithms INFO: Total inference time: 0:00:12.742644 (0.060392 s / iter per device, on 1 devices)
[07/07 15:37:16] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056372 s / iter per device, on 1 devices)
[07/07 15:37:16] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 84.68  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 42.34  loss: 42.34  time: 0.3581  data_time: 0.0087  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:37:17] cvalgorithms INFO:  eta: 0:00:27  iter: 21  total_loss: 66.66  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.33  loss: 33.33  time: 0.3624  data_time: 0.0058  lr: 0.00090451  max_mem: 3221M
[07/07 15:37:18] cvalgorithms INFO:  eta: 0:00:27  iter: 23  total_loss: 59.18  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 29.59  loss: 29.59  time: 0.3661  data_time: 0.0072  lr: 0.00034549  max_mem: 3221M
[07/07 15:37:18] cvalgorithms INFO:  eta: 0:00:26  iter: 25  total_loss: 52.77  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 26.39  loss: 26.39  time: 0.3685  data_time: 0.0072  lr: 0.001  max_mem: 3221M
[07/07 15:37:19] cvalgorithms INFO:  eta: 0:00:25  iter: 27  total_loss: 39.03  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 19.52  loss: 19.52  time: 0.3693  data_time: 0.0072  lr: 0.00065451  max_mem: 3221M
[07/07 15:37:20] cvalgorithms INFO:  eta: 0:00:25  iter: 29  total_loss: 27.48  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 13.74  loss: 13.74  time: 0.3713  data_time: 0.0072  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:37:21] cvalgorithms INFO:  eta: 0:00:24  iter: 31  total_loss: 21.17  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 10.59  loss: 10.59  time: 0.3727  data_time: 0.0073  lr: 0.00090451  max_mem: 3221M
[07/07 15:37:22] cvalgorithms INFO:  eta: 0:00:23  iter: 33  total_loss: 20.36  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 10.18  loss: 10.18  time: 0.3736  data_time: 0.0074  lr: 0.00034549  max_mem: 3221M
[07/07 15:37:22] cvalgorithms INFO:  eta: 0:00:23  iter: 35  total_loss: 20.16  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 10.08  loss: 10.08  time: 0.3748  data_time: 0.0074  lr: 0.001  max_mem: 3221M
[07/07 15:37:23] cvalgorithms INFO:  eta: 0:00:22  iter: 37  total_loss: 18.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 9.4  loss: 9.4  time: 0.3758  data_time: 0.0075  lr: 0.00065451  max_mem: 3221M
[07/07 15:37:24] cvalgorithms INFO: Start inference on 216 batches
[07/07 15:38:09] cvalgorithms INFO: Total inference time: 0:00:13.058978 (0.061891 s / iter per device, on 1 devices)
[07/07 15:38:09] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.057039 s / iter per device, on 1 devices)
[07/07 15:38:09] cvalgorithms INFO:  eta: 0:00:22  iter: 39  total_loss: 17.29  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 8.646  loss: 8.646  time: 0.3765  data_time: 0.0075  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:38:10] cvalgorithms INFO:  eta: 0:00:22  iter: 41  total_loss: 14.12  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.062  loss: 7.062  time: 0.3787  data_time: 0.0077  lr: 0.00090451  max_mem: 3221M
[07/07 15:38:11] cvalgorithms INFO:  eta: 0:00:21  iter: 43  total_loss: 11.52  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.759  loss: 5.759  time: 0.3796  data_time: 0.0068  lr: 0.00034549  max_mem: 3221M
[07/07 15:38:12] cvalgorithms INFO:  eta: 0:00:20  iter: 45  total_loss: 10.19  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.094  loss: 5.094  time: 0.3803  data_time: 0.0069  lr: 0.001  max_mem: 3221M
[07/07 15:38:12] cvalgorithms INFO:  eta: 0:00:20  iter: 47  total_loss: 8.721  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.36  loss: 4.36  time: 0.3808  data_time: 0.0069  lr: 0.00065451  max_mem: 3221M
[07/07 15:38:13] cvalgorithms INFO:  eta: 0:00:19  iter: 49  total_loss: 7.03  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.515  loss: 3.515  time: 0.3813  data_time: 0.0069  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:38:14] cvalgorithms INFO:  eta: 0:00:18  iter: 51  total_loss: 5.926  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.963  loss: 2.963  time: 0.3823  data_time: 0.0070  lr: 0.00090451  max_mem: 3221M
[07/07 15:38:15] cvalgorithms INFO:  eta: 0:00:17  iter: 53  total_loss: 5.322  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.661  loss: 2.661  time: 0.3833  data_time: 0.0070  lr: 0.00034549  max_mem: 3221M
[07/07 15:38:16] cvalgorithms INFO:  eta: 0:00:17  iter: 55  total_loss: 5.096  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.548  loss: 2.548  time: 0.3838  data_time: 0.0070  lr: 0.001  max_mem: 3221M
[07/07 15:38:16] cvalgorithms INFO:  eta: 0:00:16  iter: 57  total_loss: 4.199  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.099  loss: 2.099  time: 0.3842  data_time: 0.0070  lr: 0.00065451  max_mem: 3221M
[07/07 15:38:17] cvalgorithms INFO: Start inference on 216 batches
[07/07 15:39:05] cvalgorithms INFO: Total inference time: 0:00:13.431921 (0.063658 s / iter per device, on 1 devices)
[07/07 15:39:05] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.057582 s / iter per device, on 1 devices)
[07/07 15:42:22] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 15:42:22] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 15:42:53] cvalgorithms INFO: Starting training from iteration 0
[07/07 15:42:57] cvalgorithms INFO:  iter: 1  total_loss: 402.4  decode.loss_seg: 0.001992  aux_0.loss: 4.28e-08  cnt.cnt_loss: 201.2  loss: 201.2  data_time: 0.0547  lr: 0.00090451  max_mem: 3221M
[07/07 15:42:58] cvalgorithms INFO:  eta: 0:00:36  iter: 3  total_loss: 281.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 140.8  loss: 140.8  time: 0.3838  data_time: 0.0299  lr: 0.00034549  max_mem: 3221M
[07/07 15:42:59] cvalgorithms INFO:  eta: 0:00:35  iter: 5  total_loss: 192.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 96.05  loss: 96.05  time: 0.3781  data_time: 0.0216  lr: 0.001  max_mem: 3221M
[07/07 15:43:00] cvalgorithms INFO:  eta: 0:00:35  iter: 7  total_loss: 144.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.1  loss: 72.1  time: 0.3805  data_time: 0.0176  lr: 0.00065451  max_mem: 3221M
[07/07 15:43:00] cvalgorithms INFO:  eta: 0:00:34  iter: 9  total_loss: 115.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 57.58  loss: 57.58  time: 0.3810  data_time: 0.0154  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:43:01] cvalgorithms INFO:  eta: 0:00:33  iter: 11  total_loss: 103.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 51.97  loss: 51.97  time: 0.3813  data_time: 0.0138  lr: 0.00090451  max_mem: 3221M
[07/07 15:43:02] cvalgorithms INFO:  eta: 0:00:32  iter: 13  total_loss: 87.89  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.94  loss: 43.94  time: 0.3822  data_time: 0.0126  lr: 0.00034549  max_mem: 3221M
[07/07 15:43:03] cvalgorithms INFO:  eta: 0:00:32  iter: 15  total_loss: 72.47  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 36.24  loss: 36.24  time: 0.3810  data_time: 0.0117  lr: 0.001  max_mem: 3221M
[07/07 15:43:03] cvalgorithms INFO:  eta: 0:00:31  iter: 17  total_loss: 72.47  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 36.24  loss: 36.24  time: 0.3827  data_time: 0.0110  lr: 0.00065451  max_mem: 3221M
[07/07 15:43:04] cvalgorithms INFO: Start inference on 216 batches
[07/07 15:43:37] cvalgorithms INFO: Inference done 11/216. Dataloading: 0.0010 s/iter. Inference: 0.0534 s/iter. Eval: 0.0006 s/iter. Total: 0.0550 s/iter. ETA=0:00:11
[07/07 15:43:37] cvalgorithms INFO: Inference done 12/216. Dataloading: 0.0010 s/iter. Inference: 0.0532 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:11
[07/07 15:43:37] cvalgorithms INFO: Inference done 13/216. Dataloading: 0.0010 s/iter. Inference: 0.0531 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:11
[07/07 15:43:37] cvalgorithms INFO: Inference done 14/216. Dataloading: 0.0010 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:11
[07/07 15:43:37] cvalgorithms INFO: Inference done 15/216. Dataloading: 0.0011 s/iter. Inference: 0.0530 s/iter. Eval: 0.0006 s/iter. Total: 0.0548 s/iter. ETA=0:00:11
[07/07 15:43:37] cvalgorithms INFO: Inference done 16/216. Dataloading: 0.0011 s/iter. Inference: 0.0533 s/iter. Eval: 0.0006 s/iter. Total: 0.0551 s/iter. ETA=0:00:11
[07/07 15:43:37] cvalgorithms INFO: Inference done 17/216. Dataloading: 0.0011 s/iter. Inference: 0.0535 s/iter. Eval: 0.0006 s/iter. Total: 0.0553 s/iter. ETA=0:00:11
[07/07 15:43:37] cvalgorithms INFO: Inference done 18/216. Dataloading: 0.0011 s/iter. Inference: 0.0536 s/iter. Eval: 0.0006 s/iter. Total: 0.0555 s/iter. ETA=0:00:10
[07/07 15:43:37] cvalgorithms INFO: Inference done 19/216. Dataloading: 0.0011 s/iter. Inference: 0.0537 s/iter. Eval: 0.0006 s/iter. Total: 0.0556 s/iter. ETA=0:00:10
[07/07 15:43:37] cvalgorithms INFO: Inference done 20/216. Dataloading: 0.0011 s/iter. Inference: 0.0538 s/iter. Eval: 0.0006 s/iter. Total: 0.0557 s/iter. ETA=0:00:10
[07/07 15:43:37] cvalgorithms INFO: Inference done 21/216. Dataloading: 0.0011 s/iter. Inference: 0.0538 s/iter. Eval: 0.0006 s/iter. Total: 0.0558 s/iter. ETA=0:00:10
[07/07 15:43:37] cvalgorithms INFO: Inference done 22/216. Dataloading: 0.0011 s/iter. Inference: 0.0539 s/iter. Eval: 0.0006 s/iter. Total: 0.0558 s/iter. ETA=0:00:10
[07/07 15:43:37] cvalgorithms INFO: Inference done 23/216. Dataloading: 0.0011 s/iter. Inference: 0.0540 s/iter. Eval: 0.0006 s/iter. Total: 0.0560 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 24/216. Dataloading: 0.0011 s/iter. Inference: 0.0541 s/iter. Eval: 0.0006 s/iter. Total: 0.0560 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 25/216. Dataloading: 0.0011 s/iter. Inference: 0.0542 s/iter. Eval: 0.0006 s/iter. Total: 0.0561 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 26/216. Dataloading: 0.0011 s/iter. Inference: 0.0542 s/iter. Eval: 0.0006 s/iter. Total: 0.0561 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 27/216. Dataloading: 0.0011 s/iter. Inference: 0.0542 s/iter. Eval: 0.0006 s/iter. Total: 0.0562 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 28/216. Dataloading: 0.0011 s/iter. Inference: 0.0542 s/iter. Eval: 0.0006 s/iter. Total: 0.0562 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 29/216. Dataloading: 0.0011 s/iter. Inference: 0.0543 s/iter. Eval: 0.0006 s/iter. Total: 0.0563 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 30/216. Dataloading: 0.0011 s/iter. Inference: 0.0543 s/iter. Eval: 0.0006 s/iter. Total: 0.0563 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 31/216. Dataloading: 0.0011 s/iter. Inference: 0.0543 s/iter. Eval: 0.0006 s/iter. Total: 0.0563 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 32/216. Dataloading: 0.0011 s/iter. Inference: 0.0543 s/iter. Eval: 0.0006 s/iter. Total: 0.0563 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 33/216. Dataloading: 0.0011 s/iter. Inference: 0.0544 s/iter. Eval: 0.0006 s/iter. Total: 0.0564 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 34/216. Dataloading: 0.0011 s/iter. Inference: 0.0544 s/iter. Eval: 0.0006 s/iter. Total: 0.0564 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 35/216. Dataloading: 0.0011 s/iter. Inference: 0.0544 s/iter. Eval: 0.0006 s/iter. Total: 0.0564 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 36/216. Dataloading: 0.0011 s/iter. Inference: 0.0545 s/iter. Eval: 0.0006 s/iter. Total: 0.0564 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 37/216. Dataloading: 0.0011 s/iter. Inference: 0.0545 s/iter. Eval: 0.0006 s/iter. Total: 0.0565 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 38/216. Dataloading: 0.0011 s/iter. Inference: 0.0545 s/iter. Eval: 0.0006 s/iter. Total: 0.0565 s/iter. ETA=0:00:10
[07/07 15:43:38] cvalgorithms INFO: Inference done 39/216. Dataloading: 0.0011 s/iter. Inference: 0.0545 s/iter. Eval: 0.0006 s/iter. Total: 0.0565 s/iter. ETA=0:00:09
[07/07 15:43:38] cvalgorithms INFO: Inference done 40/216. Dataloading: 0.0011 s/iter. Inference: 0.0546 s/iter. Eval: 0.0006 s/iter. Total: 0.0565 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 41/216. Dataloading: 0.0011 s/iter. Inference: 0.0546 s/iter. Eval: 0.0006 s/iter. Total: 0.0566 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 42/216. Dataloading: 0.0011 s/iter. Inference: 0.0547 s/iter. Eval: 0.0006 s/iter. Total: 0.0567 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 43/216. Dataloading: 0.0011 s/iter. Inference: 0.0547 s/iter. Eval: 0.0006 s/iter. Total: 0.0567 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 44/216. Dataloading: 0.0011 s/iter. Inference: 0.0548 s/iter. Eval: 0.0006 s/iter. Total: 0.0569 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 45/216. Dataloading: 0.0011 s/iter. Inference: 0.0549 s/iter. Eval: 0.0006 s/iter. Total: 0.0569 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 46/216. Dataloading: 0.0011 s/iter. Inference: 0.0549 s/iter. Eval: 0.0006 s/iter. Total: 0.0570 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 47/216. Dataloading: 0.0011 s/iter. Inference: 0.0550 s/iter. Eval: 0.0006 s/iter. Total: 0.0570 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 48/216. Dataloading: 0.0011 s/iter. Inference: 0.0550 s/iter. Eval: 0.0006 s/iter. Total: 0.0571 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 49/216. Dataloading: 0.0011 s/iter. Inference: 0.0551 s/iter. Eval: 0.0006 s/iter. Total: 0.0571 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 50/216. Dataloading: 0.0011 s/iter. Inference: 0.0551 s/iter. Eval: 0.0006 s/iter. Total: 0.0571 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 51/216. Dataloading: 0.0011 s/iter. Inference: 0.0551 s/iter. Eval: 0.0006 s/iter. Total: 0.0571 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 52/216. Dataloading: 0.0011 s/iter. Inference: 0.0552 s/iter. Eval: 0.0006 s/iter. Total: 0.0572 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 53/216. Dataloading: 0.0011 s/iter. Inference: 0.0552 s/iter. Eval: 0.0006 s/iter. Total: 0.0573 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 54/216. Dataloading: 0.0011 s/iter. Inference: 0.0552 s/iter. Eval: 0.0006 s/iter. Total: 0.0573 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 55/216. Dataloading: 0.0011 s/iter. Inference: 0.0553 s/iter. Eval: 0.0006 s/iter. Total: 0.0573 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 56/216. Dataloading: 0.0011 s/iter. Inference: 0.0553 s/iter. Eval: 0.0006 s/iter. Total: 0.0573 s/iter. ETA=0:00:09
[07/07 15:43:39] cvalgorithms INFO: Inference done 57/216. Dataloading: 0.0011 s/iter. Inference: 0.0553 s/iter. Eval: 0.0006 s/iter. Total: 0.0574 s/iter. ETA=0:00:09
[07/07 15:43:40] cvalgorithms INFO: Inference done 58/216. Dataloading: 0.0011 s/iter. Inference: 0.0554 s/iter. Eval: 0.0006 s/iter. Total: 0.0574 s/iter. ETA=0:00:09
[07/07 15:43:40] cvalgorithms INFO: Inference done 59/216. Dataloading: 0.0011 s/iter. Inference: 0.0554 s/iter. Eval: 0.0006 s/iter. Total: 0.0574 s/iter. ETA=0:00:09
[07/07 15:43:40] cvalgorithms INFO: Inference done 60/216. Dataloading: 0.0011 s/iter. Inference: 0.0554 s/iter. Eval: 0.0006 s/iter. Total: 0.0575 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 61/216. Dataloading: 0.0011 s/iter. Inference: 0.0555 s/iter. Eval: 0.0006 s/iter. Total: 0.0575 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 62/216. Dataloading: 0.0011 s/iter. Inference: 0.0555 s/iter. Eval: 0.0006 s/iter. Total: 0.0576 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 63/216. Dataloading: 0.0011 s/iter. Inference: 0.0556 s/iter. Eval: 0.0006 s/iter. Total: 0.0577 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 64/216. Dataloading: 0.0011 s/iter. Inference: 0.0556 s/iter. Eval: 0.0006 s/iter. Total: 0.0577 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 65/216. Dataloading: 0.0011 s/iter. Inference: 0.0556 s/iter. Eval: 0.0006 s/iter. Total: 0.0577 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 66/216. Dataloading: 0.0011 s/iter. Inference: 0.0557 s/iter. Eval: 0.0006 s/iter. Total: 0.0577 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 67/216. Dataloading: 0.0011 s/iter. Inference: 0.0557 s/iter. Eval: 0.0006 s/iter. Total: 0.0578 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 68/216. Dataloading: 0.0011 s/iter. Inference: 0.0557 s/iter. Eval: 0.0006 s/iter. Total: 0.0578 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 69/216. Dataloading: 0.0011 s/iter. Inference: 0.0557 s/iter. Eval: 0.0006 s/iter. Total: 0.0578 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 70/216. Dataloading: 0.0011 s/iter. Inference: 0.0558 s/iter. Eval: 0.0006 s/iter. Total: 0.0578 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 71/216. Dataloading: 0.0011 s/iter. Inference: 0.0558 s/iter. Eval: 0.0006 s/iter. Total: 0.0579 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 72/216. Dataloading: 0.0011 s/iter. Inference: 0.0558 s/iter. Eval: 0.0006 s/iter. Total: 0.0579 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 73/216. Dataloading: 0.0011 s/iter. Inference: 0.0558 s/iter. Eval: 0.0006 s/iter. Total: 0.0579 s/iter. ETA=0:00:08
[07/07 15:43:40] cvalgorithms INFO: Inference done 74/216. Dataloading: 0.0011 s/iter. Inference: 0.0559 s/iter. Eval: 0.0006 s/iter. Total: 0.0579 s/iter. ETA=0:00:08
[07/07 15:43:41] cvalgorithms INFO: Inference done 75/216. Dataloading: 0.0011 s/iter. Inference: 0.0559 s/iter. Eval: 0.0006 s/iter. Total: 0.0579 s/iter. ETA=0:00:08
[07/07 15:43:41] cvalgorithms INFO: Inference done 76/216. Dataloading: 0.0011 s/iter. Inference: 0.0559 s/iter. Eval: 0.0006 s/iter. Total: 0.0580 s/iter. ETA=0:00:08
[07/07 15:43:41] cvalgorithms INFO: Inference done 77/216. Dataloading: 0.0011 s/iter. Inference: 0.0559 s/iter. Eval: 0.0006 s/iter. Total: 0.0580 s/iter. ETA=0:00:08
[07/07 15:43:41] cvalgorithms INFO: Inference done 78/216. Dataloading: 0.0011 s/iter. Inference: 0.0559 s/iter. Eval: 0.0006 s/iter. Total: 0.0580 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 79/216. Dataloading: 0.0011 s/iter. Inference: 0.0559 s/iter. Eval: 0.0006 s/iter. Total: 0.0580 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 80/216. Dataloading: 0.0011 s/iter. Inference: 0.0559 s/iter. Eval: 0.0006 s/iter. Total: 0.0580 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 81/216. Dataloading: 0.0011 s/iter. Inference: 0.0559 s/iter. Eval: 0.0006 s/iter. Total: 0.0580 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 82/216. Dataloading: 0.0011 s/iter. Inference: 0.0559 s/iter. Eval: 0.0006 s/iter. Total: 0.0580 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 83/216. Dataloading: 0.0011 s/iter. Inference: 0.0560 s/iter. Eval: 0.0006 s/iter. Total: 0.0581 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 84/216. Dataloading: 0.0011 s/iter. Inference: 0.0560 s/iter. Eval: 0.0006 s/iter. Total: 0.0581 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 85/216. Dataloading: 0.0011 s/iter. Inference: 0.0560 s/iter. Eval: 0.0006 s/iter. Total: 0.0581 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 86/216. Dataloading: 0.0011 s/iter. Inference: 0.0560 s/iter. Eval: 0.0006 s/iter. Total: 0.0581 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 87/216. Dataloading: 0.0011 s/iter. Inference: 0.0560 s/iter. Eval: 0.0006 s/iter. Total: 0.0581 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 88/216. Dataloading: 0.0011 s/iter. Inference: 0.0560 s/iter. Eval: 0.0006 s/iter. Total: 0.0581 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 89/216. Dataloading: 0.0011 s/iter. Inference: 0.0561 s/iter. Eval: 0.0006 s/iter. Total: 0.0582 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 90/216. Dataloading: 0.0011 s/iter. Inference: 0.0561 s/iter. Eval: 0.0006 s/iter. Total: 0.0582 s/iter. ETA=0:00:07
[07/07 15:43:41] cvalgorithms INFO: Inference done 91/216. Dataloading: 0.0011 s/iter. Inference: 0.0561 s/iter. Eval: 0.0006 s/iter. Total: 0.0582 s/iter. ETA=0:00:07
[07/07 15:43:42] cvalgorithms INFO: Inference done 92/216. Dataloading: 0.0011 s/iter. Inference: 0.0561 s/iter. Eval: 0.0006 s/iter. Total: 0.0582 s/iter. ETA=0:00:07
[07/07 15:43:42] cvalgorithms INFO: Inference done 93/216. Dataloading: 0.0011 s/iter. Inference: 0.0561 s/iter. Eval: 0.0006 s/iter. Total: 0.0582 s/iter. ETA=0:00:07
[07/07 15:43:42] cvalgorithms INFO: Inference done 94/216. Dataloading: 0.0011 s/iter. Inference: 0.0561 s/iter. Eval: 0.0006 s/iter. Total: 0.0582 s/iter. ETA=0:00:07
[07/07 15:43:42] cvalgorithms INFO: Inference done 95/216. Dataloading: 0.0011 s/iter. Inference: 0.0562 s/iter. Eval: 0.0006 s/iter. Total: 0.0582 s/iter. ETA=0:00:07
[07/07 15:43:42] cvalgorithms INFO: Inference done 96/216. Dataloading: 0.0011 s/iter. Inference: 0.0562 s/iter. Eval: 0.0006 s/iter. Total: 0.0582 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 97/216. Dataloading: 0.0011 s/iter. Inference: 0.0562 s/iter. Eval: 0.0006 s/iter. Total: 0.0583 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 98/216. Dataloading: 0.0011 s/iter. Inference: 0.0562 s/iter. Eval: 0.0006 s/iter. Total: 0.0583 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 99/216. Dataloading: 0.0011 s/iter. Inference: 0.0562 s/iter. Eval: 0.0006 s/iter. Total: 0.0583 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 100/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0583 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 101/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 102/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 103/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 104/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 105/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 106/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 107/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:42] cvalgorithms INFO: Inference done 108/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:43] cvalgorithms INFO: Inference done 109/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:43] cvalgorithms INFO: Inference done 110/216. Dataloading: 0.0011 s/iter. Inference: 0.0563 s/iter. Eval: 0.0006 s/iter. Total: 0.0584 s/iter. ETA=0:00:06
[07/07 15:43:43] cvalgorithms INFO: Inference done 111/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0585 s/iter. ETA=0:00:06
[07/07 15:43:43] cvalgorithms INFO: Inference done 112/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0585 s/iter. ETA=0:00:06
[07/07 15:43:43] cvalgorithms INFO: Inference done 113/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0585 s/iter. ETA=0:00:06
[07/07 15:43:43] cvalgorithms INFO: Inference done 114/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0585 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 115/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0585 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 116/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0585 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 117/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0585 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 118/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0585 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 119/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0585 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 120/216. Dataloading: 0.0011 s/iter. Inference: 0.0564 s/iter. Eval: 0.0006 s/iter. Total: 0.0586 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 121/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0586 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 122/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0586 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 123/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0586 s/iter. ETA=0:00:05
[07/07 15:43:43] cvalgorithms INFO: Inference done 124/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0586 s/iter. ETA=0:00:05
[07/07 15:43:44] cvalgorithms INFO: Inference done 125/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0586 s/iter. ETA=0:00:05
[07/07 15:43:44] cvalgorithms INFO: Inference done 126/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0586 s/iter. ETA=0:00:05
[07/07 15:43:44] cvalgorithms INFO: Inference done 127/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0587 s/iter. ETA=0:00:05
[07/07 15:43:44] cvalgorithms INFO: Inference done 128/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0587 s/iter. ETA=0:00:05
[07/07 15:43:44] cvalgorithms INFO: Inference done 129/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0587 s/iter. ETA=0:00:05
[07/07 15:43:44] cvalgorithms INFO: Inference done 130/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0587 s/iter. ETA=0:00:05
[07/07 15:43:44] cvalgorithms INFO: Inference done 131/216. Dataloading: 0.0011 s/iter. Inference: 0.0565 s/iter. Eval: 0.0006 s/iter. Total: 0.0587 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 132/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0587 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 133/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 134/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 135/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 136/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 137/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 138/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 139/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 140/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:44] cvalgorithms INFO: Inference done 141/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:45] cvalgorithms INFO: Inference done 142/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:45] cvalgorithms INFO: Inference done 143/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:45] cvalgorithms INFO: Inference done 144/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:45] cvalgorithms INFO: Inference done 145/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:45] cvalgorithms INFO: Inference done 146/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:45] cvalgorithms INFO: Inference done 147/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:04
[07/07 15:43:45] cvalgorithms INFO: Inference done 148/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 149/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 150/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 151/216. Dataloading: 0.0012 s/iter. Inference: 0.0566 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 152/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0588 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 153/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 154/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 155/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 156/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 157/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:45] cvalgorithms INFO: Inference done 158/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:46] cvalgorithms INFO: Inference done 159/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:46] cvalgorithms INFO: Inference done 160/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:46] cvalgorithms INFO: Inference done 161/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:46] cvalgorithms INFO: Inference done 162/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:46] cvalgorithms INFO: Inference done 163/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:46] cvalgorithms INFO: Inference done 164/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:46] cvalgorithms INFO: Inference done 165/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:03
[07/07 15:43:46] cvalgorithms INFO: Inference done 166/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0589 s/iter. ETA=0:00:02
[07/07 15:43:46] cvalgorithms INFO: Inference done 167/216. Dataloading: 0.0012 s/iter. Inference: 0.0567 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:46] cvalgorithms INFO: Inference done 168/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:46] cvalgorithms INFO: Inference done 169/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:46] cvalgorithms INFO: Inference done 170/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:46] cvalgorithms INFO: Inference done 171/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:46] cvalgorithms INFO: Inference done 172/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:46] cvalgorithms INFO: Inference done 173/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:46] cvalgorithms INFO: Inference done 174/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:46] cvalgorithms INFO: Inference done 175/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:47] cvalgorithms INFO: Inference done 176/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:47] cvalgorithms INFO: Inference done 177/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:47] cvalgorithms INFO: Inference done 178/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:47] cvalgorithms INFO: Inference done 179/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:47] cvalgorithms INFO: Inference done 180/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:47] cvalgorithms INFO: Inference done 181/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:47] cvalgorithms INFO: Inference done 182/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:02
[07/07 15:43:47] cvalgorithms INFO: Inference done 183/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:01
[07/07 15:43:47] cvalgorithms INFO: Inference done 184/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:01
[07/07 15:43:47] cvalgorithms INFO: Inference done 185/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:01
[07/07 15:43:47] cvalgorithms INFO: Inference done 186/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:01
[07/07 15:43:47] cvalgorithms INFO: Inference done 187/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:01
[07/07 15:43:47] cvalgorithms INFO: Inference done 188/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:01
[07/07 15:43:47] cvalgorithms INFO: Inference done 189/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:01
[07/07 15:43:47] cvalgorithms INFO: Inference done 190/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0590 s/iter. ETA=0:00:01
[07/07 15:43:47] cvalgorithms INFO: Inference done 191/216. Dataloading: 0.0012 s/iter. Inference: 0.0568 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:01
[07/07 15:43:48] cvalgorithms INFO: Inference done 192/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:01
[07/07 15:43:48] cvalgorithms INFO: Inference done 193/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:01
[07/07 15:43:48] cvalgorithms INFO: Inference done 194/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:01
[07/07 15:43:48] cvalgorithms INFO: Inference done 195/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:01
[07/07 15:43:48] cvalgorithms INFO: Inference done 196/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:01
[07/07 15:43:48] cvalgorithms INFO: Inference done 197/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:01
[07/07 15:43:48] cvalgorithms INFO: Inference done 198/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:01
[07/07 15:43:48] cvalgorithms INFO: Inference done 199/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:01
[07/07 15:43:48] cvalgorithms INFO: Inference done 200/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0591 s/iter. ETA=0:00:00
[07/07 15:43:48] cvalgorithms INFO: Inference done 201/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:48] cvalgorithms INFO: Inference done 202/216. Dataloading: 0.0012 s/iter. Inference: 0.0569 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:48] cvalgorithms INFO: Inference done 203/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:48] cvalgorithms INFO: Inference done 204/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:48] cvalgorithms INFO: Inference done 205/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:48] cvalgorithms INFO: Inference done 206/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:48] cvalgorithms INFO: Inference done 207/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:48] cvalgorithms INFO: Inference done 208/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:49] cvalgorithms INFO: Inference done 209/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:49] cvalgorithms INFO: Inference done 210/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:49] cvalgorithms INFO: Inference done 211/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:49] cvalgorithms INFO: Inference done 212/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:49] cvalgorithms INFO: Inference done 213/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:49] cvalgorithms INFO: Inference done 214/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:49] cvalgorithms INFO: Inference done 215/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:43:49] cvalgorithms INFO: Inference done 216/216. Dataloading: 0.0012 s/iter. Inference: 0.0570 s/iter. Eval: 0.0006 s/iter. Total: 0.0592 s/iter. ETA=0:00:00
[07/07 15:45:50] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 15:45:51] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 15:46:21] cvalgorithms INFO: Starting training from iteration 0
[07/07 15:46:25] cvalgorithms INFO:  iter: 1  total_loss: 694.2  decode.loss_seg: -0.0005078  aux_0.loss: 3.833e-05  cnt.cnt_loss: 347.1  loss: 347.1  data_time: 0.0474  lr: 0.00090451  max_mem: 3221M
[07/07 15:46:25] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 568.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 284.1  loss: 284.1  time: 0.3594  data_time: 0.0260  lr: 0.00034549  max_mem: 3221M
[07/07 15:46:26] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 504.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 252  loss: 252  time: 0.3617  data_time: 0.0188  lr: 0.001  max_mem: 3221M
[07/07 15:46:27] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 329.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 164.5  loss: 164.5  time: 0.3628  data_time: 0.0154  lr: 0.00065451  max_mem: 3221M
[07/07 15:46:28] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 194.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 97.05  loss: 97.05  time: 0.3634  data_time: 0.0133  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:46:28] cvalgorithms INFO:  eta: 0:00:32  iter: 11  total_loss: 182.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 91.13  loss: 91.13  time: 0.3656  data_time: 0.0119  lr: 0.00090451  max_mem: 3221M
[07/07 15:46:29] cvalgorithms INFO:  eta: 0:00:31  iter: 13  total_loss: 162.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 81.47  loss: 81.47  time: 0.3665  data_time: 0.0109  lr: 0.00034549  max_mem: 3221M
[07/07 15:46:30] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 142.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 71.35  loss: 71.35  time: 0.3667  data_time: 0.0101  lr: 0.001  max_mem: 3221M
[07/07 15:46:31] cvalgorithms INFO:  eta: 0:00:30  iter: 17  total_loss: 116  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 57.98  loss: 57.98  time: 0.3682  data_time: 0.0096  lr: 0.00065451  max_mem: 3221M
[07/07 15:46:31] cvalgorithms INFO: Start inference on 216 batches
[07/07 15:50:19] cvalgorithms INFO: Total inference time: 0:03:15.161025 (0.924934 s / iter per device, on 1 devices)
[07/07 15:50:21] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.057290 s / iter per device, on 1 devices)
[07/07 15:54:43] cvalgorithms INFO:  eta: 0:00:29  iter: 19  total_loss: 87.23  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.61  loss: 43.61  time: 0.3696  data_time: 0.0091  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:54:44] cvalgorithms INFO:  eta: 0:00:28  iter: 21  total_loss: 74.01  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.01  loss: 37.01  time: 0.3766  data_time: 0.0051  lr: 0.00090451  max_mem: 3221M
[07/07 15:54:45] cvalgorithms INFO:  eta: 0:00:27  iter: 23  total_loss: 41.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 20.99  loss: 20.99  time: 0.3751  data_time: 0.0051  lr: 0.00034549  max_mem: 3221M
[07/07 15:54:46] cvalgorithms INFO:  eta: 0:00:27  iter: 25  total_loss: 33.96  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.98  loss: 16.98  time: 0.3736  data_time: 0.0052  lr: 0.001  max_mem: 3221M
[07/07 15:54:47] cvalgorithms INFO:  eta: 0:00:26  iter: 27  total_loss: 33.96  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.98  loss: 16.98  time: 0.3725  data_time: 0.0051  lr: 0.00065451  max_mem: 3221M
[07/07 15:55:14] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 15:55:14] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 15:55:43] cvalgorithms INFO: Starting training from iteration 0
[07/07 15:55:46] cvalgorithms INFO:  iter: 1  total_loss: 395.5  decode.loss_seg: 1.627e-07  aux_0.loss: -2.386e-06  cnt.cnt_loss: 197.7  loss: 197.7  data_time: 0.0430  lr: 0.00090451  max_mem: 3221M
[07/07 15:55:47] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 178.6  decode.loss_seg: 0  aux_0.loss: -3.361e-08  cnt.cnt_loss: 89.31  loss: 89.31  time: 0.3608  data_time: 0.0236  lr: 0.00034549  max_mem: 3221M
[07/07 15:55:48] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 139.3  decode.loss_seg: 0  aux_0.loss: -3.361e-08  cnt.cnt_loss: 69.67  loss: 69.67  time: 0.3583  data_time: 0.0172  lr: 0.001  max_mem: 3221M
[07/07 15:55:49] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 139.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 69.67  loss: 69.67  time: 0.3582  data_time: 0.0139  lr: 0.00065451  max_mem: 3221M
[07/07 15:55:49] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 106.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 53.39  loss: 53.39  time: 0.3579  data_time: 0.0121  lr: 9.5492e-05  max_mem: 3221M
[07/07 15:55:50] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 89.11  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 44.55  loss: 44.55  time: 0.3588  data_time: 0.0109  lr: 0.00090451  max_mem: 3221M
[07/07 15:55:51] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 70.98  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.49  loss: 35.49  time: 0.3584  data_time: 0.0099  lr: 0.00034549  max_mem: 3221M
[07/07 15:55:51] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 70.98  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.49  loss: 35.49  time: 0.3582  data_time: 0.0093  lr: 0.001  max_mem: 3221M
[07/07 15:55:52] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 70.98  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.49  loss: 35.49  time: 0.3582  data_time: 0.0087  lr: 0.00065451  max_mem: 3221M
[07/07 15:55:53] cvalgorithms INFO: Start inference on 216 batches
[07/07 16:17:54] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 16:17:54] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 16:18:22] cvalgorithms INFO: Starting training from iteration 0
[07/07 16:18:26] cvalgorithms INFO:  iter: 1  total_loss: 550.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 275.2  loss: 275.2  data_time: 0.0499  lr: 0.00090451  max_mem: 3221M
[07/07 16:18:26] cvalgorithms INFO:  eta: 0:00:36  iter: 3  total_loss: 335.9  decode.loss_seg: 0  aux_0.loss: -3.49e-07  cnt.cnt_loss: 168  loss: 168  time: 0.3821  data_time: 0.0278  lr: 0.00034549  max_mem: 3221M
[07/07 16:18:27] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 100  decode.loss_seg: 0  aux_0.loss: -3.49e-07  cnt.cnt_loss: 50.02  loss: 50.02  time: 0.3711  data_time: 0.0201  lr: 0.001  max_mem: 3221M
[07/07 16:18:28] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 81.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 40.7  loss: 40.7  time: 0.3657  data_time: 0.0162  lr: 0.00065451  max_mem: 3221M
[07/07 16:18:29] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 78.82  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.41  loss: 39.41  time: 0.3630  data_time: 0.0138  lr: 9.5492e-05  max_mem: 3221M
[07/07 16:18:29] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 78.82  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.41  loss: 39.41  time: 0.3611  data_time: 0.0122  lr: 0.00090451  max_mem: 3221M
[07/07 16:18:30] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 75.08  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.54  loss: 37.54  time: 0.3604  data_time: 0.0111  lr: 0.00034549  max_mem: 3221M
[07/07 16:18:31] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 62.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 31.38  loss: 31.38  time: 0.3595  data_time: 0.0102  lr: 0.001  max_mem: 3221M
[07/07 16:18:31] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 47.16  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.58  loss: 23.58  time: 0.3591  data_time: 0.0096  lr: 0.00065451  max_mem: 3221M
[07/07 16:18:32] cvalgorithms INFO: Start inference on 216 batches
[07/07 17:09:48] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 17:09:48] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 17:10:16] cvalgorithms INFO: Starting training from iteration 0
[07/07 17:10:20] cvalgorithms INFO:  iter: 1  total_loss: 125.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 62.9  loss: 62.9  data_time: 0.0332  lr: 0.00090451  max_mem: 3221M
[07/07 17:10:21] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 39.87  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 19.94  loss: 19.94  time: 0.3540  data_time: 0.0188  lr: 0.00034549  max_mem: 3221M
[07/07 17:10:21] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 68.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.38  loss: 34.38  time: 0.3550  data_time: 0.0140  lr: 0.001  max_mem: 3221M
[07/07 17:10:22] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 101.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.81  loss: 50.81  time: 0.3566  data_time: 0.0117  lr: 0.00065451  max_mem: 3221M
[07/07 17:10:23] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 101.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.81  loss: 50.81  time: 0.3563  data_time: 0.0103  lr: 9.5492e-05  max_mem: 3221M
[07/07 17:10:24] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 68.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.38  loss: 34.38  time: 0.3565  data_time: 0.0093  lr: 0.00090451  max_mem: 3221M
[07/07 17:10:24] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 101.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.81  loss: 50.81  time: 0.3564  data_time: 0.0086  lr: 0.00034549  max_mem: 3221M
[07/07 17:10:25] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 101.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.81  loss: 50.81  time: 0.3562  data_time: 0.0081  lr: 0.001  max_mem: 3221M
[07/07 17:10:26] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 95.49  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 47.74  loss: 47.74  time: 0.3564  data_time: 0.0077  lr: 0.00065451  max_mem: 3221M
[07/07 17:10:26] cvalgorithms INFO: Start inference on 216 batches
[07/07 17:11:09] cvalgorithms INFO: Total inference time: 0:00:12.445983 (0.058986 s / iter per device, on 1 devices)
[07/07 17:11:09] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.053773 s / iter per device, on 1 devices)
[07/07 17:16:43] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/07 17:16:43] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/07 17:17:12] cvalgorithms INFO: Starting training from iteration 0
[07/07 17:17:16] cvalgorithms INFO:  iter: 1  total_loss: 281.6  decode.loss_seg: -0.0009238  aux_0.loss: -4.712e-06  cnt.cnt_loss: 140.8  loss: 140.8  data_time: 0.0446  lr: 0.00090451  max_mem: 3221M
[07/07 17:17:17] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 228.3  decode.loss_seg: -2.138e-05  aux_0.loss: -1.839e-06  cnt.cnt_loss: 114.1  loss: 114.1  time: 0.3574  data_time: 0.0247  lr: 0.00034549  max_mem: 3221M
[07/07 17:17:17] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 122.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 61.03  loss: 61.03  time: 0.3556  data_time: 0.0179  lr: 0.001  max_mem: 3221M
[07/07 17:17:18] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 122.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 61.03  loss: 61.03  time: 0.3568  data_time: 0.0144  lr: 0.00065451  max_mem: 3221M
[07/07 17:17:19] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 122.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 61.03  loss: 61.03  time: 0.3578  data_time: 0.0125  lr: 9.5492e-05  max_mem: 3221M
[07/07 17:17:20] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 166.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 83.22  loss: 83.22  time: 0.3579  data_time: 0.0112  lr: 0.00090451  max_mem: 3221M
[07/07 17:17:20] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 122.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 61.03  loss: 61.03  time: 0.3582  data_time: 0.0102  lr: 0.00034549  max_mem: 3221M
[07/07 17:17:21] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 95.28  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 47.64  loss: 47.64  time: 0.3587  data_time: 0.0095  lr: 0.001  max_mem: 3221M
[07/07 17:17:22] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 71.55  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.78  loss: 35.78  time: 0.3585  data_time: 0.0089  lr: 0.00065451  max_mem: 3221M
[07/07 17:17:22] cvalgorithms INFO: Start inference on 216 batches
[07/07 17:18:04] cvalgorithms INFO: Total inference time: 0:00:12.638635 (0.059899 s / iter per device, on 1 devices)
[07/07 17:18:04] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.055145 s / iter per device, on 1 devices)
[07/07 17:22:05] cvalgorithms INFO: Preparing results for LEVIR-CD format ...
[07/14 11:21:56] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/14 11:21:56] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/14 11:22:26] cvalgorithms INFO: Starting training from iteration 0
[07/14 11:22:35] cvalgorithms INFO:  iter: 1  total_loss: 294.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 147.2  loss: 147.2  data_time: 0.0911  lr: 0.00090451  max_mem: 3221M
[07/14 11:22:36] cvalgorithms INFO:  eta: 0:00:39  iter: 3  total_loss: 220.6  decode.loss_seg: 0  aux_0.loss: 9.127e-08  cnt.cnt_loss: 110.3  loss: 110.3  time: 0.4094  data_time: 0.0660  lr: 0.00034549  max_mem: 3221M
[07/14 11:22:37] cvalgorithms INFO:  eta: 0:00:38  iter: 5  total_loss: 175.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 87.95  loss: 87.95  time: 0.4012  data_time: 0.0510  lr: 0.001  max_mem: 3221M
[07/14 11:22:37] cvalgorithms INFO:  eta: 0:00:36  iter: 7  total_loss: 133  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 66.52  loss: 66.52  time: 0.3924  data_time: 0.0395  lr: 0.00065451  max_mem: 3221M
[07/14 11:22:38] cvalgorithms INFO:  eta: 0:00:34  iter: 9  total_loss: 175.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 87.95  loss: 87.95  time: 0.3885  data_time: 0.0325  lr: 9.5492e-05  max_mem: 3221M
[07/14 11:22:39] cvalgorithms INFO:  eta: 0:00:33  iter: 11  total_loss: 133  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 66.52  loss: 66.52  time: 0.3857  data_time: 0.0279  lr: 0.00090451  max_mem: 3221M
[07/14 11:22:40] cvalgorithms INFO:  eta: 0:00:32  iter: 13  total_loss: 95.72  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 47.86  loss: 47.86  time: 0.3850  data_time: 0.0247  lr: 0.00034549  max_mem: 3221M
[07/14 11:22:41] cvalgorithms INFO:  eta: 0:00:31  iter: 15  total_loss: 87.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.55  loss: 43.55  time: 0.3864  data_time: 0.0223  lr: 0.001  max_mem: 3221M
[07/14 11:22:41] cvalgorithms INFO:  eta: 0:00:31  iter: 17  total_loss: 77.89  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 38.94  loss: 38.94  time: 0.3877  data_time: 0.0204  lr: 0.00065451  max_mem: 3221M
[07/14 11:22:42] cvalgorithms INFO: Start inference on 216 batches
[07/14 11:23:31] cvalgorithms INFO: Total inference time: 0:00:13.185775 (0.062492 s / iter per device, on 1 devices)
[07/14 11:23:31] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056625 s / iter per device, on 1 devices)
[07/27 14:02:34] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/27 14:03:10] cvalgorithms INFO: Starting training from iteration 0
[07/27 14:03:14] cvalgorithms INFO:  iter: 1  total_loss: 617.7  decode.loss_seg: 5.41e-07  aux_0.loss: 0  cnt.cnt_loss: 308.9  loss: 308.9  data_time: 0.0848  lr: 0.00090451  max_mem: 3221M
[07/27 14:03:15] cvalgorithms INFO:  eta: 0:00:36  iter: 3  total_loss: 466.1  decode.loss_seg: 0  aux_0.loss: -7.029e-07  cnt.cnt_loss: 233.1  loss: 233.1  time: 0.3833  data_time: 0.0450  lr: 0.00034549  max_mem: 3221M
[07/27 14:03:16] cvalgorithms INFO:  eta: 0:00:35  iter: 5  total_loss: 344  decode.loss_seg: 0  aux_0.loss: -7.029e-07  cnt.cnt_loss: 172  loss: 172  time: 0.3821  data_time: 0.0317  lr: 0.001  max_mem: 3221M
[07/27 14:03:17] cvalgorithms INFO:  eta: 0:00:35  iter: 7  total_loss: 228.5  decode.loss_seg: 0  aux_0.loss: -2.132e-07  cnt.cnt_loss: 114.2  loss: 114.2  time: 0.3829  data_time: 0.0250  lr: 0.00065451  max_mem: 3221M
[07/27 14:03:17] cvalgorithms INFO:  eta: 0:00:34  iter: 9  total_loss: 143  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 71.49  loss: 71.49  time: 0.3841  data_time: 0.0210  lr: 9.5492e-05  max_mem: 3221M
[07/27 14:03:18] cvalgorithms INFO:  eta: 0:00:33  iter: 11  total_loss: 141  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 70.52  loss: 70.52  time: 0.3835  data_time: 0.0184  lr: 0.00090451  max_mem: 3221M
[07/27 14:03:19] cvalgorithms INFO:  eta: 0:00:33  iter: 13  total_loss: 111.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 55.96  loss: 55.96  time: 0.3866  data_time: 0.0165  lr: 0.00034549  max_mem: 3221M
[07/27 14:03:20] cvalgorithms INFO:  eta: 0:00:32  iter: 15  total_loss: 141  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 70.52  loss: 70.52  time: 0.3881  data_time: 0.0151  lr: 0.001  max_mem: 3221M
[07/27 14:03:21] cvalgorithms INFO:  eta: 0:00:31  iter: 17  total_loss: 111.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 55.96  loss: 55.96  time: 0.3898  data_time: 0.0139  lr: 0.00065451  max_mem: 3221M
[07/27 14:03:21] cvalgorithms INFO: Start inference on 216 batches
[07/27 14:04:08] cvalgorithms INFO: Total inference time: 0:00:13.189716 (0.062511 s / iter per device, on 1 devices)
[07/27 14:04:08] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.057566 s / iter per device, on 1 devices)
[08/01 13:55:22] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[08/01 13:55:55] cvalgorithms INFO: Starting training from iteration 0
[08/01 13:55:59] cvalgorithms INFO:  iter: 1  total_loss: 439.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 219.5  loss: 219.5  data_time: 0.0468  lr: 0.00090451  max_mem: 3221M
[08/01 13:56:00] cvalgorithms INFO:  eta: 0:00:37  iter: 3  total_loss: 204.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 102.1  loss: 102.1  time: 0.3902  data_time: 0.0261  lr: 0.00034549  max_mem: 3221M
[08/01 13:56:01] cvalgorithms INFO:  eta: 0:00:36  iter: 5  total_loss: 147.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 73.8  loss: 73.8  time: 0.3864  data_time: 0.0192  lr: 0.001  max_mem: 3221M
[08/01 13:56:02] cvalgorithms INFO:  eta: 0:00:35  iter: 7  total_loss: 118.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 59.19  loss: 59.19  time: 0.3836  data_time: 0.0158  lr: 0.00065451  max_mem: 3221M
[08/01 13:56:02] cvalgorithms INFO:  eta: 0:00:34  iter: 9  total_loss: 183  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 91.48  loss: 91.48  time: 0.3827  data_time: 0.0136  lr: 9.5492e-05  max_mem: 3221M
[08/01 13:56:03] cvalgorithms INFO:  eta: 0:00:33  iter: 11  total_loss: 183  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 91.48  loss: 91.48  time: 0.3897  data_time: 0.0121  lr: 0.00090451  max_mem: 3221M
[08/01 13:56:04] cvalgorithms INFO:  eta: 0:00:32  iter: 13  total_loss: 129.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 64.92  loss: 64.92  time: 0.3897  data_time: 0.0111  lr: 0.00034549  max_mem: 3221M
[08/01 13:56:05] cvalgorithms INFO:  eta: 0:00:31  iter: 15  total_loss: 96.53  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 48.27  loss: 48.27  time: 0.3880  data_time: 0.0103  lr: 0.001  max_mem: 3221M
[08/01 13:56:05] cvalgorithms INFO:  eta: 0:00:31  iter: 17  total_loss: 84.36  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 42.18  loss: 42.18  time: 0.3865  data_time: 0.0097  lr: 0.00065451  max_mem: 3221M
[08/01 13:56:06] cvalgorithms INFO: Start inference on 216 batches
[08/01 13:56:51] cvalgorithms INFO: Total inference time: 0:00:12.887189 (0.061077 s / iter per device, on 1 devices)
[08/01 13:56:51] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056505 s / iter per device, on 1 devices)
[08/17 14:10:26] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[08/17 14:10:57] cvalgorithms INFO: Starting training from iteration 0
[08/17 14:30:57] cvalgorithms INFO:  iter: 1  total_loss: 435  decode.loss_seg: -1.122e-07  aux_0.loss: 0  cnt.cnt_loss: 217.5  loss: 217.5  data_time: 0.0928  lr: 0.00090451  max_mem: 3249M
[08/23 14:21:42] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[08/23 14:22:12] cvalgorithms INFO: Starting training from iteration 0
[08/23 14:24:15] cvalgorithms INFO:  iter: 1  total_loss: 253.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 126.6  loss: 126.6  data_time: 0.0635  lr: 0.00090451  max_mem: 2675M
[08/23 14:24:15] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 91.89  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 45.94  loss: 45.94  time: 0.3631  data_time: 0.0342  lr: 0.00034549  max_mem: 2675M
[08/23 14:24:16] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 91.89  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 45.94  loss: 45.94  time: 0.3626  data_time: 0.0243  lr: 0.001  max_mem: 2675M
[08/23 14:24:17] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 91.89  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 45.94  loss: 45.94  time: 0.3610  data_time: 0.0193  lr: 0.00065451  max_mem: 2675M
[08/23 14:24:17] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 162.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 81.06  loss: 81.06  time: 0.3603  data_time: 0.0163  lr: 9.5492e-05  max_mem: 2675M
[08/23 14:24:18] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 91.89  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 45.94  loss: 45.94  time: 0.3602  data_time: 0.0144  lr: 0.00090451  max_mem: 2675M
[08/23 14:24:19] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 78.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.35  loss: 39.35  time: 0.3598  data_time: 0.0129  lr: 0.00034549  max_mem: 2675M
[08/23 14:24:20] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 71.73  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.86  loss: 35.86  time: 0.3600  data_time: 0.0118  lr: 0.001  max_mem: 2675M
[08/23 14:24:20] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 71.73  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.86  loss: 35.86  time: 0.3599  data_time: 0.0110  lr: 0.00065451  max_mem: 2675M
[08/23 14:24:21] cvalgorithms INFO: Start inference on 216 batches
[08/23 14:25:05] cvalgorithms INFO: Total inference time: 0:00:13.348508 (0.063263 s / iter per device, on 1 devices)
[08/23 14:25:05] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.057815 s / iter per device, on 1 devices)
[08/23 14:25:05] cvalgorithms INFO: Preparing results for LEVIR-CD format ...
[08/23 14:25:05] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 65.49  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.75  loss: 32.75  time: 0.3598  data_time: 0.0104  lr: 9.5492e-05  max_mem: 2675M
[08/23 14:25:06] cvalgorithms INFO:  eta: 0:00:28  iter: 21  total_loss: 50.76  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 25.38  loss: 25.38  time: 0.3632  data_time: 0.0053  lr: 0.00090451  max_mem: 2675M
[08/23 14:25:06] cvalgorithms INFO:  eta: 0:00:27  iter: 23  total_loss: 39.51  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 19.75  loss: 19.75  time: 0.3665  data_time: 0.0066  lr: 0.00034549  max_mem: 2675M
[08/23 14:25:07] cvalgorithms INFO:  eta: 0:00:26  iter: 25  total_loss: 39.51  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 19.75  loss: 19.75  time: 0.3683  data_time: 0.0066  lr: 0.001  max_mem: 2675M
[08/23 14:25:08] cvalgorithms INFO:  eta: 0:00:26  iter: 27  total_loss: 34.77  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.38  loss: 17.38  time: 0.3697  data_time: 0.0067  lr: 0.00065451  max_mem: 2675M
[08/23 14:25:09] cvalgorithms INFO:  eta: 0:00:25  iter: 29  total_loss: 29.08  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 14.54  loss: 14.54  time: 0.3709  data_time: 0.0067  lr: 9.5492e-05  max_mem: 2675M
[08/23 14:25:10] cvalgorithms INFO:  eta: 0:00:24  iter: 31  total_loss: 24.61  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.31  loss: 12.31  time: 0.3718  data_time: 0.0067  lr: 0.00090451  max_mem: 2675M
[08/23 14:25:10] cvalgorithms INFO:  eta: 0:00:23  iter: 33  total_loss: 20.12  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 10.06  loss: 10.06  time: 0.3726  data_time: 0.0068  lr: 0.00034549  max_mem: 2675M
[08/23 14:25:11] cvalgorithms INFO:  eta: 0:00:23  iter: 35  total_loss: 15.03  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.516  loss: 7.516  time: 0.3734  data_time: 0.0068  lr: 0.001  max_mem: 2675M
[08/23 14:25:12] cvalgorithms INFO:  eta: 0:00:23  iter: 37  total_loss: 13.49  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.747  loss: 6.747  time: 0.3742  data_time: 0.0069  lr: 0.00065451  max_mem: 2675M
[08/23 14:25:13] cvalgorithms INFO: Start inference on 216 batches
[08/23 14:25:57] cvalgorithms INFO: Total inference time: 0:00:12.944482 (0.061348 s / iter per device, on 1 devices)
[08/23 14:25:57] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056416 s / iter per device, on 1 devices)
[08/23 14:25:57] cvalgorithms INFO: Preparing results for LEVIR-CD format ...
[08/23 14:25:57] cvalgorithms INFO:  eta: 0:00:22  iter: 39  total_loss: 13.06  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.531  loss: 6.531  time: 0.3747  data_time: 0.0069  lr: 9.5492e-05  max_mem: 2675M
[08/23 14:25:58] cvalgorithms INFO:  eta: 0:00:22  iter: 41  total_loss: 11.67  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.834  loss: 5.834  time: 0.3759  data_time: 0.0063  lr: 0.00090451  max_mem: 2675M
[08/23 14:25:59] cvalgorithms INFO:  eta: 0:00:21  iter: 43  total_loss: 11.67  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.834  loss: 5.834  time: 0.3764  data_time: 0.0051  lr: 0.00034549  max_mem: 2675M
[08/23 14:26:00] cvalgorithms INFO:  eta: 0:00:20  iter: 45  total_loss: 10.62  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.309  loss: 5.309  time: 0.3773  data_time: 0.0051  lr: 0.001  max_mem: 2675M
[08/23 14:26:00] cvalgorithms INFO:  eta: 0:00:20  iter: 47  total_loss: 8.911  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.456  loss: 4.456  time: 0.3778  data_time: 0.0052  lr: 0.00065451  max_mem: 2675M
[08/23 14:26:01] cvalgorithms INFO:  eta: 0:00:19  iter: 49  total_loss: 8.007  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.004  loss: 4.004  time: 0.3784  data_time: 0.0052  lr: 9.5492e-05  max_mem: 2675M
[08/23 14:26:02] cvalgorithms INFO:  eta: 0:00:18  iter: 51  total_loss: 7.342  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.671  loss: 3.671  time: 0.3788  data_time: 0.0053  lr: 0.00090451  max_mem: 2675M
[08/23 14:26:03] cvalgorithms INFO:  eta: 0:00:17  iter: 53  total_loss: 6.095  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.047  loss: 3.047  time: 0.3795  data_time: 0.0053  lr: 0.00034549  max_mem: 2675M
[08/23 14:26:04] cvalgorithms INFO:  eta: 0:00:16  iter: 55  total_loss: 5.168  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.584  loss: 2.584  time: 0.3802  data_time: 0.0053  lr: 0.001  max_mem: 2675M
[08/23 14:26:04] cvalgorithms INFO:  eta: 0:00:16  iter: 57  total_loss: 4.148  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.074  loss: 2.074  time: 0.3807  data_time: 0.0053  lr: 0.00065451  max_mem: 2675M
[08/23 14:26:05] cvalgorithms INFO: Start inference on 216 batches
[08/23 14:27:10] cvalgorithms INFO: Total inference time: 0:00:12.899622 (0.061136 s / iter per device, on 1 devices)
[08/23 14:27:10] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056507 s / iter per device, on 1 devices)
[08/23 14:27:10] cvalgorithms INFO: Preparing results for LEVIR-CD format ...
[08/23 14:27:10] cvalgorithms INFO:  eta: 0:00:15  iter: 59  total_loss: 3.918  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.959  loss: 1.959  time: 0.3812  data_time: 0.0053  lr: 9.5492e-05  max_mem: 2675M
[08/23 14:27:11] cvalgorithms INFO:  eta: 0:00:14  iter: 61  total_loss: 3.767  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.884  loss: 1.884  time: 0.3825  data_time: 0.0053  lr: 0.00090451  max_mem: 2675M
[08/23 14:27:12] cvalgorithms INFO:  eta: 0:00:13  iter: 63  total_loss: 3.254  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.627  loss: 1.627  time: 0.3843  data_time: 0.0054  lr: 0.00034549  max_mem: 2675M
[08/23 14:27:13] cvalgorithms INFO:  eta: 0:00:13  iter: 65  total_loss: 2.663  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.331  loss: 1.331  time: 0.3848  data_time: 0.0054  lr: 0.001  max_mem: 2675M
[08/23 14:27:13] cvalgorithms INFO:  eta: 0:00:12  iter: 67  total_loss: 2.663  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.331  loss: 1.331  time: 0.3854  data_time: 0.0054  lr: 0.00065451  max_mem: 2675M
[08/23 14:27:14] cvalgorithms INFO:  eta: 0:00:11  iter: 69  total_loss: 2.419  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.21  loss: 1.21  time: 0.3867  data_time: 0.0055  lr: 9.5492e-05  max_mem: 2675M
[08/23 14:27:15] cvalgorithms INFO:  eta: 0:00:10  iter: 71  total_loss: 2.419  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.21  loss: 1.21  time: 0.3872  data_time: 0.0055  lr: 0.00090451  max_mem: 2675M
[08/23 14:27:16] cvalgorithms INFO:  eta: 0:00:10  iter: 73  total_loss: 2.419  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.21  loss: 1.21  time: 0.3873  data_time: 0.0055  lr: 0.00034549  max_mem: 2675M
[08/23 14:27:17] cvalgorithms INFO:  eta: 0:00:09  iter: 75  total_loss: 2.419  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.21  loss: 1.21  time: 0.3875  data_time: 0.0055  lr: 0.001  max_mem: 2675M
[08/23 14:27:18] cvalgorithms INFO:  eta: 0:00:08  iter: 77  total_loss: 2.112  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.056  loss: 1.056  time: 0.3876  data_time: 0.0056  lr: 0.00065451  max_mem: 2675M
[08/23 14:27:18] cvalgorithms INFO: Start inference on 216 batches
[08/23 14:28:06] cvalgorithms INFO: Total inference time: 0:00:13.263790 (0.062862 s / iter per device, on 1 devices)
[08/23 14:28:06] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.058607 s / iter per device, on 1 devices)
[08/23 14:28:06] cvalgorithms INFO: Preparing results for LEVIR-CD format ...
[08/23 14:28:06] cvalgorithms INFO:  eta: 0:00:07  iter: 79  total_loss: 2.112  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.056  loss: 1.056  time: 0.3880  data_time: 0.0056  lr: 9.5492e-05  max_mem: 2675M
[08/23 14:28:07] cvalgorithms INFO:  eta: 0:00:07  iter: 81  total_loss: 2.112  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.056  loss: 1.056  time: 0.3884  data_time: 0.0055  lr: 0.00090451  max_mem: 2675M
[08/23 14:28:08] cvalgorithms INFO:  eta: 0:00:06  iter: 83  total_loss: 2.648  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.324  loss: 1.324  time: 0.3888  data_time: 0.0054  lr: 0.00034549  max_mem: 2675M
[08/23 14:28:09] cvalgorithms INFO:  eta: 0:00:05  iter: 85  total_loss: 2.179  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.089  loss: 1.089  time: 0.3906  data_time: 0.0055  lr: 0.001  max_mem: 2675M
[08/23 14:28:10] cvalgorithms INFO:  eta: 0:00:04  iter: 87  total_loss: 1.714  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8569  loss: 0.8569  time: 0.3911  data_time: 0.0057  lr: 0.00065451  max_mem: 2675M
[08/23 14:28:11] cvalgorithms INFO:  eta: 0:00:03  iter: 89  total_loss: 1.714  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8569  loss: 0.8569  time: 0.3913  data_time: 0.0056  lr: 9.5492e-05  max_mem: 2675M
[08/23 14:28:11] cvalgorithms INFO:  eta: 0:00:03  iter: 91  total_loss: 1.547  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7737  loss: 0.7737  time: 0.3915  data_time: 0.0057  lr: 0.00090451  max_mem: 2675M
[08/23 14:28:12] cvalgorithms INFO:  eta: 0:00:02  iter: 93  total_loss: 1.38  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.69  loss: 0.69  time: 0.3918  data_time: 0.0056  lr: 0.00034549  max_mem: 2675M
[08/23 14:28:13] cvalgorithms INFO:  eta: 0:00:01  iter: 95  total_loss: 1.547  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7737  loss: 0.7737  time: 0.3922  data_time: 0.0056  lr: 0.001  max_mem: 2675M
[08/23 14:28:14] cvalgorithms INFO:  eta: 0:00:00  iter: 97  total_loss: 1.581  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7905  loss: 0.7905  time: 0.3929  data_time: 0.0057  lr: 0.00065451  max_mem: 2675M
[08/23 14:28:15] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.584  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7919  loss: 0.7919  time: 0.3957  data_time: 0.0058  lr: 9.5492e-05  max_mem: 2675M
[08/23 14:28:15] cvalgorithms INFO: Start inference on 216 batches
[08/23 14:29:07] cvalgorithms INFO: Total inference time: 0:00:12.989784 (0.061563 s / iter per device, on 1 devices)
[08/23 14:29:07] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056832 s / iter per device, on 1 devices)
[08/23 14:29:07] cvalgorithms INFO: Preparing results for LEVIR-CD format ...
[08/23 14:29:07] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.584  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7919  loss: 0.7919  time: 0.3957  data_time: 0.0058  lr: 9.5492e-05  max_mem: 2675M
[08/23 14:57:21] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[08/23 14:57:51] cvalgorithms INFO: Starting training from iteration 0
[08/23 14:57:55] cvalgorithms INFO:  iter: 1  total_loss: 454.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 227.1  loss: 227.1  data_time: 0.0608  lr: 0.00090451  max_mem: 3221M
[08/23 14:57:56] cvalgorithms INFO:  eta: 0:00:35  iter: 3  total_loss: 311.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 155.8  loss: 155.8  time: 0.3730  data_time: 0.0328  lr: 0.00034549  max_mem: 3221M
[08/23 14:57:57] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 235.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 117.9  loss: 117.9  time: 0.3697  data_time: 0.0236  lr: 0.001  max_mem: 3221M
[08/23 14:57:58] cvalgorithms INFO:  eta: 0:00:34  iter: 7  total_loss: 146.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 73.27  loss: 73.27  time: 0.3710  data_time: 0.0189  lr: 0.00065451  max_mem: 3221M
[08/23 14:57:58] cvalgorithms INFO:  eta: 0:00:33  iter: 9  total_loss: 151.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 75.78  loss: 75.78  time: 0.3703  data_time: 0.0160  lr: 9.5492e-05  max_mem: 3221M
[08/23 14:57:59] cvalgorithms INFO:  eta: 0:00:32  iter: 11  total_loss: 97.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 48.55  loss: 48.55  time: 0.3699  data_time: 0.0141  lr: 0.00090451  max_mem: 3221M
[08/23 14:58:00] cvalgorithms INFO:  eta: 0:00:31  iter: 13  total_loss: 85.48  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 42.74  loss: 42.74  time: 0.3697  data_time: 0.0128  lr: 0.00034549  max_mem: 3221M
[08/23 14:58:00] cvalgorithms INFO:  eta: 0:00:31  iter: 15  total_loss: 78.33  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.17  loss: 39.17  time: 0.3697  data_time: 0.0118  lr: 0.001  max_mem: 3221M
[08/23 14:58:01] cvalgorithms INFO:  eta: 0:00:30  iter: 17  total_loss: 74.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.07  loss: 37.07  time: 0.3700  data_time: 0.0110  lr: 0.00065451  max_mem: 3221M
[08/23 14:58:02] cvalgorithms INFO: Start inference on 216 batches
[08/23 15:03:48] cvalgorithms INFO: Total inference time: 0:00:12.280105 (0.058200 s / iter per device, on 1 devices)
[08/23 15:03:48] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.053565 s / iter per device, on 1 devices)
[08/26 14:48:38] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[08/26 14:49:08] cvalgorithms INFO: Starting training from iteration 0
[08/26 14:49:12] cvalgorithms INFO:  iter: 1  total_loss: 196.7  decode.loss_seg: -1.772e-13  aux_0.loss: 0  cnt.cnt_loss: 98.35  loss: 98.35  data_time: 0.0536  lr: 0.00090451  max_mem: 3221M
[08/26 14:49:13] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 223.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 111.7  loss: 111.7  time: 0.3523  data_time: 0.0292  lr: 0.00034549  max_mem: 3221M
[08/26 14:49:14] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 102.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 51.13  loss: 51.13  time: 0.3520  data_time: 0.0209  lr: 0.001  max_mem: 3221M
[08/26 14:49:14] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 104.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 52.19  loss: 52.19  time: 0.3550  data_time: 0.0168  lr: 0.00065451  max_mem: 3221M
[08/26 14:49:15] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 74.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.1  loss: 37.1  time: 0.3538  data_time: 0.0143  lr: 9.5492e-05  max_mem: 3221M
[08/26 14:49:16] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 61.95  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 30.97  loss: 30.97  time: 0.3542  data_time: 0.0126  lr: 0.00090451  max_mem: 3221M
[08/26 14:49:17] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 61.95  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 30.97  loss: 30.97  time: 0.3538  data_time: 0.0115  lr: 0.00034549  max_mem: 3221M
[08/26 14:49:17] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 55.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.95  loss: 27.95  time: 0.3542  data_time: 0.0106  lr: 0.001  max_mem: 3221M
[08/26 14:49:18] cvalgorithms INFO:  eta: 0:00:28  iter: 17  total_loss: 50.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 25.42  loss: 25.42  time: 0.3541  data_time: 0.0099  lr: 0.00065451  max_mem: 3221M
[08/26 14:49:19] cvalgorithms INFO: Start inference on 216 batches
[08/26 14:49:59] cvalgorithms INFO: Total inference time: 0:00:12.077652 (0.057240 s / iter per device, on 1 devices)
[08/26 14:49:59] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.052307 s / iter per device, on 1 devices)
[09/01 16:14:56] cvalgorithms INFO: Preparing results for LEVIR-CD format ...
[09/01 16:14:56] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 46.61  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.3  loss: 23.3  time: 0.3546  data_time: 0.0093  lr: 9.5492e-05  max_mem: 3221M
[09/06 13:52:02] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 13:52:37] cvalgorithms INFO: Starting training from iteration 0
[09/06 14:08:14] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 14:08:53] cvalgorithms INFO: Starting training from iteration 0
[09/06 14:09:02] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 123, in train
    self.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 127, in run_step
    self._trainer.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 211, in run_step
    loss_dict = self.model(_img, ground_truth=_ground_truth, return_metrics=True)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 306, in forward
    metrics = self.forward_train(inputs, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 221, in forward_train
    aux, ground_truth)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 166, in _auxiliary_head_forward_train
    loss_aux = aux_head.forward_train(x, ground_truth)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\decode_heads\decode_head.py", line 196, in forward_train
    seg_logits = self.forward(inputs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\decode_heads\fcn_head.py", line 83, in forward
    output = self.convs(x)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\container.py", line 119, in forward
    input = module(input)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\base\blocks\conv_module.py", line 201, in forward
    x = self.conv(x)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\conv.py", line 399, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\conv.py", line 396, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [64, 768, 3, 3], expected input[2, 192, 14, 14] to have 768 channels, but got 192 channels instead
[09/06 14:09:02] cvalgorithms INFO:  iter: 0    lr: N/A  max_mem: 3178M
[09/06 14:10:55] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 14:11:29] cvalgorithms INFO: Starting training from iteration 0
[09/06 14:11:32] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 123, in train
    self.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 127, in run_step
    self._trainer.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 211, in run_step
    loss_dict = self.model(_img, ground_truth=_ground_truth, return_metrics=True)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 306, in forward
    metrics = self.forward_train(inputs, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 221, in forward_train
    aux, ground_truth)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 166, in _auxiliary_head_forward_train
    loss_aux = aux_head.forward_train(x, ground_truth)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\decode_heads\decode_head.py", line 196, in forward_train
    seg_logits = self.forward(inputs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\decode_heads\fcn_head.py", line 83, in forward
    output = self.convs(x)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\container.py", line 119, in forward
    input = module(input)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\base\blocks\conv_module.py", line 201, in forward
    x = self.conv(x)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\conv.py", line 399, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\conv.py", line 396, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [64, 768, 3, 3], expected input[2, 192, 14, 14] to have 768 channels, but got 192 channels instead
[09/06 14:11:32] cvalgorithms INFO:  iter: 0    lr: N/A  max_mem: 3178M
[09/06 14:13:20] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 14:13:54] cvalgorithms INFO: Starting training from iteration 0
[09/06 14:13:58] cvalgorithms INFO:  iter: 1  total_loss: 316.8  decode.loss_seg: 0.002501  aux_0.loss: -4.605e-06  cnt.cnt_loss: 158.4  loss: 158.4  data_time: 0.0653  lr: 0.00090451  max_mem: 3207M
[09/06 14:13:59] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 316.8  decode.loss_seg: 0.00105  aux_0.loss: -1.19e-06  cnt.cnt_loss: 158.4  loss: 158.4  time: 0.3613  data_time: 0.0350  lr: 0.00034549  max_mem: 3207M
[09/06 14:14:00] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 249.6  decode.loss_seg: 0  aux_0.loss: -1.507e-08  cnt.cnt_loss: 124.8  loss: 124.8  time: 0.3629  data_time: 0.0250  lr: 0.001  max_mem: 3207M
[09/06 14:14:01] cvalgorithms INFO:  eta: 0:00:33  iter: 7  total_loss: 140.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 70.46  loss: 70.46  time: 0.3630  data_time: 0.0200  lr: 0.00065451  max_mem: 3207M
[09/06 14:14:01] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 98.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 49.41  loss: 49.41  time: 0.3623  data_time: 0.0170  lr: 9.5492e-05  max_mem: 3207M
[09/06 14:14:02] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 84.93  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 42.47  loss: 42.47  time: 0.3650  data_time: 0.0150  lr: 0.00090451  max_mem: 3207M
[09/06 14:14:03] cvalgorithms INFO:  eta: 0:00:31  iter: 13  total_loss: 84.93  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 42.47  loss: 42.47  time: 0.3651  data_time: 0.0136  lr: 0.00034549  max_mem: 3207M
[09/06 14:14:04] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 75.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.99  loss: 37.99  time: 0.3644  data_time: 0.0125  lr: 0.001  max_mem: 3207M
[09/06 14:14:04] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 66.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.15  loss: 33.15  time: 0.3643  data_time: 0.0117  lr: 0.00065451  max_mem: 3207M
[09/06 14:14:05] cvalgorithms INFO: Start inference on 216 batches
[09/06 14:14:52] cvalgorithms INFO: Total inference time: 0:00:13.529581 (0.064121 s / iter per device, on 1 devices)
[09/06 14:14:52] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.058007 s / iter per device, on 1 devices)
[09/06 14:16:13] cvalgorithms INFO: Preparing results for LEVIR-CD format ...
[09/06 14:16:13] cvalgorithms INFO:  eta: 0:00:29  iter: 19  total_loss: 51.65  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 25.83  loss: 25.83  time: 0.3641  data_time: 0.0110  lr: 9.5492e-05  max_mem: 3207M
[09/06 14:16:14] cvalgorithms INFO:  eta: 0:00:28  iter: 21  total_loss: 39.73  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 19.86  loss: 19.86  time: 0.3766  data_time: 0.0052  lr: 0.00090451  max_mem: 3207M
[09/06 14:16:15] cvalgorithms INFO:  eta: 0:00:27  iter: 23  total_loss: 36.63  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 18.31  loss: 18.31  time: 0.3743  data_time: 0.0053  lr: 0.00034549  max_mem: 3207M
[09/06 14:16:15] cvalgorithms INFO:  eta: 0:00:26  iter: 25  total_loss: 32.58  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.29  loss: 16.29  time: 0.3726  data_time: 0.0052  lr: 0.001  max_mem: 3207M
[09/06 14:16:16] cvalgorithms INFO:  eta: 0:00:26  iter: 27  total_loss: 26.61  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 13.3  loss: 13.3  time: 0.3716  data_time: 0.0052  lr: 0.00065451  max_mem: 3207M
[09/06 14:16:17] cvalgorithms INFO:  eta: 0:00:25  iter: 29  total_loss: 23.43  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 11.71  loss: 11.71  time: 0.3719  data_time: 0.0052  lr: 9.5492e-05  max_mem: 3207M
[09/06 14:16:18] cvalgorithms INFO:  eta: 0:00:24  iter: 31  total_loss: 21.78  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 10.89  loss: 10.89  time: 0.3716  data_time: 0.0052  lr: 0.00090451  max_mem: 3207M
[09/06 14:16:18] cvalgorithms INFO:  eta: 0:00:23  iter: 33  total_loss: 16.85  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 8.426  loss: 8.426  time: 0.3724  data_time: 0.0052  lr: 0.00034549  max_mem: 3207M
[09/06 14:16:19] cvalgorithms INFO:  eta: 0:00:23  iter: 35  total_loss: 12.04  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.018  loss: 6.018  time: 0.3754  data_time: 0.0055  lr: 0.001  max_mem: 3207M
[09/06 14:16:20] cvalgorithms INFO:  eta: 0:00:22  iter: 37  total_loss: 9.686  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.843  loss: 4.843  time: 0.3755  data_time: 0.0056  lr: 0.00065451  max_mem: 3207M
[09/06 14:19:42] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 14:20:12] cvalgorithms INFO: Starting training from iteration 0
[09/06 14:20:15] cvalgorithms INFO:  iter: 1  total_loss: 336.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 168.3  loss: 168.3  data_time: 0.0423  lr: 0.00090451  max_mem: 2014M
[09/06 14:20:16] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 123, in train
    self.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 127, in run_step
    self._trainer.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 220, in run_step
    losses.backward()
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\autograd\__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
RuntimeError: CUDA error: an illegal memory access was encountered
[09/06 14:20:16] cvalgorithms INFO:  eta: 0:00:14  iter: 3  total_loss: 246.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 123.1  loss: 123.1  time: 0.1555  data_time: 0.0289  lr: 0.00065451  max_mem: 2014M
[09/06 14:37:07] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 14:59:24] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 14:59:58] cvalgorithms INFO: Starting training from iteration 0
[09/06 15:00:01] cvalgorithms INFO:  iter: 1  total_loss: 331  decode.loss_seg: 0.001327  aux_0.loss: 7.212e-07  cnt.cnt_loss: 165.5  loss: 165.5  data_time: 0.0577  lr: 0.00090451  max_mem: 3207M
[09/06 15:00:02] cvalgorithms INFO:  eta: 0:00:35  iter: 3  total_loss: 331  decode.loss_seg: 0  aux_0.loss: 2.653e-07  cnt.cnt_loss: 165.5  loss: 165.5  time: 0.3718  data_time: 0.0312  lr: 0.00034549  max_mem: 3207M
[09/06 15:00:03] cvalgorithms INFO:  eta: 0:00:35  iter: 5  total_loss: 198.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 99.06  loss: 99.06  time: 0.3724  data_time: 0.0224  lr: 0.001  max_mem: 3207M
[09/06 15:00:04] cvalgorithms INFO:  eta: 0:00:34  iter: 7  total_loss: 107.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 53.94  loss: 53.94  time: 0.3800  data_time: 0.0184  lr: 0.00065451  max_mem: 3207M
[09/06 15:00:04] cvalgorithms INFO:  eta: 0:00:34  iter: 9  total_loss: 107.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 53.94  loss: 53.94  time: 0.3808  data_time: 0.0156  lr: 9.5492e-05  max_mem: 3207M
[09/06 15:00:05] cvalgorithms INFO:  eta: 0:00:33  iter: 11  total_loss: 90.52  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 45.26  loss: 45.26  time: 0.3802  data_time: 0.0138  lr: 0.00090451  max_mem: 3207M
[09/06 15:00:06] cvalgorithms INFO:  eta: 0:00:32  iter: 13  total_loss: 77.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 38.87  loss: 38.87  time: 0.3794  data_time: 0.0125  lr: 0.00034549  max_mem: 3207M
[09/06 15:00:07] cvalgorithms INFO:  eta: 0:00:31  iter: 15  total_loss: 65.49  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.75  loss: 32.75  time: 0.3792  data_time: 0.0115  lr: 0.001  max_mem: 3207M
[09/06 15:00:08] cvalgorithms INFO:  eta: 0:00:31  iter: 17  total_loss: 65.49  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.75  loss: 32.75  time: 0.3801  data_time: 0.0107  lr: 0.00065451  max_mem: 3207M
[09/06 15:00:08] cvalgorithms INFO: Start inference on 216 batches
[09/06 15:00:56] cvalgorithms INFO: Total inference time: 0:00:12.643265 (0.059921 s / iter per device, on 1 devices)
[09/06 15:00:56] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.055800 s / iter per device, on 1 devices)
[09/06 15:26:18] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 15:26:49] cvalgorithms INFO: Starting training from iteration 0
[09/06 15:26:53] cvalgorithms INFO:  iter: 1  total_loss: 341  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 170.5  loss: 170.5  data_time: 0.0832  lr: 0.00090451  max_mem: 3207M
[09/06 15:26:53] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 341  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 170.5  loss: 170.5  time: 0.3506  data_time: 0.0446  lr: 0.00034549  max_mem: 3207M
[09/06 15:26:54] cvalgorithms INFO:  eta: 0:00:32  iter: 5  total_loss: 267  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 133.5  loss: 133.5  time: 0.3511  data_time: 0.0311  lr: 0.001  max_mem: 3207M
[09/06 15:26:55] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 222.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 111  loss: 111  time: 0.3510  data_time: 0.0244  lr: 0.00065451  max_mem: 3207M
[09/06 15:26:56] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 190.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 95.21  loss: 95.21  time: 0.3541  data_time: 0.0205  lr: 9.5492e-05  max_mem: 3207M
[09/06 15:26:56] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 140.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 70.26  loss: 70.26  time: 0.3541  data_time: 0.0179  lr: 0.00090451  max_mem: 3207M
[09/06 15:26:57] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 93.32  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 46.66  loss: 46.66  time: 0.3539  data_time: 0.0160  lr: 0.00034549  max_mem: 3207M
[09/06 15:26:58] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 86.33  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.17  loss: 43.17  time: 0.3537  data_time: 0.0145  lr: 0.001  max_mem: 3207M
[09/06 15:26:58] cvalgorithms INFO:  eta: 0:00:28  iter: 17  total_loss: 71.58  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.79  loss: 35.79  time: 0.3534  data_time: 0.0134  lr: 0.00065451  max_mem: 3207M
[09/06 15:26:59] cvalgorithms INFO: Start inference on 216 batches
[09/06 15:27:43] cvalgorithms INFO: Total inference time: 0:00:12.429457 (0.058907 s / iter per device, on 1 devices)
[09/06 15:27:43] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.054029 s / iter per device, on 1 devices)
[09/06 15:35:04] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 15:35:34] cvalgorithms INFO: Starting training from iteration 0
[09/06 15:35:38] cvalgorithms INFO:  iter: 1  total_loss: 215.4  decode.loss_seg: -5.444e-05  aux_0.loss: 1.026e-06  cnt.cnt_loss: 107.7  loss: 107.7  data_time: 0.0749  lr: 0.00090451  max_mem: 3207M
[09/06 15:35:38] cvalgorithms INFO:  eta: 0:00:35  iter: 3  total_loss: 77.94  decode.loss_seg: 5.219e-10  aux_0.loss: -4.756e-08  cnt.cnt_loss: 38.97  loss: 38.97  time: 0.3673  data_time: 0.0404  lr: 0.00034549  max_mem: 3207M
[09/06 15:35:39] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 78.37  decode.loss_seg: 5.219e-10  aux_0.loss: 1.094e-07  cnt.cnt_loss: 39.19  loss: 39.19  time: 0.3558  data_time: 0.0283  lr: 0.001  max_mem: 3207M
[09/06 15:35:40] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 78.37  decode.loss_seg: 5.219e-10  aux_0.loss: 1.094e-07  cnt.cnt_loss: 39.19  loss: 39.19  time: 0.3537  data_time: 0.0223  lr: 0.00065451  max_mem: 3207M
[09/06 15:35:40] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 86.23  decode.loss_seg: 4.003e-13  aux_0.loss: 1.094e-07  cnt.cnt_loss: 43.12  loss: 43.12  time: 0.3529  data_time: 0.0187  lr: 9.5492e-05  max_mem: 3207M
[09/06 15:35:41] cvalgorithms INFO:  eta: 0:00:30  iter: 11  total_loss: 79.98  decode.loss_seg: 4.003e-13  aux_0.loss: 1.094e-07  cnt.cnt_loss: 39.99  loss: 39.99  time: 0.3523  data_time: 0.0163  lr: 0.00090451  max_mem: 3207M
[09/06 15:35:42] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 86.23  decode.loss_seg: 4.003e-13  aux_0.loss: 0  cnt.cnt_loss: 43.12  loss: 43.12  time: 0.3518  data_time: 0.0146  lr: 0.00034549  max_mem: 3207M
[09/06 15:35:42] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 79.98  decode.loss_seg: 4.003e-13  aux_0.loss: 0  cnt.cnt_loss: 39.99  loss: 39.99  time: 0.3520  data_time: 0.0134  lr: 0.001  max_mem: 3207M
[09/06 15:35:43] cvalgorithms INFO:  eta: 0:00:28  iter: 17  total_loss: 72.13  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 36.06  loss: 36.06  time: 0.3532  data_time: 0.0124  lr: 0.00065451  max_mem: 3207M
[09/06 15:35:44] cvalgorithms INFO: Start inference on 216 batches
[09/06 15:36:28] cvalgorithms INFO: Total inference time: 0:00:12.379344 (0.058670 s / iter per device, on 1 devices)
[09/06 15:36:28] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.054075 s / iter per device, on 1 devices)
[09/06 16:00:24] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 16:00:54] cvalgorithms INFO: Starting training from iteration 0
[09/06 16:00:57] cvalgorithms INFO:  iter: 1  total_loss: 246.5  decode.loss_seg: 0.0002392  aux_0.loss: -1.852e-07  cnt.cnt_loss: 123.3  loss: 123.3  data_time: 0.0502  lr: 0.00090451  max_mem: 3207M
[09/06 16:00:58] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 139.2  decode.loss_seg: 0  aux_0.loss: -1.839e-07  cnt.cnt_loss: 69.59  loss: 69.59  time: 0.3557  data_time: 0.0273  lr: 0.00034549  max_mem: 3207M
[09/06 16:00:59] cvalgorithms INFO:  eta: 0:00:32  iter: 5  total_loss: 96.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 48.49  loss: 48.49  time: 0.3515  data_time: 0.0196  lr: 0.001  max_mem: 3207M
[09/06 16:00:59] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 96.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 48.49  loss: 48.49  time: 0.3520  data_time: 0.0158  lr: 0.00065451  max_mem: 3207M
[09/06 16:01:00] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 96.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 48.49  loss: 48.49  time: 0.3516  data_time: 0.0135  lr: 9.5492e-05  max_mem: 3207M
[09/06 16:01:01] cvalgorithms INFO:  eta: 0:00:30  iter: 11  total_loss: 80.26  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 40.13  loss: 40.13  time: 0.3524  data_time: 0.0120  lr: 0.00090451  max_mem: 3207M
[09/06 16:01:02] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 64.53  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.26  loss: 32.26  time: 0.3523  data_time: 0.0109  lr: 0.00034549  max_mem: 3207M
[09/06 16:01:02] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 54.53  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.26  loss: 27.26  time: 0.3521  data_time: 0.0101  lr: 0.001  max_mem: 3207M
[09/06 16:01:03] cvalgorithms INFO:  eta: 0:00:28  iter: 17  total_loss: 37.13  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 18.56  loss: 18.56  time: 0.3521  data_time: 0.0094  lr: 0.00065451  max_mem: 3207M
[09/06 16:04:58] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 16:05:28] cvalgorithms INFO: Starting training from iteration 0
[09/06 16:05:32] cvalgorithms INFO:  iter: 1  total_loss: 336.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 168.1  loss: 168.1  data_time: 0.0775  lr: 0.00090451  max_mem: 3207M
[09/06 16:05:32] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 252.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 126.3  loss: 126.3  time: 0.3487  data_time: 0.0409  lr: 0.00034549  max_mem: 3207M
[09/06 16:05:33] cvalgorithms INFO:  eta: 0:00:32  iter: 5  total_loss: 211.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 105.5  loss: 105.5  time: 0.3492  data_time: 0.0287  lr: 0.001  max_mem: 3207M
[09/06 16:05:34] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 211.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 105.5  loss: 105.5  time: 0.3519  data_time: 0.0229  lr: 0.00065451  max_mem: 3207M
[09/06 16:05:34] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 167.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 83.77  loss: 83.77  time: 0.3515  data_time: 0.0193  lr: 9.5492e-05  max_mem: 3207M
[09/06 16:05:35] cvalgorithms INFO:  eta: 0:00:30  iter: 11  total_loss: 136.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 68.35  loss: 68.35  time: 0.3538  data_time: 0.0168  lr: 0.00090451  max_mem: 3207M
[09/06 16:05:36] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 128.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 64.26  loss: 64.26  time: 0.3531  data_time: 0.0150  lr: 0.00034549  max_mem: 3207M
[09/06 16:05:36] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 100.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.32  loss: 50.32  time: 0.3530  data_time: 0.0137  lr: 0.001  max_mem: 3207M
[09/06 16:05:37] cvalgorithms INFO:  eta: 0:00:28  iter: 17  total_loss: 84.85  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 42.43  loss: 42.43  time: 0.3529  data_time: 0.0127  lr: 0.00065451  max_mem: 3207M
[09/06 18:25:56] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 18:26:26] cvalgorithms INFO: Starting training from iteration 0
[09/06 18:26:32] cvalgorithms INFO:  iter: 1  total_loss: 422.4  decode.loss_seg: 0.001868  aux_0.loss: -3.044e-05  cnt.cnt_loss: 211.2  loss: 211.2  data_time: 0.0599  lr: 0.00090451  max_mem: 2413M
[09/06 18:26:33] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 211  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 105.5  loss: 105.5  time: 0.3502  data_time: 0.0323  lr: 0.00034549  max_mem: 2413M
[09/06 18:26:33] cvalgorithms INFO:  eta: 0:00:32  iter: 5  total_loss: 169.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 84.84  loss: 84.84  time: 0.3499  data_time: 0.0230  lr: 0.001  max_mem: 2413M
[09/06 18:26:34] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 135.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 67.75  loss: 67.75  time: 0.3489  data_time: 0.0183  lr: 0.00065451  max_mem: 2413M
[09/06 18:26:35] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 135.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 67.75  loss: 67.75  time: 0.3494  data_time: 0.0156  lr: 9.5492e-05  max_mem: 2413M
[09/06 18:26:35] cvalgorithms INFO:  eta: 0:00:30  iter: 11  total_loss: 122.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 61.1  loss: 61.1  time: 0.3497  data_time: 0.0137  lr: 0.00090451  max_mem: 2413M
[09/06 18:26:36] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 122.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 61.1  loss: 61.1  time: 0.3500  data_time: 0.0124  lr: 0.00034549  max_mem: 2413M
[09/06 18:26:37] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 115.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 57.86  loss: 57.86  time: 0.3502  data_time: 0.0114  lr: 0.001  max_mem: 2413M
[09/06 18:26:37] cvalgorithms INFO:  eta: 0:00:28  iter: 17  total_loss: 101.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.55  loss: 50.55  time: 0.3505  data_time: 0.0106  lr: 0.00065451  max_mem: 2413M
[09/06 18:27:16] cvalgorithms INFO: Start inference on 216 batches
[09/06 18:27:57] cvalgorithms INFO: Total inference time: 0:00:11.743172 (0.055655 s / iter per device, on 1 devices)
[09/06 18:27:57] cvalgorithms INFO: Total inference pure compute time: 0:00:10 (0.051267 s / iter per device, on 1 devices)
[09/06 20:06:39] cvalgorithms INFO: Preparing results for LEVIR-CD format ...
[09/06 20:24:16] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 20:24:45] cvalgorithms INFO: Starting training from iteration 0
[09/06 20:24:48] cvalgorithms INFO:  iter: 1  total_loss: 234.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 117.3  loss: 117.3  data_time: 0.0746  lr: 0.00090451  max_mem: 2413M
[09/06 20:24:49] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 118.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 59.13  loss: 59.13  time: 0.3485  data_time: 0.0396  lr: 0.00034549  max_mem: 2413M
[09/06 20:24:49] cvalgorithms INFO:  eta: 0:00:32  iter: 5  total_loss: 118.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 59.13  loss: 59.13  time: 0.3488  data_time: 0.0279  lr: 0.001  max_mem: 2413M
[09/06 20:24:50] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 134.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 67.21  loss: 67.21  time: 0.3489  data_time: 0.0220  lr: 0.00065451  max_mem: 2413M
[09/06 20:24:51] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 83.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.88  loss: 41.88  time: 0.3499  data_time: 0.0186  lr: 9.5492e-05  max_mem: 2413M
[09/06 20:24:51] cvalgorithms INFO:  eta: 0:00:30  iter: 11  total_loss: 78.86  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.43  loss: 39.43  time: 0.3501  data_time: 0.0162  lr: 0.00090451  max_mem: 2413M
[09/06 20:24:52] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 77.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 38.87  loss: 38.87  time: 0.3505  data_time: 0.0147  lr: 0.00034549  max_mem: 2413M
[09/06 20:24:53] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 68.46  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.23  loss: 34.23  time: 0.3504  data_time: 0.0135  lr: 0.001  max_mem: 2413M
[09/06 20:24:54] cvalgorithms INFO:  eta: 0:00:28  iter: 17  total_loss: 68.46  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.23  loss: 34.23  time: 0.3508  data_time: 0.0125  lr: 0.00065451  max_mem: 2413M
[09/06 20:25:41] cvalgorithms INFO: Start inference on 216 batches
[09/06 21:56:22] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 21:56:51] cvalgorithms INFO: Starting training from iteration 0
[09/06 21:56:54] cvalgorithms INFO:  iter: 1  total_loss: 248.9  decode.loss_seg: -0.004555  aux_0.loss: 1.232e-05  cnt.cnt_loss: 124.4  loss: 124.4  data_time: 0.0762  lr: 0.00090451  max_mem: 2413M
[09/06 21:56:55] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 124.2  decode.loss_seg: -3.192e-12  aux_0.loss: 0  cnt.cnt_loss: 62.09  loss: 62.09  time: 0.3621  data_time: 0.0402  lr: 0.00034549  max_mem: 2413M
[09/06 21:56:56] cvalgorithms INFO:  eta: 0:00:32  iter: 5  total_loss: 112.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 56.17  loss: 56.17  time: 0.3558  data_time: 0.0282  lr: 0.001  max_mem: 2413M
[09/06 21:56:56] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 112.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 56.17  loss: 56.17  time: 0.3543  data_time: 0.0223  lr: 0.00065451  max_mem: 2413M
[09/06 21:56:57] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 124.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 62.09  loss: 62.09  time: 0.3538  data_time: 0.0187  lr: 9.5492e-05  max_mem: 2413M
[09/06 21:56:58] cvalgorithms INFO:  eta: 0:00:30  iter: 11  total_loss: 134  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 66.98  loss: 66.98  time: 0.3532  data_time: 0.0163  lr: 0.00090451  max_mem: 2413M
[09/06 21:56:58] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 134  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 66.98  loss: 66.98  time: 0.3528  data_time: 0.0146  lr: 0.00034549  max_mem: 2413M
[09/06 21:56:59] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 152.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.21  loss: 76.21  time: 0.3527  data_time: 0.0134  lr: 0.001  max_mem: 2413M
[09/06 21:57:00] cvalgorithms INFO:  eta: 0:00:28  iter: 17  total_loss: 152.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.21  loss: 76.21  time: 0.3531  data_time: 0.0124  lr: 0.00065451  max_mem: 2413M
[09/06 21:57:01] cvalgorithms INFO: Start inference on 216 batches
[09/06 21:57:30] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 88, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 165, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluators)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 98, in inference_on_dataset
    evaluator.process(inputs, outputs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 43, in process
    evaluator.process(inputs, outputs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\levir_evaluation.py", line 77, in process
    self._conf_matrix += _fast_hist(pred.flatten(), gt.flatten, self.num_classes)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\comm\computer_ops.py", line 14, in _fast_hist
    + label_pred[mask], minlength=num_classes**2
TypeError: 'builtin_function_or_method' object is not subscriptable
[09/06 21:57:30] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 134  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 66.98  loss: 66.98  time: 0.3529  data_time: 0.0116  lr: 9.5492e-05  max_mem: 2413M
[09/06 21:58:12] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 21:58:46] cvalgorithms INFO: Starting training from iteration 0
[09/06 21:58:49] cvalgorithms INFO:  iter: 1  total_loss: 189.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 94.83  loss: 94.83  data_time: 0.0627  lr: 0.00090451  max_mem: 2413M
[09/06 21:58:50] cvalgorithms INFO:  eta: 0:00:34  iter: 3  total_loss: 163.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 81.92  loss: 81.92  time: 0.3543  data_time: 0.0335  lr: 0.00034549  max_mem: 2413M
[09/06 21:58:51] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 115.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 57.96  loss: 57.96  time: 0.3565  data_time: 0.0238  lr: 0.001  max_mem: 2413M
[09/06 21:58:51] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 97.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 48.88  loss: 48.88  time: 0.3558  data_time: 0.0190  lr: 0.00065451  max_mem: 2413M
[09/06 21:58:52] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 97.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 48.88  loss: 48.88  time: 0.3563  data_time: 0.0161  lr: 9.5492e-05  max_mem: 2413M
[09/06 21:58:53] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 80.31  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 40.15  loss: 40.15  time: 0.3572  data_time: 0.0141  lr: 0.00090451  max_mem: 2413M
[09/06 21:58:53] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 80.31  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 40.15  loss: 40.15  time: 0.3578  data_time: 0.0127  lr: 0.00034549  max_mem: 2413M
[09/06 21:58:54] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 80.31  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 40.15  loss: 40.15  time: 0.3599  data_time: 0.0117  lr: 0.001  max_mem: 2413M
[09/06 21:58:55] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 90.71  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 45.36  loss: 45.36  time: 0.3608  data_time: 0.0110  lr: 0.00065451  max_mem: 2413M
[09/06 21:58:56] cvalgorithms INFO: Start inference on 216 batches
[09/06 22:06:10] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 22:06:39] cvalgorithms INFO: Starting training from iteration 0
[09/06 22:06:43] cvalgorithms INFO:  iter: 1  total_loss: 311.7  decode.loss_seg: -0.0006811  aux_0.loss: 4.231e-06  cnt.cnt_loss: 155.9  loss: 155.9  data_time: 0.0721  lr: 0.00090451  max_mem: 2413M
[09/06 22:06:43] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 133.2  decode.loss_seg: 2.948e-12  aux_0.loss: 2.571e-07  cnt.cnt_loss: 66.62  loss: 66.62  time: 0.3508  data_time: 0.0382  lr: 0.00034549  max_mem: 2413M
[09/06 22:06:44] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 150.4  decode.loss_seg: 2.948e-12  aux_0.loss: 0  cnt.cnt_loss: 75.22  loss: 75.22  time: 0.3522  data_time: 0.0270  lr: 0.001  max_mem: 2413M
[09/06 22:06:45] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 150.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 75.22  loss: 75.22  time: 0.3524  data_time: 0.0213  lr: 0.00065451  max_mem: 2413M
[09/06 22:06:46] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 150.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 75.22  loss: 75.22  time: 0.3519  data_time: 0.0179  lr: 9.5492e-05  max_mem: 2413M
[09/06 22:06:46] cvalgorithms INFO:  eta: 0:00:30  iter: 11  total_loss: 126.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 63.42  loss: 63.42  time: 0.3514  data_time: 0.0156  lr: 0.00090451  max_mem: 2413M
[09/06 22:06:47] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 81.15  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 40.58  loss: 40.58  time: 0.3514  data_time: 0.0140  lr: 0.00034549  max_mem: 2413M
[09/06 22:06:48] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 75.38  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.69  loss: 37.69  time: 0.3512  data_time: 0.0128  lr: 0.001  max_mem: 2413M
[09/06 22:06:48] cvalgorithms INFO:  eta: 0:00:28  iter: 17  total_loss: 59.73  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 29.87  loss: 29.87  time: 0.3515  data_time: 0.0119  lr: 0.00065451  max_mem: 2413M
[09/06 22:06:49] cvalgorithms INFO: Start inference on 216 batches
[09/06 22:08:22] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 22:08:53] cvalgorithms INFO: Starting training from iteration 0
[09/06 22:08:56] cvalgorithms INFO:  iter: 1  total_loss: 105  decode.loss_seg: -0.0004229  aux_0.loss: 3.336e-08  cnt.cnt_loss: 52.48  loss: 52.48  data_time: 0.0595  lr: 0.00090451  max_mem: 2413M
[09/06 22:08:57] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 105  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 52.48  loss: 52.48  time: 0.3536  data_time: 0.0320  lr: 0.00034549  max_mem: 2413M
[09/06 22:08:57] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 144.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.4  loss: 72.4  time: 0.3560  data_time: 0.0231  lr: 0.001  max_mem: 2413M
[09/06 22:08:58] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 144.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.4  loss: 72.4  time: 0.3567  data_time: 0.0186  lr: 0.00065451  max_mem: 2413M
[09/06 22:08:59] cvalgorithms INFO:  eta: 0:00:32  iter: 9  total_loss: 162.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 81.16  loss: 81.16  time: 0.3561  data_time: 0.0159  lr: 9.5492e-05  max_mem: 2413M
[09/06 22:09:00] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 162.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 81.16  loss: 81.16  time: 0.3558  data_time: 0.0140  lr: 0.00090451  max_mem: 2413M
[09/06 22:09:00] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 144.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.4  loss: 72.4  time: 0.3559  data_time: 0.0127  lr: 0.00034549  max_mem: 2413M
[09/06 22:09:01] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 105  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 52.48  loss: 52.48  time: 0.3556  data_time: 0.0117  lr: 0.001  max_mem: 2413M
[09/06 22:09:02] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 69.63  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.82  loss: 34.82  time: 0.3557  data_time: 0.0109  lr: 0.00065451  max_mem: 2413M
[09/06 22:09:02] cvalgorithms INFO: Start inference on 216 batches
[09/06 22:09:51] cvalgorithms INFO: Total inference time: 0:00:13.195997 (0.062540 s / iter per device, on 1 devices)
[09/06 22:09:51] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.054078 s / iter per device, on 1 devices)
[09/06 22:09:51] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49500594712168583, 'acc': 0.9900118942433717, 'f1_score': array([0.99498082, 0.        ])})])
[09/06 22:09:51] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 137, in _do_eval
    v = float(v)
TypeError: only size-1 arrays can be converted to Python scalars

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 142, in _do_eval
    ) from e
ValueError: [EvalHook] eval_function should return a nested dict of float. Got 'levir/f1_score: [0.99498082 0.        ]' instead.
[09/06 22:09:51] cvalgorithms INFO:  eta: 0:00:28  iter: 19  total_loss: 69.63  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 34.82  loss: 34.82  time: 0.3557  data_time: 0.0103  lr: 9.5492e-05  max_mem: 2413M
[09/06 22:11:28] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 22:11:59] cvalgorithms INFO: Starting training from iteration 0
[09/06 22:12:02] cvalgorithms INFO:  iter: 1  total_loss: 472  decode.loss_seg: 0.002877  aux_0.loss: -1.063e-05  cnt.cnt_loss: 236  loss: 236  data_time: 0.0406  lr: 0.00090451  max_mem: 2413M
[09/06 22:12:03] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 257.2  decode.loss_seg: 5.268e-10  aux_0.loss: -5.87e-07  cnt.cnt_loss: 128.6  loss: 128.6  time: 0.3525  data_time: 0.0226  lr: 0.00034549  max_mem: 2413M
[09/06 22:12:04] cvalgorithms INFO:  eta: 0:00:33  iter: 5  total_loss: 129.2  decode.loss_seg: 2.989e-11  aux_0.loss: 0  cnt.cnt_loss: 64.6  loss: 64.6  time: 0.3560  data_time: 0.0165  lr: 0.001  max_mem: 2413M
[09/06 22:12:05] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 114.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 57.06  loss: 57.06  time: 0.3563  data_time: 0.0135  lr: 0.00065451  max_mem: 2413M
[09/06 22:12:05] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 142.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 71.08  loss: 71.08  time: 0.3561  data_time: 0.0117  lr: 9.5492e-05  max_mem: 2413M
[09/06 22:12:06] cvalgorithms INFO:  eta: 0:00:31  iter: 11  total_loss: 142.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 71.08  loss: 71.08  time: 0.3595  data_time: 0.0106  lr: 0.00090451  max_mem: 2413M
[09/06 22:12:07] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 142.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 71.08  loss: 71.08  time: 0.3597  data_time: 0.0098  lr: 0.00034549  max_mem: 2413M
[09/06 22:12:08] cvalgorithms INFO:  eta: 0:00:30  iter: 15  total_loss: 142.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 71.08  loss: 71.08  time: 0.3613  data_time: 0.0092  lr: 0.001  max_mem: 2413M
[09/06 22:12:08] cvalgorithms INFO:  eta: 0:00:29  iter: 17  total_loss: 120.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 60.35  loss: 60.35  time: 0.3618  data_time: 0.0087  lr: 0.00065451  max_mem: 2413M
[09/06 22:12:09] cvalgorithms INFO: Start inference on 216 batches
[09/06 22:13:19] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 22:13:51] cvalgorithms INFO: Starting training from iteration 0
[09/06 22:13:54] cvalgorithms INFO:  iter: 1  total_loss: 377  decode.loss_seg: 0.0008491  aux_0.loss: -1.524e-05  cnt.cnt_loss: 188.5  loss: 188.5  data_time: 0.0659  lr: 0.00090451  max_mem: 2413M
[09/06 22:13:55] cvalgorithms INFO:  eta: 0:00:35  iter: 3  total_loss: 340.6  decode.loss_seg: 2.559e-08  aux_0.loss: -8.722e-07  cnt.cnt_loss: 170.3  loss: 170.3  time: 0.3688  data_time: 0.0352  lr: 0.00034549  max_mem: 2413M
[09/06 22:13:55] cvalgorithms INFO:  eta: 0:00:34  iter: 5  total_loss: 272.2  decode.loss_seg: 3.325e-10  aux_0.loss: -2.428e-07  cnt.cnt_loss: 136.1  loss: 136.1  time: 0.3657  data_time: 0.0250  lr: 0.001  max_mem: 2413M
[09/06 22:13:56] cvalgorithms INFO:  eta: 0:00:34  iter: 7  total_loss: 176  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 88  loss: 88  time: 0.3691  data_time: 0.0199  lr: 0.00065451  max_mem: 2413M
[09/06 22:13:57] cvalgorithms INFO:  eta: 0:00:33  iter: 9  total_loss: 272.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 136.1  loss: 136.1  time: 0.3705  data_time: 0.0169  lr: 9.5492e-05  max_mem: 2413M
[09/06 22:13:58] cvalgorithms INFO:  eta: 0:00:32  iter: 11  total_loss: 264.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 132.5  loss: 132.5  time: 0.3704  data_time: 0.0148  lr: 0.00090451  max_mem: 2413M
[09/06 22:13:58] cvalgorithms INFO:  eta: 0:00:32  iter: 13  total_loss: 183  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 91.5  loss: 91.5  time: 0.3710  data_time: 0.0133  lr: 0.00034549  max_mem: 2413M
[09/06 22:13:59] cvalgorithms INFO:  eta: 0:00:31  iter: 15  total_loss: 106.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 53.27  loss: 53.27  time: 0.3722  data_time: 0.0122  lr: 0.001  max_mem: 2413M
[09/06 22:14:00] cvalgorithms INFO:  eta: 0:00:30  iter: 17  total_loss: 99.54  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 49.77  loss: 49.77  time: 0.3728  data_time: 0.0114  lr: 0.00065451  max_mem: 2413M
[09/06 22:14:01] cvalgorithms INFO: Start inference on 216 batches
[09/06 22:14:46] cvalgorithms INFO: Total inference time: 0:00:13.467061 (0.063825 s / iter per device, on 1 devices)
[09/06 22:14:46] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.055387 s / iter per device, on 1 devices)
[09/06 22:14:51] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49500594712168583, 'acc': 0.9900118942433717, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/06 22:14:51] cvalgorithms INFO:  eta: 0:00:29  iter: 19  total_loss: 94.12  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 47.06  loss: 47.06  time: 0.3737  data_time: 0.0107  lr: 9.5492e-05  max_mem: 2413M
[09/06 22:14:52] cvalgorithms INFO:  eta: 0:00:29  iter: 21  total_loss: 91.66  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 45.83  loss: 45.83  time: 0.3837  data_time: 0.0049  lr: 0.00090451  max_mem: 2417M
[09/06 22:14:52] cvalgorithms INFO:  eta: 0:00:28  iter: 23  total_loss: 77.62  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 38.81  loss: 38.81  time: 0.3834  data_time: 0.0049  lr: 0.00034549  max_mem: 2417M
[09/06 22:14:53] cvalgorithms INFO:  eta: 0:00:27  iter: 25  total_loss: 72.86  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 36.43  loss: 36.43  time: 0.3832  data_time: 0.0050  lr: 0.001  max_mem: 2417M
[09/06 22:14:54] cvalgorithms INFO:  eta: 0:00:27  iter: 27  total_loss: 55.99  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 27.99  loss: 27.99  time: 0.3830  data_time: 0.0050  lr: 0.00065451  max_mem: 2417M
[09/06 22:14:55] cvalgorithms INFO:  eta: 0:00:26  iter: 29  total_loss: 39.69  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 19.84  loss: 19.84  time: 0.3829  data_time: 0.0051  lr: 9.5492e-05  max_mem: 2417M
[09/06 22:14:56] cvalgorithms INFO:  eta: 0:00:25  iter: 31  total_loss: 28.66  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 14.33  loss: 14.33  time: 0.3830  data_time: 0.0051  lr: 0.00090451  max_mem: 2417M
[09/06 22:14:56] cvalgorithms INFO:  eta: 0:00:25  iter: 33  total_loss: 23.56  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 11.78  loss: 11.78  time: 0.3829  data_time: 0.0051  lr: 0.00034549  max_mem: 2417M
[09/06 22:14:57] cvalgorithms INFO:  eta: 0:00:24  iter: 35  total_loss: 20.46  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 10.23  loss: 10.23  time: 0.3829  data_time: 0.0052  lr: 0.001  max_mem: 2417M
[09/06 22:14:58] cvalgorithms INFO:  eta: 0:00:23  iter: 37  total_loss: 16.96  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 8.479  loss: 8.479  time: 0.3832  data_time: 0.0052  lr: 0.00065451  max_mem: 2417M
[09/06 22:14:59] cvalgorithms INFO: Start inference on 216 batches
[09/06 22:15:48] cvalgorithms INFO: Total inference time: 0:00:13.826495 (0.065528 s / iter per device, on 1 devices)
[09/06 22:15:48] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056339 s / iter per device, on 1 devices)
[09/06 22:15:48] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49500594712168583, 'acc': 0.9900118942433717, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/06 22:15:48] cvalgorithms INFO:  eta: 0:00:22  iter: 39  total_loss: 16.27  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 8.137  loss: 8.137  time: 0.3833  data_time: 0.0052  lr: 9.5492e-05  max_mem: 2417M
[09/06 22:15:49] cvalgorithms INFO:  eta: 0:00:22  iter: 41  total_loss: 14.17  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.085  loss: 7.085  time: 0.3849  data_time: 0.0051  lr: 0.00090451  max_mem: 2417M
[09/06 22:15:50] cvalgorithms INFO:  eta: 0:00:21  iter: 43  total_loss: 12.33  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.164  loss: 6.164  time: 0.3863  data_time: 0.0052  lr: 0.00034549  max_mem: 2417M
[09/06 22:15:50] cvalgorithms INFO:  eta: 0:00:20  iter: 45  total_loss: 10.53  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.266  loss: 5.266  time: 0.3869  data_time: 0.0053  lr: 0.001  max_mem: 2417M
[09/06 22:15:51] cvalgorithms INFO:  eta: 0:00:19  iter: 47  total_loss: 9.127  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.564  loss: 4.564  time: 0.3875  data_time: 0.0053  lr: 0.00065451  max_mem: 2417M
[09/06 22:15:52] cvalgorithms INFO:  eta: 0:00:19  iter: 49  total_loss: 7.304  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.652  loss: 3.652  time: 0.3880  data_time: 0.0054  lr: 9.5492e-05  max_mem: 2417M
[09/06 22:15:53] cvalgorithms INFO:  eta: 0:00:18  iter: 51  total_loss: 6.295  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.148  loss: 3.148  time: 0.3883  data_time: 0.0055  lr: 0.00090451  max_mem: 2417M
[09/06 22:15:54] cvalgorithms INFO:  eta: 0:00:17  iter: 53  total_loss: 5.52  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.76  loss: 2.76  time: 0.3888  data_time: 0.0056  lr: 0.00034549  max_mem: 2417M
[09/06 22:15:54] cvalgorithms INFO:  eta: 0:00:16  iter: 55  total_loss: 4.935  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.468  loss: 2.468  time: 0.3890  data_time: 0.0056  lr: 0.001  max_mem: 2417M
[09/06 22:15:55] cvalgorithms INFO:  eta: 0:00:16  iter: 57  total_loss: 4.644  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.322  loss: 2.322  time: 0.3890  data_time: 0.0057  lr: 0.00065451  max_mem: 2417M
[09/06 22:15:56] cvalgorithms INFO: Start inference on 216 batches
[09/06 22:16:48] cvalgorithms INFO: Total inference time: 0:00:13.876745 (0.065767 s / iter per device, on 1 devices)
[09/06 22:16:48] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.057409 s / iter per device, on 1 devices)
[09/06 22:16:48] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49500594712168583, 'acc': 0.9900118942433717, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/06 22:16:48] cvalgorithms INFO:  eta: 0:00:15  iter: 59  total_loss: 4.418  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.209  loss: 2.209  time: 0.3891  data_time: 0.0057  lr: 9.5492e-05  max_mem: 2417M
[09/06 22:16:49] cvalgorithms INFO:  eta: 0:00:14  iter: 61  total_loss: 4.233  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.116  loss: 2.116  time: 0.3892  data_time: 0.0057  lr: 0.00090451  max_mem: 2417M
[09/06 22:16:50] cvalgorithms INFO:  eta: 0:00:13  iter: 63  total_loss: 3.612  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.806  loss: 1.806  time: 0.3898  data_time: 0.0070  lr: 0.00034549  max_mem: 2417M
[09/06 22:16:50] cvalgorithms INFO:  eta: 0:00:13  iter: 65  total_loss: 3.091  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.546  loss: 1.546  time: 0.3897  data_time: 0.0071  lr: 0.001  max_mem: 2417M
[09/06 22:16:51] cvalgorithms INFO:  eta: 0:00:12  iter: 67  total_loss: 2.727  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.363  loss: 1.363  time: 0.3897  data_time: 0.0070  lr: 0.00065451  max_mem: 2417M
[09/06 22:16:52] cvalgorithms INFO:  eta: 0:00:11  iter: 69  total_loss: 2.163  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.081  loss: 1.081  time: 0.3897  data_time: 0.0070  lr: 9.5492e-05  max_mem: 2417M
[09/06 22:16:53] cvalgorithms INFO:  eta: 0:00:10  iter: 71  total_loss: 1.826  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.913  loss: 0.913  time: 0.3899  data_time: 0.0070  lr: 0.00090451  max_mem: 2417M
[09/06 22:16:54] cvalgorithms INFO:  eta: 0:00:10  iter: 73  total_loss: 1.633  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8167  loss: 0.8167  time: 0.3907  data_time: 0.0072  lr: 0.00034549  max_mem: 2417M
[09/06 22:16:54] cvalgorithms INFO:  eta: 0:00:09  iter: 75  total_loss: 1.633  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8167  loss: 0.8167  time: 0.3915  data_time: 0.0072  lr: 0.001  max_mem: 2417M
[09/06 22:16:55] cvalgorithms INFO:  eta: 0:00:08  iter: 77  total_loss: 1.633  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8167  loss: 0.8167  time: 0.3916  data_time: 0.0073  lr: 0.00065451  max_mem: 2417M
[09/06 22:16:56] cvalgorithms INFO: Start inference on 216 batches
[09/06 22:17:48] cvalgorithms INFO: Total inference time: 0:00:13.878119 (0.065773 s / iter per device, on 1 devices)
[09/06 22:17:48] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056190 s / iter per device, on 1 devices)
[09/06 22:17:48] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49641467227791936, 'acc': 0.9897203048971297, 'precision': 0.0032101245944033377, 'recall': 0.09013682640485408, 'f1_score': 0.006199454201556568})])
[09/06 22:17:48] cvalgorithms INFO:  eta: 0:00:07  iter: 79  total_loss: 1.146  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5731  loss: 0.5731  time: 0.3917  data_time: 0.0074  lr: 9.5492e-05  max_mem: 2417M
[09/06 22:17:48] cvalgorithms INFO:  eta: 0:00:07  iter: 81  total_loss: 1.094  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5471  loss: 0.5471  time: 0.3918  data_time: 0.0074  lr: 0.00090451  max_mem: 2417M
[09/06 22:17:49] cvalgorithms INFO:  eta: 0:00:06  iter: 83  total_loss: 1.022  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5111  loss: 0.5111  time: 0.3918  data_time: 0.0061  lr: 0.00034549  max_mem: 2417M
[09/06 22:17:50] cvalgorithms INFO:  eta: 0:00:05  iter: 85  total_loss: 1.022  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5111  loss: 0.5111  time: 0.3918  data_time: 0.0060  lr: 0.001  max_mem: 2417M
[09/06 22:17:51] cvalgorithms INFO:  eta: 0:00:04  iter: 87  total_loss: 1.091  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5455  loss: 0.5455  time: 0.3917  data_time: 0.0061  lr: 0.00065451  max_mem: 2417M
[09/06 22:17:52] cvalgorithms INFO:  eta: 0:00:03  iter: 89  total_loss: 1.916  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9578  loss: 0.9578  time: 0.3917  data_time: 0.0061  lr: 9.5492e-05  max_mem: 2417M
[09/06 22:17:52] cvalgorithms INFO:  eta: 0:00:03  iter: 91  total_loss: 2.228  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.114  loss: 1.114  time: 0.3918  data_time: 0.0061  lr: 0.00090451  max_mem: 2417M
[09/06 22:17:53] cvalgorithms INFO:  eta: 0:00:02  iter: 93  total_loss: 1.916  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9578  loss: 0.9578  time: 0.3919  data_time: 0.0058  lr: 0.00034549  max_mem: 2417M
[09/06 22:17:54] cvalgorithms INFO:  eta: 0:00:01  iter: 95  total_loss: 1.743  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8716  loss: 0.8716  time: 0.3919  data_time: 0.0058  lr: 0.001  max_mem: 2417M
[09/06 22:17:55] cvalgorithms INFO:  eta: 0:00:00  iter: 97  total_loss: 1.372  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6859  loss: 0.6859  time: 0.3919  data_time: 0.0057  lr: 0.00065451  max_mem: 2417M
[09/06 22:17:56] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.644  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8223  loss: 0.8222  time: 0.3921  data_time: 0.0057  lr: 9.5492e-05  max_mem: 2417M
[09/06 22:17:56] cvalgorithms INFO: Start inference on 216 batches
[09/06 22:18:48] cvalgorithms INFO: Total inference time: 0:00:13.967695 (0.066198 s / iter per device, on 1 devices)
[09/06 22:18:48] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.056913 s / iter per device, on 1 devices)
[09/06 22:18:48] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49500594712168583, 'acc': 0.9900118942433717, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/06 22:18:48] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.644  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8223  loss: 0.8222  time: 0.3921  data_time: 0.0057  lr: 9.5492e-05  max_mem: 2417M
[09/06 22:19:52] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/06 22:20:28] cvalgorithms INFO: Starting training from iteration 0
[09/06 22:20:31] cvalgorithms INFO:  iter: 1  total_loss: 144  decode.loss_seg: -0.01743  aux_0.loss: 1.342e-05  cnt.cnt_loss: 72.01  loss: 71.99  data_time: 0.0486  lr: 0.00090451  max_mem: 2413M
[09/06 22:20:32] cvalgorithms INFO:  eta: 0:00:36  iter: 3  total_loss: 124  decode.loss_seg: 0  aux_0.loss: 6.201e-07  cnt.cnt_loss: 62.01  loss: 62.01  time: 0.3820  data_time: 0.0267  lr: 0.00034549  max_mem: 2413M
[09/06 22:20:33] cvalgorithms INFO:  eta: 0:00:35  iter: 5  total_loss: 77.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 38.7  loss: 38.7  time: 0.3829  data_time: 0.0194  lr: 0.001  max_mem: 2413M
[09/06 22:20:33] cvalgorithms INFO:  eta: 0:00:35  iter: 7  total_loss: 70.02  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.01  loss: 35.01  time: 0.3821  data_time: 0.0158  lr: 0.00065451  max_mem: 2413M
[09/06 22:20:34] cvalgorithms INFO:  eta: 0:00:34  iter: 9  total_loss: 62.76  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 31.38  loss: 31.38  time: 0.3817  data_time: 0.0136  lr: 9.5492e-05  max_mem: 2413M
[09/06 22:20:35] cvalgorithms INFO:  eta: 0:00:33  iter: 11  total_loss: 45.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 22.57  loss: 22.57  time: 0.3809  data_time: 0.0122  lr: 0.00090451  max_mem: 2413M
[09/06 22:20:36] cvalgorithms INFO:  eta: 0:00:32  iter: 13  total_loss: 50.18  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 25.09  loss: 25.09  time: 0.3817  data_time: 0.0111  lr: 0.00034549  max_mem: 2413M
[09/06 22:20:37] cvalgorithms INFO:  eta: 0:00:32  iter: 15  total_loss: 45.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 22.57  loss: 22.57  time: 0.3827  data_time: 0.0105  lr: 0.001  max_mem: 2413M
[09/06 22:20:37] cvalgorithms INFO:  eta: 0:00:31  iter: 17  total_loss: 45.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 22.57  loss: 22.57  time: 0.3829  data_time: 0.0099  lr: 0.00065451  max_mem: 2413M
[09/06 22:20:38] cvalgorithms INFO: Start inference on 216 batches
[09/06 22:21:28] cvalgorithms INFO: Total inference time: 0:00:13.574036 (0.064332 s / iter per device, on 1 devices)
[09/06 22:21:28] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056139 s / iter per device, on 1 devices)
[09/06 22:21:28] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49633891340011793, 'acc': 0.9926778268002359, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/06 22:21:28] cvalgorithms INFO:  eta: 0:00:30  iter: 19  total_loss: 50.18  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 25.09  loss: 25.09  time: 0.3832  data_time: 0.0094  lr: 9.5492e-05  max_mem: 2413M
[09/06 22:21:29] cvalgorithms INFO:  eta: 0:00:29  iter: 21  total_loss: 50.18  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 25.09  loss: 25.09  time: 0.3838  data_time: 0.0050  lr: 0.00090451  max_mem: 2417M
[09/06 22:21:30] cvalgorithms INFO:  eta: 0:00:29  iter: 23  total_loss: 45.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 22.57  loss: 22.57  time: 0.3846  data_time: 0.0051  lr: 0.00034549  max_mem: 2417M
[09/06 22:21:30] cvalgorithms INFO:  eta: 0:00:28  iter: 25  total_loss: 43.93  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 21.97  loss: 21.97  time: 0.3846  data_time: 0.0052  lr: 0.001  max_mem: 2417M
[09/06 22:21:31] cvalgorithms INFO:  eta: 0:00:27  iter: 27  total_loss: 41.58  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 20.79  loss: 20.79  time: 0.3848  data_time: 0.0052  lr: 0.00065451  max_mem: 2417M
[09/06 22:21:32] cvalgorithms INFO:  eta: 0:00:26  iter: 29  total_loss: 35.43  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.71  loss: 17.71  time: 0.3853  data_time: 0.0052  lr: 9.5492e-05  max_mem: 2417M
[09/06 22:21:33] cvalgorithms INFO:  eta: 0:00:26  iter: 31  total_loss: 33.52  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.76  loss: 16.76  time: 0.3859  data_time: 0.0053  lr: 0.00090451  max_mem: 2417M
[09/06 22:21:33] cvalgorithms INFO:  eta: 0:00:25  iter: 33  total_loss: 31.07  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 15.53  loss: 15.53  time: 0.3860  data_time: 0.0053  lr: 0.00034549  max_mem: 2417M
[09/06 22:21:34] cvalgorithms INFO:  eta: 0:00:24  iter: 35  total_loss: 28.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 14.38  loss: 14.38  time: 0.3860  data_time: 0.0053  lr: 0.001  max_mem: 2417M
[09/06 22:21:35] cvalgorithms INFO:  eta: 0:00:23  iter: 37  total_loss: 24.03  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.01  loss: 12.01  time: 0.3864  data_time: 0.0053  lr: 0.00065451  max_mem: 2417M
[09/06 22:21:36] cvalgorithms INFO: Start inference on 216 batches
[09/06 22:22:27] cvalgorithms INFO: Total inference time: 0:00:13.365635 (0.063344 s / iter per device, on 1 devices)
[09/06 22:22:27] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056014 s / iter per device, on 1 devices)
[09/06 22:22:27] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49318948487260994, 'acc': 0.9863789697452199, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/06 22:22:27] cvalgorithms INFO:  eta: 0:00:23  iter: 39  total_loss: 18.61  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 9.305  loss: 9.305  time: 0.3866  data_time: 0.0053  lr: 9.5492e-05  max_mem: 2417M
[09/06 22:22:28] cvalgorithms INFO:  eta: 0:00:22  iter: 41  total_loss: 10.35  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.174  loss: 5.174  time: 0.3875  data_time: 0.0054  lr: 0.00090451  max_mem: 2417M
[09/06 22:22:28] cvalgorithms INFO:  eta: 0:00:21  iter: 43  total_loss: 10.35  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.174  loss: 5.174  time: 0.3878  data_time: 0.0055  lr: 0.00034549  max_mem: 2417M
[09/06 22:22:29] cvalgorithms INFO:  eta: 0:00:20  iter: 45  total_loss: 8.622  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.311  loss: 4.311  time: 0.3880  data_time: 0.0056  lr: 0.001  max_mem: 2417M
[09/06 22:22:30] cvalgorithms INFO:  eta: 0:00:20  iter: 47  total_loss: 7.61  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.805  loss: 3.805  time: 0.3882  data_time: 0.0056  lr: 0.00065451  max_mem: 2417M
[09/06 22:22:31] cvalgorithms INFO:  eta: 0:00:19  iter: 49  total_loss: 6.392  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.196  loss: 3.196  time: 0.3884  data_time: 0.0056  lr: 9.5492e-05  max_mem: 2417M
[09/06 22:22:32] cvalgorithms INFO:  eta: 0:00:18  iter: 51  total_loss: 5.792  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.896  loss: 2.896  time: 0.3887  data_time: 0.0056  lr: 0.00090451  max_mem: 2417M
[09/06 22:22:32] cvalgorithms INFO:  eta: 0:00:17  iter: 53  total_loss: 5.309  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.655  loss: 2.655  time: 0.3889  data_time: 0.0056  lr: 0.00034549  max_mem: 2417M
[09/06 22:22:33] cvalgorithms INFO:  eta: 0:00:17  iter: 55  total_loss: 4.955  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.478  loss: 2.478  time: 0.3891  data_time: 0.0056  lr: 0.001  max_mem: 2417M
[09/06 22:22:34] cvalgorithms INFO:  eta: 0:00:16  iter: 57  total_loss: 4.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.37  loss: 2.37  time: 0.3890  data_time: 0.0056  lr: 0.00065451  max_mem: 2417M
[09/06 22:22:35] cvalgorithms INFO: Start inference on 216 batches
[09/06 22:23:27] cvalgorithms INFO: Total inference time: 0:00:13.463409 (0.063808 s / iter per device, on 1 devices)
[09/06 22:23:27] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056022 s / iter per device, on 1 devices)
[09/06 22:23:27] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4955118031732491, 'acc': 0.9910236063464982, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/06 22:23:27] cvalgorithms INFO:  eta: 0:00:15  iter: 59  total_loss: 4.363  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.182  loss: 2.182  time: 0.3895  data_time: 0.0056  lr: 9.5492e-05  max_mem: 2417M
[09/06 22:23:28] cvalgorithms INFO:  eta: 0:00:14  iter: 61  total_loss: 3.726  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.863  loss: 1.863  time: 0.3896  data_time: 0.0057  lr: 0.00090451  max_mem: 2417M
[09/06 22:23:28] cvalgorithms INFO:  eta: 0:00:14  iter: 63  total_loss: 3.171  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.585  loss: 1.585  time: 0.3896  data_time: 0.0056  lr: 0.00034549  max_mem: 2417M
[09/06 22:23:29] cvalgorithms INFO:  eta: 0:00:13  iter: 65  total_loss: 3.034  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.517  loss: 1.517  time: 0.3896  data_time: 0.0056  lr: 0.001  max_mem: 2417M
[09/06 22:23:30] cvalgorithms INFO:  eta: 0:00:12  iter: 67  total_loss: 2.221  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.11  loss: 1.11  time: 0.3898  data_time: 0.0056  lr: 0.00065451  max_mem: 2417M
[09/06 22:23:31] cvalgorithms INFO:  eta: 0:00:11  iter: 69  total_loss: 2.221  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.11  loss: 1.11  time: 0.3899  data_time: 0.0056  lr: 9.5492e-05  max_mem: 2417M
[09/06 22:23:32] cvalgorithms INFO:  eta: 0:00:10  iter: 71  total_loss: 2.106  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.053  loss: 1.053  time: 0.3902  data_time: 0.0056  lr: 0.00090451  max_mem: 2417M
[09/06 22:23:32] cvalgorithms INFO:  eta: 0:00:10  iter: 73  total_loss: 2.221  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.11  loss: 1.11  time: 0.3902  data_time: 0.0056  lr: 0.00034549  max_mem: 2417M
[09/06 22:23:33] cvalgorithms INFO:  eta: 0:00:09  iter: 75  total_loss: 2.406  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.203  loss: 1.203  time: 0.3902  data_time: 0.0056  lr: 0.001  max_mem: 2417M
[09/06 22:23:34] cvalgorithms INFO:  eta: 0:00:08  iter: 77  total_loss: 2.335  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.167  loss: 1.167  time: 0.3914  data_time: 0.0057  lr: 0.00065451  max_mem: 2417M
[09/06 22:23:35] cvalgorithms INFO: Start inference on 216 batches
[09/06 22:24:27] cvalgorithms INFO: Total inference time: 0:00:13.351640 (0.063278 s / iter per device, on 1 devices)
[09/06 22:24:27] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056163 s / iter per device, on 1 devices)
[09/06 22:24:27] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4950214917257254, 'acc': 0.9900429834514508, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/06 22:24:27] cvalgorithms INFO:  eta: 0:00:07  iter: 79  total_loss: 1.66  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.83  loss: 0.83  time: 0.3919  data_time: 0.0057  lr: 9.5492e-05  max_mem: 2417M
[09/06 22:24:28] cvalgorithms INFO:  eta: 0:00:07  iter: 81  total_loss: 2.151  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.075  loss: 1.075  time: 0.3919  data_time: 0.0056  lr: 0.00090451  max_mem: 2417M
[09/06 22:24:28] cvalgorithms INFO:  eta: 0:00:06  iter: 83  total_loss: 2.358  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.179  loss: 1.179  time: 0.3921  data_time: 0.0056  lr: 0.00034549  max_mem: 2417M
[09/06 22:24:29] cvalgorithms INFO:  eta: 0:00:05  iter: 85  total_loss: 2.358  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.179  loss: 1.179  time: 0.3925  data_time: 0.0055  lr: 0.001  max_mem: 2417M
[09/06 22:24:30] cvalgorithms INFO:  eta: 0:00:04  iter: 87  total_loss: 2.542  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.271  loss: 1.271  time: 0.3929  data_time: 0.0055  lr: 0.00065451  max_mem: 2417M
[09/06 22:24:31] cvalgorithms INFO:  eta: 0:00:03  iter: 89  total_loss: 2.16  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.08  loss: 1.08  time: 0.3933  data_time: 0.0056  lr: 9.5492e-05  max_mem: 2417M
[09/06 22:24:32] cvalgorithms INFO:  eta: 0:00:03  iter: 91  total_loss: 2.145  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.072  loss: 1.072  time: 0.3936  data_time: 0.0056  lr: 0.00090451  max_mem: 2417M
[09/06 22:24:33] cvalgorithms INFO:  eta: 0:00:02  iter: 93  total_loss: 1.931  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9655  loss: 0.9655  time: 0.3942  data_time: 0.0056  lr: 0.00034549  max_mem: 2417M
[09/06 22:24:33] cvalgorithms INFO:  eta: 0:00:01  iter: 95  total_loss: 1.656  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8279  loss: 0.8279  time: 0.3944  data_time: 0.0056  lr: 0.001  max_mem: 2417M
[09/06 22:24:34] cvalgorithms INFO:  eta: 0:00:00  iter: 97  total_loss: 1.656  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8279  loss: 0.8279  time: 0.3951  data_time: 0.0056  lr: 0.00065451  max_mem: 2417M
[09/06 22:24:35] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.656  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8279  loss: 0.8279  time: 0.3955  data_time: 0.0056  lr: 9.5492e-05  max_mem: 2417M
[09/06 22:24:35] cvalgorithms INFO: Start inference on 216 batches
[09/06 22:25:28] cvalgorithms INFO: Total inference time: 0:00:13.385162 (0.063437 s / iter per device, on 1 devices)
[09/06 22:25:28] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056169 s / iter per device, on 1 devices)
[09/06 22:25:28] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49216779710599934, 'acc': 0.9843355942119987, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/06 22:25:28] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.656  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8279  loss: 0.8279  time: 0.3955  data_time: 0.0056  lr: 9.5492e-05  max_mem: 2417M
[09/07 12:11:59] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/07 12:12:27] cvalgorithms INFO: Starting training from iteration 0
[09/07 12:12:32] cvalgorithms INFO:  iter: 1  total_loss: 126.8  decode.loss_seg: 0.0002055  aux_0.loss: -1.485e-07  cnt.cnt_loss: 63.39  loss: 63.39  data_time: 0.0587  lr: 0.00090451  max_mem: 3207M
[09/07 12:12:33] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 100.5  decode.loss_seg: 5.331e-13  aux_0.loss: -4.289e-08  cnt.cnt_loss: 50.23  loss: 50.23  time: 0.3505  data_time: 0.0315  lr: 0.00034549  max_mem: 3207M
[09/07 12:12:34] cvalgorithms INFO:  eta: 0:00:32  iter: 5  total_loss: 100.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.23  loss: 50.23  time: 0.3475  data_time: 0.0226  lr: 0.001  max_mem: 3207M
[09/07 12:12:34] cvalgorithms INFO:  eta: 0:00:31  iter: 7  total_loss: 100.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 50.23  loss: 50.23  time: 0.3469  data_time: 0.0180  lr: 0.00065451  max_mem: 3207M
[09/07 12:12:35] cvalgorithms INFO:  eta: 0:00:30  iter: 9  total_loss: 85.82  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 42.91  loss: 42.91  time: 0.3458  data_time: 0.0153  lr: 9.5492e-05  max_mem: 3207M
[09/07 12:12:36] cvalgorithms INFO:  eta: 0:00:30  iter: 11  total_loss: 63.96  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 31.98  loss: 31.98  time: 0.3457  data_time: 0.0135  lr: 0.00090451  max_mem: 3207M
[09/07 12:12:36] cvalgorithms INFO:  eta: 0:00:29  iter: 13  total_loss: 63.96  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 31.98  loss: 31.98  time: 0.3464  data_time: 0.0122  lr: 0.00034549  max_mem: 3207M
[09/07 12:12:37] cvalgorithms INFO:  eta: 0:00:28  iter: 15  total_loss: 54.25  decode.loss_seg: 5.331e-13  aux_0.loss: 0  cnt.cnt_loss: 27.12  loss: 27.12  time: 0.3461  data_time: 0.0112  lr: 0.001  max_mem: 3207M
[09/07 12:12:38] cvalgorithms INFO:  eta: 0:00:28  iter: 17  total_loss: 54.25  decode.loss_seg: 5.331e-13  aux_0.loss: 0  cnt.cnt_loss: 27.12  loss: 27.12  time: 0.3459  data_time: 0.0105  lr: 0.00065451  max_mem: 3207M
[09/07 12:12:39] cvalgorithms INFO: Start inference on 216 batches
[09/07 12:13:18] cvalgorithms INFO: Total inference time: 0:00:11.912463 (0.056457 s / iter per device, on 1 devices)
[09/07 12:13:18] cvalgorithms INFO: Total inference pure compute time: 0:00:10 (0.050592 s / iter per device, on 1 devices)
[09/07 12:13:18] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49352128722510236, 'acc': 0.9870425744502047, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/07 12:13:18] cvalgorithms INFO:  eta: 0:00:27  iter: 19  total_loss: 52.96  decode.loss_seg: 5.331e-13  aux_0.loss: 0  cnt.cnt_loss: 26.48  loss: 26.48  time: 0.3459  data_time: 0.0098  lr: 9.5492e-05  max_mem: 3207M
[09/07 12:13:19] cvalgorithms INFO:  eta: 0:00:26  iter: 21  total_loss: 39.42  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 19.71  loss: 19.71  time: 0.3489  data_time: 0.0044  lr: 0.00090451  max_mem: 3207M
[09/07 12:13:20] cvalgorithms INFO:  eta: 0:00:26  iter: 23  total_loss: 29.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 14.91  loss: 14.91  time: 0.3493  data_time: 0.0044  lr: 0.00034549  max_mem: 3207M
[09/07 12:13:20] cvalgorithms INFO:  eta: 0:00:25  iter: 25  total_loss: 31.34  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 15.67  loss: 15.67  time: 0.3497  data_time: 0.0044  lr: 0.001  max_mem: 3207M
[09/07 12:13:21] cvalgorithms INFO:  eta: 0:00:24  iter: 27  total_loss: 27.26  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 13.63  loss: 13.63  time: 0.3499  data_time: 0.0044  lr: 0.00065451  max_mem: 3207M
[09/07 12:13:22] cvalgorithms INFO:  eta: 0:00:24  iter: 29  total_loss: 22.46  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 11.23  loss: 11.23  time: 0.3500  data_time: 0.0044  lr: 9.5492e-05  max_mem: 3207M
[09/07 12:13:23] cvalgorithms INFO:  eta: 0:00:23  iter: 31  total_loss: 21.68  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 10.84  loss: 10.84  time: 0.3503  data_time: 0.0044  lr: 0.00090451  max_mem: 3207M
[09/07 12:13:23] cvalgorithms INFO:  eta: 0:00:22  iter: 33  total_loss: 19.88  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 9.94  loss: 9.94  time: 0.3505  data_time: 0.0044  lr: 0.00034549  max_mem: 3207M
[09/07 12:13:24] cvalgorithms INFO:  eta: 0:00:22  iter: 35  total_loss: 17.28  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 8.642  loss: 8.642  time: 0.3508  data_time: 0.0044  lr: 0.001  max_mem: 3207M
[09/07 12:13:25] cvalgorithms INFO:  eta: 0:00:21  iter: 37  total_loss: 13.08  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.542  loss: 6.542  time: 0.3512  data_time: 0.0044  lr: 0.00065451  max_mem: 3207M
[09/07 12:13:25] cvalgorithms INFO: Start inference on 216 batches
[09/07 12:14:07] cvalgorithms INFO: Total inference time: 0:00:12.325953 (0.058417 s / iter per device, on 1 devices)
[09/07 12:14:07] cvalgorithms INFO: Total inference pure compute time: 0:00:10 (0.051940 s / iter per device, on 1 devices)
[09/07 12:14:07] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49488149898796674, 'acc': 0.9897629979759335, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/07 12:14:07] cvalgorithms INFO:  eta: 0:00:21  iter: 39  total_loss: 12.16  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.08  loss: 6.08  time: 0.3514  data_time: 0.0044  lr: 9.5492e-05  max_mem: 3207M
[09/07 12:14:08] cvalgorithms INFO:  eta: 0:00:20  iter: 41  total_loss: 12.12  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.061  loss: 6.061  time: 0.3521  data_time: 0.0044  lr: 0.00090451  max_mem: 3207M
[09/07 12:14:09] cvalgorithms INFO:  eta: 0:00:19  iter: 43  total_loss: 10.06  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.029  loss: 5.029  time: 0.3532  data_time: 0.0045  lr: 0.00034549  max_mem: 3207M
[09/07 12:14:10] cvalgorithms INFO:  eta: 0:00:19  iter: 45  total_loss: 8.848  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.424  loss: 4.424  time: 0.3542  data_time: 0.0045  lr: 0.001  max_mem: 3207M
[09/07 12:14:10] cvalgorithms INFO:  eta: 0:00:18  iter: 47  total_loss: 7.377  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.688  loss: 3.688  time: 0.3549  data_time: 0.0045  lr: 0.00065451  max_mem: 3207M
[09/07 12:14:11] cvalgorithms INFO:  eta: 0:00:17  iter: 49  total_loss: 6.201  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.101  loss: 3.101  time: 0.3558  data_time: 0.0045  lr: 9.5492e-05  max_mem: 3207M
[09/07 12:14:12] cvalgorithms INFO:  eta: 0:00:16  iter: 51  total_loss: 5.532  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.766  loss: 2.766  time: 0.3566  data_time: 0.0045  lr: 0.00090451  max_mem: 3207M
[09/07 12:14:13] cvalgorithms INFO:  eta: 0:00:16  iter: 53  total_loss: 4.189  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.095  loss: 2.095  time: 0.3574  data_time: 0.0045  lr: 0.00034549  max_mem: 3207M
[09/07 12:14:13] cvalgorithms INFO:  eta: 0:00:15  iter: 55  total_loss: 3.805  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.902  loss: 1.902  time: 0.3582  data_time: 0.0045  lr: 0.001  max_mem: 3207M
[09/07 12:14:14] cvalgorithms INFO:  eta: 0:00:14  iter: 57  total_loss: 3.408  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.704  loss: 1.704  time: 0.3589  data_time: 0.0045  lr: 0.00065451  max_mem: 3207M
[09/07 12:14:15] cvalgorithms INFO: Start inference on 216 batches
[09/07 12:14:59] cvalgorithms INFO: Total inference time: 0:00:12.556513 (0.059510 s / iter per device, on 1 devices)
[09/07 12:14:59] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.054027 s / iter per device, on 1 devices)
[09/07 12:14:59] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4971098283271342, 'acc': 0.9942196566542684, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/07 12:14:59] cvalgorithms INFO:  eta: 0:00:14  iter: 59  total_loss: 3.184  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.592  loss: 1.592  time: 0.3596  data_time: 0.0045  lr: 9.5492e-05  max_mem: 3207M
[09/07 12:14:59] cvalgorithms INFO:  eta: 0:00:13  iter: 61  total_loss: 3.184  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.592  loss: 1.592  time: 0.3603  data_time: 0.0046  lr: 0.00090451  max_mem: 3207M
[09/07 12:15:00] cvalgorithms INFO:  eta: 0:00:12  iter: 63  total_loss: 2.752  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.376  loss: 1.376  time: 0.3610  data_time: 0.0046  lr: 0.00034549  max_mem: 3207M
[09/07 12:15:01] cvalgorithms INFO:  eta: 0:00:12  iter: 65  total_loss: 2.823  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.412  loss: 1.412  time: 0.3617  data_time: 0.0047  lr: 0.001  max_mem: 3207M
[09/07 12:15:02] cvalgorithms INFO:  eta: 0:00:11  iter: 67  total_loss: 2.372  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.186  loss: 1.186  time: 0.3622  data_time: 0.0047  lr: 0.00065451  max_mem: 3207M
[09/07 12:15:02] cvalgorithms INFO:  eta: 0:00:10  iter: 69  total_loss: 2.204  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.102  loss: 1.102  time: 0.3631  data_time: 0.0047  lr: 9.5492e-05  max_mem: 3207M
[09/07 12:15:03] cvalgorithms INFO:  eta: 0:00:10  iter: 71  total_loss: 2.152  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.076  loss: 1.076  time: 0.3645  data_time: 0.0049  lr: 0.00090451  max_mem: 3207M
[09/07 12:15:04] cvalgorithms INFO:  eta: 0:00:09  iter: 73  total_loss: 2.152  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.076  loss: 1.076  time: 0.3650  data_time: 0.0049  lr: 0.00034549  max_mem: 3207M
[09/07 12:15:05] cvalgorithms INFO:  eta: 0:00:08  iter: 75  total_loss: 2.204  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.102  loss: 1.102  time: 0.3659  data_time: 0.0050  lr: 0.001  max_mem: 3207M
[09/07 12:15:06] cvalgorithms INFO:  eta: 0:00:08  iter: 77  total_loss: 2.649  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.324  loss: 1.324  time: 0.3664  data_time: 0.0050  lr: 0.00065451  max_mem: 3207M
[09/07 12:15:06] cvalgorithms INFO: Start inference on 216 batches
[09/07 12:15:53] cvalgorithms INFO: Total inference time: 0:00:13.058517 (0.061889 s / iter per device, on 1 devices)
[09/07 12:15:53] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.055024 s / iter per device, on 1 devices)
[09/07 12:15:53] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4954892436985759, 'acc': 0.9909784873971518, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/07 12:15:53] cvalgorithms INFO:  eta: 0:00:07  iter: 79  total_loss: 2.649  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.324  loss: 1.324  time: 0.3670  data_time: 0.0050  lr: 9.5492e-05  max_mem: 3207M
[09/07 12:15:54] cvalgorithms INFO:  eta: 0:00:06  iter: 81  total_loss: 2.424  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.212  loss: 1.212  time: 0.3676  data_time: 0.0051  lr: 0.00090451  max_mem: 3207M
[09/07 12:15:54] cvalgorithms INFO:  eta: 0:00:05  iter: 83  total_loss: 2.209  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.105  loss: 1.105  time: 0.3679  data_time: 0.0051  lr: 0.00034549  max_mem: 3207M
[09/07 12:15:55] cvalgorithms INFO:  eta: 0:00:05  iter: 85  total_loss: 2.48  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.24  loss: 1.24  time: 0.3683  data_time: 0.0051  lr: 0.001  max_mem: 3207M
[09/07 12:15:56] cvalgorithms INFO:  eta: 0:00:04  iter: 87  total_loss: 2.209  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.105  loss: 1.105  time: 0.3686  data_time: 0.0051  lr: 0.00065451  max_mem: 3207M
[09/07 12:15:57] cvalgorithms INFO:  eta: 0:00:03  iter: 89  total_loss: 2.138  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.069  loss: 1.069  time: 0.3689  data_time: 0.0051  lr: 9.5492e-05  max_mem: 3207M
[09/07 12:15:57] cvalgorithms INFO:  eta: 0:00:03  iter: 91  total_loss: 2.144  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.072  loss: 1.072  time: 0.3692  data_time: 0.0050  lr: 0.00090451  max_mem: 3207M
[09/07 12:15:58] cvalgorithms INFO:  eta: 0:00:02  iter: 93  total_loss: 2.144  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.072  loss: 1.072  time: 0.3693  data_time: 0.0050  lr: 0.00034549  max_mem: 3207M
[09/07 12:15:59] cvalgorithms INFO:  eta: 0:00:01  iter: 95  total_loss: 2.091  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.045  loss: 1.045  time: 0.3696  data_time: 0.0049  lr: 0.001  max_mem: 3207M
[09/07 12:16:00] cvalgorithms INFO:  eta: 0:00:00  iter: 97  total_loss: 1.785  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8927  loss: 0.8927  time: 0.3699  data_time: 0.0049  lr: 0.00065451  max_mem: 3207M
[09/07 12:16:00] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.592  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7959  loss: 0.7959  time: 0.3700  data_time: 0.0049  lr: 9.5492e-05  max_mem: 3207M
[09/07 12:16:00] cvalgorithms INFO: Start inference on 216 batches
[09/07 12:16:48] cvalgorithms INFO: Total inference time: 0:00:13.180392 (0.062466 s / iter per device, on 1 devices)
[09/07 12:16:48] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.055570 s / iter per device, on 1 devices)
[09/07 12:16:48] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49755281211006114, 'acc': 0.9951056242201223, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/07 12:16:48] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.592  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7959  loss: 0.7959  time: 0.3700  data_time: 0.0049  lr: 9.5492e-05  max_mem: 3207M
[09/07 18:28:16] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/07 18:28:45] cvalgorithms INFO: Starting training from iteration 0
[09/07 18:28:49] cvalgorithms INFO:  iter: 1  total_loss: 422.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 211.2  loss: 211.2  data_time: 0.0546  lr: 0.00090451  max_mem: 3207M
[09/07 18:28:50] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 201.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 100.7  loss: 100.7  time: 0.3487  data_time: 0.0295  lr: 0.00034549  max_mem: 3207M
[09/07 18:28:50] cvalgorithms INFO:  eta: 0:00:32  iter: 5  total_loss: 198.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 99.04  loss: 99.04  time: 0.3478  data_time: 0.0213  lr: 0.001  max_mem: 3207M
[09/07 18:28:51] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 198.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 99.04  loss: 99.04  time: 0.3553  data_time: 0.0171  lr: 0.00065451  max_mem: 3207M
[09/07 18:28:52] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 198.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 99.04  loss: 99.04  time: 0.3535  data_time: 0.0147  lr: 9.5492e-05  max_mem: 3207M
[09/07 18:28:52] cvalgorithms INFO:  eta: 0:00:30  iter: 11  total_loss: 174.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 87.08  loss: 87.08  time: 0.3525  data_time: 0.0131  lr: 0.00090451  max_mem: 3207M
[09/07 18:28:53] cvalgorithms INFO:  eta: 0:00:29  iter: 13  total_loss: 133.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 66.72  loss: 66.72  time: 0.3516  data_time: 0.0120  lr: 0.00034549  max_mem: 3207M
[09/07 18:28:54] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 83.71  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.86  loss: 41.86  time: 0.3514  data_time: 0.0110  lr: 0.001  max_mem: 3207M
[09/07 18:28:55] cvalgorithms INFO:  eta: 0:00:28  iter: 17  total_loss: 83.71  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 41.86  loss: 41.86  time: 0.3516  data_time: 0.0103  lr: 0.00065451  max_mem: 3207M
[09/07 18:28:55] cvalgorithms INFO: Start inference on 216 batches
[09/07 18:29:40] cvalgorithms INFO: Total inference time: 0:00:12.390960 (0.058725 s / iter per device, on 1 devices)
[09/07 18:29:40] cvalgorithms INFO: Total inference pure compute time: 0:00:10 (0.051769 s / iter per device, on 1 devices)
[09/07 18:29:40] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.495172611976525, 'acc': 0.99034522395305, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/07 18:29:40] cvalgorithms INFO:  eta: 0:00:27  iter: 19  total_loss: 52.33  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 26.16  loss: 26.16  time: 0.3510  data_time: 0.0097  lr: 9.5492e-05  max_mem: 3207M
[09/07 18:29:41] cvalgorithms INFO:  eta: 0:00:27  iter: 21  total_loss: 44.68  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 22.34  loss: 22.34  time: 0.3515  data_time: 0.0047  lr: 0.00090451  max_mem: 3207M
[09/07 18:29:42] cvalgorithms INFO:  eta: 0:00:26  iter: 23  total_loss: 38.03  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 19.01  loss: 19.01  time: 0.3523  data_time: 0.0047  lr: 0.00034549  max_mem: 3207M
[09/07 18:29:42] cvalgorithms INFO:  eta: 0:00:25  iter: 25  total_loss: 35.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.92  loss: 17.92  time: 0.3538  data_time: 0.0046  lr: 0.001  max_mem: 3207M
[09/07 18:29:43] cvalgorithms INFO:  eta: 0:00:25  iter: 27  total_loss: 35.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.92  loss: 17.92  time: 0.3551  data_time: 0.0046  lr: 0.00065451  max_mem: 3207M
[09/07 18:29:44] cvalgorithms INFO:  eta: 0:00:24  iter: 29  total_loss: 31.86  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 15.93  loss: 15.93  time: 0.3562  data_time: 0.0046  lr: 9.5492e-05  max_mem: 3207M
[09/07 18:29:45] cvalgorithms INFO:  eta: 0:00:24  iter: 31  total_loss: 31.72  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 15.86  loss: 15.86  time: 0.3577  data_time: 0.0046  lr: 0.00090451  max_mem: 3207M
[09/07 18:29:45] cvalgorithms INFO:  eta: 0:00:23  iter: 33  total_loss: 25.57  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.79  loss: 12.79  time: 0.3588  data_time: 0.0045  lr: 0.00034549  max_mem: 3207M
[09/07 18:29:46] cvalgorithms INFO:  eta: 0:00:22  iter: 35  total_loss: 25.57  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.79  loss: 12.79  time: 0.3594  data_time: 0.0046  lr: 0.001  max_mem: 3207M
[09/07 18:29:47] cvalgorithms INFO:  eta: 0:00:22  iter: 37  total_loss: 20.96  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 10.48  loss: 10.48  time: 0.3599  data_time: 0.0046  lr: 0.00065451  max_mem: 3207M
[09/07 18:29:48] cvalgorithms INFO: Start inference on 216 batches
[09/07 18:37:25] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/07 18:37:54] cvalgorithms INFO: Starting training from iteration 0
[09/07 18:42:08] cvalgorithms INFO:  iter: 1  total_loss: 248.4  decode.loss_seg: 0.705  aux_0.loss: 0.7057  cnt.cnt_loss: 122.8  loss: 124.2  data_time: 0.0681  lr: 0.00090451  max_mem: 3232M
[09/07 18:42:08] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 238.7  decode.loss_seg: 0.681  aux_0.loss: 0.6873  cnt.cnt_loss: 118  loss: 119.4  time: 0.3474  data_time: 0.0369  lr: 0.00034549  max_mem: 3232M
[09/07 18:42:09] cvalgorithms INFO:  eta: 0:00:32  iter: 5  total_loss: 153.8  decode.loss_seg: 0.6564  aux_0.loss: 0.6759  cnt.cnt_loss: 75.57  loss: 76.89  time: 0.3472  data_time: 0.0260  lr: 0.001  max_mem: 3232M
[09/07 18:42:10] cvalgorithms INFO:  eta: 0:00:31  iter: 7  total_loss: 153.8  decode.loss_seg: 0.6505  aux_0.loss: 0.6659  cnt.cnt_loss: 75.57  loss: 76.89  time: 0.3470  data_time: 0.0206  lr: 0.00065451  max_mem: 3232M
[09/07 18:42:10] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 140.3  decode.loss_seg: 0.6488  aux_0.loss: 0.6642  cnt.cnt_loss: 68.88  loss: 70.14  time: 0.3482  data_time: 0.0175  lr: 9.5492e-05  max_mem: 3232M
[09/07 18:42:11] cvalgorithms INFO:  eta: 0:00:30  iter: 11  total_loss: 128.5  decode.loss_seg: 0.6295  aux_0.loss: 0.6509  cnt.cnt_loss: 62.99  loss: 64.26  time: 0.3489  data_time: 0.0154  lr: 0.00090451  max_mem: 3232M
[09/07 18:42:12] cvalgorithms INFO:  eta: 0:00:29  iter: 13  total_loss: 120.1  decode.loss_seg: 0.601  aux_0.loss: 0.6287  cnt.cnt_loss: 58.81  loss: 60.05  time: 0.3487  data_time: 0.0139  lr: 0.00034549  max_mem: 3232M
[09/07 18:42:13] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 106.8  decode.loss_seg: 0.5897  aux_0.loss: 0.6123  cnt.cnt_loss: 52.14  loss: 53.41  time: 0.3486  data_time: 0.0128  lr: 0.001  max_mem: 3232M
[09/07 18:42:13] cvalgorithms INFO:  eta: 0:00:28  iter: 17  total_loss: 82.43  decode.loss_seg: 0.5837  aux_0.loss: 0.6039  cnt.cnt_loss: 39.93  loss: 41.22  time: 0.3496  data_time: 0.0119  lr: 0.00065451  max_mem: 3232M
[09/07 18:42:14] cvalgorithms INFO: Start inference on 216 batches
[09/07 18:42:49] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 88, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 165, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluators)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 98, in inference_on_dataset
    evaluator.process(inputs, outputs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 43, in process
    evaluator.process(inputs, outputs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\levir_evaluation.py", line 57, in process
    self._conf_matrix += _fast_hist(pred.flatten(), gt.flatten(), self.num_classes)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\comm\computer_ops.py", line 14, in _fast_hist
    + label_pred[mask], minlength=num_classes**2
IndexError: boolean index did not match indexed array along dimension 0; dimension is 200704 but corresponding boolean dimension is 401408
[09/07 18:42:49] cvalgorithms INFO:  eta: 0:00:27  iter: 19  total_loss: 69.13  decode.loss_seg: 0.5728  aux_0.loss: 0.5989  cnt.cnt_loss: 33.44  loss: 34.57  time: 0.3496  data_time: 0.0111  lr: 9.5492e-05  max_mem: 3232M
[09/23 21:54:16] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/23 21:54:45] cvalgorithms INFO: Starting training from iteration 0
[09/23 21:54:51] cvalgorithms INFO:  iter: 1  total_loss: 231.6  decode.loss_seg: 0  aux_0.loss: 0.6823  cnt.cnt_loss: 115.1  loss: 115.8  data_time: 0.0670  lr: 0.00090451  max_mem: 3207M
[09/23 21:54:51] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 182.1  decode.loss_seg: 0  aux_0.loss: 0.6621  cnt.cnt_loss: 90.41  loss: 91.07  time: 0.3477  data_time: 0.0358  lr: 0.00034549  max_mem: 3207M
[09/23 21:54:52] cvalgorithms INFO:  eta: 0:00:32  iter: 5  total_loss: 125  decode.loss_seg: 0  aux_0.loss: 0.6381  cnt.cnt_loss: 61.86  loss: 62.51  time: 0.3471  data_time: 0.0253  lr: 0.001  max_mem: 3207M
[09/23 21:54:53] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 92.45  decode.loss_seg: 0  aux_0.loss: 0.6264  cnt.cnt_loss: 45.57  loss: 46.23  time: 0.3481  data_time: 0.0200  lr: 0.00065451  max_mem: 3207M
[09/23 21:54:54] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 92.45  decode.loss_seg: 0  aux_0.loss: 0.6255  cnt.cnt_loss: 45.57  loss: 46.23  time: 0.3484  data_time: 0.0169  lr: 9.5492e-05  max_mem: 3207M
[09/23 21:54:54] cvalgorithms INFO:  eta: 0:00:30  iter: 11  total_loss: 92.45  decode.loss_seg: 0  aux_0.loss: 0.6126  cnt.cnt_loss: 45.57  loss: 46.23  time: 0.3499  data_time: 0.0148  lr: 0.00090451  max_mem: 3207M
[09/23 21:54:55] cvalgorithms INFO:  eta: 0:00:30  iter: 13  total_loss: 92.45  decode.loss_seg: 0  aux_0.loss: 0.5879  cnt.cnt_loss: 45.57  loss: 46.23  time: 0.3502  data_time: 0.0133  lr: 0.00034549  max_mem: 3207M
[09/23 21:54:56] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 80.06  decode.loss_seg: 0  aux_0.loss: 0.5744  cnt.cnt_loss: 39.44  loss: 40.03  time: 0.3501  data_time: 0.0122  lr: 0.001  max_mem: 3207M
[09/23 21:54:56] cvalgorithms INFO:  eta: 0:00:28  iter: 17  total_loss: 58.27  decode.loss_seg: 0  aux_0.loss: 0.5744  cnt.cnt_loss: 28.57  loss: 29.14  time: 0.3498  data_time: 0.0113  lr: 0.00065451  max_mem: 3207M
[09/23 21:54:57] cvalgorithms INFO: Start inference on 216 batches
[09/23 22:01:59] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 150, in after_step
    self._do_eval()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 128, in _do_eval
    results = self._func()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 89, in test_and_save_results
    self._last_eval_results = self._eval(self.cfg, self.model)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 166, in _eval
    results_i = inference_on_dataset(model, self.build_val_loader(cfg), evaluators)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 98, in inference_on_dataset
    evaluator.process(inputs, outputs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\evaluator.py", line 43, in process
    evaluator.process(inputs, outputs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\levir_evaluation.py", line 57, in process
    self._conf_matrix += _fast_hist(pred.flatten(), gt.flatten(), self.num_classes)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\evaluation\comm\computer_ops.py", line 15, in _fast_hist
    ).reshape(num_classes, num_classes)
ValueError: cannot reshape array of size 2 into shape (1,1)
[09/23 22:01:59] cvalgorithms INFO:  eta: 0:00:27  iter: 19  total_loss: 42.12  decode.loss_seg: 0  aux_0.loss: 0.5667  cnt.cnt_loss: 20.55  loss: 21.06  time: 0.3509  data_time: 0.0106  lr: 9.5492e-05  max_mem: 3207M
[09/23 22:03:04] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/23 22:03:32] cvalgorithms INFO: Starting training from iteration 0
[09/23 22:03:36] cvalgorithms INFO:  iter: 1  total_loss: 158.1  decode.loss_seg: 0.0003647  aux_0.loss: 0.6832  cnt.cnt_loss: 78.36  loss: 79.04  data_time: 0.0507  lr: 0.00090451  max_mem: 3207M
[09/23 22:03:36] cvalgorithms INFO:  eta: 0:00:33  iter: 3  total_loss: 122  decode.loss_seg: 0  aux_0.loss: 0.661  cnt.cnt_loss: 60.35  loss: 60.99  time: 0.3478  data_time: 0.0276  lr: 0.00034549  max_mem: 3207M
[09/23 22:03:37] cvalgorithms INFO:  eta: 0:00:32  iter: 5  total_loss: 78.46  decode.loss_seg: 0  aux_0.loss: 0.638  cnt.cnt_loss: 38.61  loss: 39.23  time: 0.3475  data_time: 0.0199  lr: 0.001  max_mem: 3207M
[09/23 22:03:38] cvalgorithms INFO:  eta: 0:00:32  iter: 7  total_loss: 98.15  decode.loss_seg: 0  aux_0.loss: 0.6257  cnt.cnt_loss: 48.47  loss: 49.07  time: 0.3490  data_time: 0.0160  lr: 0.00065451  max_mem: 3207M
[09/23 22:03:38] cvalgorithms INFO:  eta: 0:00:31  iter: 9  total_loss: 98.15  decode.loss_seg: 0  aux_0.loss: 0.623  cnt.cnt_loss: 48.47  loss: 49.07  time: 0.3487  data_time: 0.0136  lr: 9.5492e-05  max_mem: 3207M
[09/23 22:03:39] cvalgorithms INFO:  eta: 0:00:30  iter: 11  total_loss: 117.4  decode.loss_seg: 0  aux_0.loss: 0.6109  cnt.cnt_loss: 58.16  loss: 58.72  time: 0.3490  data_time: 0.0121  lr: 0.00090451  max_mem: 3207M
[09/23 22:03:40] cvalgorithms INFO:  eta: 0:00:29  iter: 13  total_loss: 98.15  decode.loss_seg: 0  aux_0.loss: 0.5888  cnt.cnt_loss: 48.47  loss: 49.07  time: 0.3488  data_time: 0.0110  lr: 0.00034549  max_mem: 3207M
[09/23 22:03:40] cvalgorithms INFO:  eta: 0:00:29  iter: 15  total_loss: 98.15  decode.loss_seg: 0  aux_0.loss: 0.5751  cnt.cnt_loss: 48.47  loss: 49.07  time: 0.3487  data_time: 0.0102  lr: 0.001  max_mem: 3207M
[09/23 22:03:41] cvalgorithms INFO:  eta: 0:00:28  iter: 17  total_loss: 78.46  decode.loss_seg: 0  aux_0.loss: 0.5629  cnt.cnt_loss: 38.61  loss: 39.23  time: 0.3497  data_time: 0.0096  lr: 0.00065451  max_mem: 3207M
[09/23 22:03:42] cvalgorithms INFO: Start inference on 216 batches
[09/23 22:04:22] cvalgorithms INFO: Total inference time: 0:00:11.932375 (0.056552 s / iter per device, on 1 devices)
[09/23 22:04:22] cvalgorithms INFO: Total inference pure compute time: 0:00:10 (0.050832 s / iter per device, on 1 devices)
[09/23 22:04:22] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49522668588266194, 'acc': 0.9904533717653239, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/23 22:04:22] cvalgorithms INFO:  eta: 0:00:27  iter: 19  total_loss: 78.46  decode.loss_seg: 0  aux_0.loss: 0.5522  cnt.cnt_loss: 38.61  loss: 39.23  time: 0.3505  data_time: 0.0091  lr: 9.5492e-05  max_mem: 3207M
[09/23 22:04:23] cvalgorithms INFO:  eta: 0:00:27  iter: 21  total_loss: 73.87  decode.loss_seg: 0  aux_0.loss: 0.5241  cnt.cnt_loss: 36.42  loss: 36.94  time: 0.3519  data_time: 0.0053  lr: 0.00090451  max_mem: 3207M
[09/23 22:04:24] cvalgorithms INFO:  eta: 0:00:26  iter: 23  total_loss: 51.64  decode.loss_seg: 0  aux_0.loss: 0.4999  cnt.cnt_loss: 25.33  loss: 25.82  time: 0.3533  data_time: 0.0052  lr: 0.00034549  max_mem: 3207M
[09/23 22:04:25] cvalgorithms INFO:  eta: 0:00:25  iter: 25  total_loss: 48.67  decode.loss_seg: 0  aux_0.loss: 0.4837  cnt.cnt_loss: 23.89  loss: 24.34  time: 0.3534  data_time: 0.0053  lr: 0.001  max_mem: 3207M
[09/23 22:04:25] cvalgorithms INFO:  eta: 0:00:25  iter: 27  total_loss: 31.4  decode.loss_seg: 0  aux_0.loss: 0.4539  cnt.cnt_loss: 15.17  loss: 15.7  time: 0.3538  data_time: 0.0053  lr: 0.00065451  max_mem: 3207M
[09/23 22:04:26] cvalgorithms INFO:  eta: 0:00:24  iter: 29  total_loss: 22.64  decode.loss_seg: 0  aux_0.loss: 0.4341  cnt.cnt_loss: 10.9  loss: 11.32  time: 0.3553  data_time: 0.0053  lr: 9.5492e-05  max_mem: 3207M
[09/23 22:04:27] cvalgorithms INFO:  eta: 0:00:24  iter: 31  total_loss: 19.85  decode.loss_seg: 0  aux_0.loss: 0.4077  cnt.cnt_loss: 9.511  loss: 9.923  time: 0.3562  data_time: 0.0053  lr: 0.00090451  max_mem: 3207M
[09/23 22:04:28] cvalgorithms INFO:  eta: 0:00:23  iter: 33  total_loss: 16.25  decode.loss_seg: 0  aux_0.loss: 0.3947  cnt.cnt_loss: 7.717  loss: 8.127  time: 0.3571  data_time: 0.0052  lr: 0.00034549  max_mem: 3207M
[09/23 22:04:28] cvalgorithms INFO:  eta: 0:00:22  iter: 35  total_loss: 14.62  decode.loss_seg: 0  aux_0.loss: 0.3746  cnt.cnt_loss: 6.96  loss: 7.31  time: 0.3582  data_time: 0.0052  lr: 0.001  max_mem: 3207M
[09/23 22:04:29] cvalgorithms INFO:  eta: 0:00:22  iter: 37  total_loss: 14.58  decode.loss_seg: 0  aux_0.loss: 0.3619  cnt.cnt_loss: 6.96  loss: 7.288  time: 0.3590  data_time: 0.0053  lr: 0.00065451  max_mem: 3207M
[09/23 22:04:30] cvalgorithms INFO: Start inference on 216 batches
[09/23 22:05:13] cvalgorithms INFO: Total inference time: 0:00:12.612535 (0.059775 s / iter per device, on 1 devices)
[09/23 22:05:13] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.053790 s / iter per device, on 1 devices)
[09/23 22:05:13] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4937402263962209, 'acc': 0.9874804527924418, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/23 22:05:13] cvalgorithms INFO:  eta: 0:00:21  iter: 39  total_loss: 12.42  decode.loss_seg: 0  aux_0.loss: 0.3518  cnt.cnt_loss: 5.87  loss: 6.211  time: 0.3597  data_time: 0.0052  lr: 9.5492e-05  max_mem: 3207M
[09/23 22:05:14] cvalgorithms INFO:  eta: 0:00:20  iter: 41  total_loss: 12.2  decode.loss_seg: 0  aux_0.loss: 0.3215  cnt.cnt_loss: 5.718  loss: 6.099  time: 0.3615  data_time: 0.0045  lr: 0.00090451  max_mem: 3207M
[09/23 22:05:15] cvalgorithms INFO:  eta: 0:00:20  iter: 43  total_loss: 11.36  decode.loss_seg: 0  aux_0.loss: 0.3066  cnt.cnt_loss: 5.367  loss: 5.679  time: 0.3628  data_time: 0.0046  lr: 0.00034549  max_mem: 3207M
[09/23 22:05:15] cvalgorithms INFO:  eta: 0:00:19  iter: 45  total_loss: 9.305  decode.loss_seg: 0  aux_0.loss: 0.294  cnt.cnt_loss: 4.317  loss: 4.653  time: 0.3639  data_time: 0.0047  lr: 0.001  max_mem: 3207M
[09/23 22:05:16] cvalgorithms INFO:  eta: 0:00:18  iter: 47  total_loss: 7.315  decode.loss_seg: 0  aux_0.loss: 0.2769  cnt.cnt_loss: 3.396  loss: 3.657  time: 0.3651  data_time: 0.0048  lr: 0.00065451  max_mem: 3207M
[09/23 22:05:17] cvalgorithms INFO:  eta: 0:00:18  iter: 49  total_loss: 6.963  decode.loss_seg: 0  aux_0.loss: 0.2633  cnt.cnt_loss: 3.218  loss: 3.481  time: 0.3664  data_time: 0.0049  lr: 9.5492e-05  max_mem: 3207M
[09/23 22:05:18] cvalgorithms INFO:  eta: 0:00:17  iter: 51  total_loss: 5.961  decode.loss_seg: 0  aux_0.loss: 0.2491  cnt.cnt_loss: 2.75  loss: 2.98  time: 0.3673  data_time: 0.0050  lr: 0.00090451  max_mem: 3207M
[09/23 22:05:18] cvalgorithms INFO:  eta: 0:00:16  iter: 53  total_loss: 5.08  decode.loss_seg: 0  aux_0.loss: 0.2375  cnt.cnt_loss: 2.302  loss: 2.54  time: 0.3678  data_time: 0.0051  lr: 0.00034549  max_mem: 3207M
[09/23 22:05:19] cvalgorithms INFO:  eta: 0:00:16  iter: 55  total_loss: 4.829  decode.loss_seg: 0  aux_0.loss: 0.2308  cnt.cnt_loss: 2.196  loss: 2.415  time: 0.3682  data_time: 0.0051  lr: 0.001  max_mem: 3207M
[09/23 22:05:20] cvalgorithms INFO:  eta: 0:00:15  iter: 57  total_loss: 4.437  decode.loss_seg: 0  aux_0.loss: 0.2232  cnt.cnt_loss: 1.958  loss: 2.218  time: 0.3697  data_time: 0.0051  lr: 0.00065451  max_mem: 3207M
[09/23 22:05:21] cvalgorithms INFO: Start inference on 216 batches
[09/23 22:06:06] cvalgorithms INFO: Total inference time: 0:00:12.912413 (0.061196 s / iter per device, on 1 devices)
[09/23 22:06:06] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.054944 s / iter per device, on 1 devices)
[09/23 22:06:06] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.5093493675033444, 'acc': 0.9871090286398251, 'precision': 0.031682465656195966, 'recall': 0.9197541551151625, 'f1_score': 0.06125489632063688})])
[09/23 22:06:06] cvalgorithms INFO:  eta: 0:00:14  iter: 59  total_loss: 4.081  decode.loss_seg: 0  aux_0.loss: 0.2136  cnt.cnt_loss: 1.81  loss: 2.041  time: 0.3711  data_time: 0.0052  lr: 9.5492e-05  max_mem: 3207M
[09/23 22:06:07] cvalgorithms INFO:  eta: 0:00:14  iter: 61  total_loss: 3.797  decode.loss_seg: 0  aux_0.loss: 0.204  cnt.cnt_loss: 1.691  loss: 1.898  time: 0.3720  data_time: 0.0053  lr: 0.00090451  max_mem: 3207M
[09/23 22:06:08] cvalgorithms INFO:  eta: 0:00:13  iter: 63  total_loss: 3.549  decode.loss_seg: 0  aux_0.loss: 0.196  cnt.cnt_loss: 1.565  loss: 1.774  time: 0.3722  data_time: 0.0053  lr: 0.00034549  max_mem: 3207M
[09/23 22:06:08] cvalgorithms INFO:  eta: 0:00:12  iter: 65  total_loss: 3.391  decode.loss_seg: 0  aux_0.loss: 0.1926  cnt.cnt_loss: 1.481  loss: 1.696  time: 0.3723  data_time: 0.0052  lr: 0.001  max_mem: 3207M
[09/23 22:06:09] cvalgorithms INFO:  eta: 0:00:12  iter: 67  total_loss: 2.977  decode.loss_seg: 0  aux_0.loss: 0.1834  cnt.cnt_loss: 1.296  loss: 1.488  time: 0.3726  data_time: 0.0051  lr: 0.00065451  max_mem: 3207M
[09/23 22:06:10] cvalgorithms INFO:  eta: 0:00:11  iter: 69  total_loss: 2.873  decode.loss_seg: 0  aux_0.loss: 0.1754  cnt.cnt_loss: 1.231  loss: 1.437  time: 0.3727  data_time: 0.0050  lr: 9.5492e-05  max_mem: 3207M
[09/23 22:06:11] cvalgorithms INFO:  eta: 0:00:10  iter: 71  total_loss: 2.798  decode.loss_seg: 0  aux_0.loss: 0.1702  cnt.cnt_loss: 1.214  loss: 1.399  time: 0.3729  data_time: 0.0050  lr: 0.00090451  max_mem: 3207M
[09/23 22:06:12] cvalgorithms INFO:  eta: 0:00:09  iter: 73  total_loss: 2.798  decode.loss_seg: 0  aux_0.loss: 0.1629  cnt.cnt_loss: 1.214  loss: 1.399  time: 0.3732  data_time: 0.0049  lr: 0.00034549  max_mem: 3207M
[09/23 22:06:12] cvalgorithms INFO:  eta: 0:00:09  iter: 75  total_loss: 2.798  decode.loss_seg: 0  aux_0.loss: 0.1536  cnt.cnt_loss: 1.214  loss: 1.399  time: 0.3735  data_time: 0.0049  lr: 0.001  max_mem: 3207M
[09/23 22:06:13] cvalgorithms INFO:  eta: 0:00:08  iter: 77  total_loss: 2.666  decode.loss_seg: 0  aux_0.loss: 0.1475  cnt.cnt_loss: 1.174  loss: 1.333  time: 0.3736  data_time: 0.0049  lr: 0.00065451  max_mem: 3207M
[09/23 22:06:14] cvalgorithms INFO: Start inference on 216 batches
[09/23 22:07:00] cvalgorithms INFO: Total inference time: 0:00:13.002553 (0.061623 s / iter per device, on 1 devices)
[09/23 22:07:00] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.055286 s / iter per device, on 1 devices)
[09/23 22:07:00] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4919323040830982, 'acc': 0.9838646081661964, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/23 22:07:00] cvalgorithms INFO:  eta: 0:00:07  iter: 79  total_loss: 2.609  decode.loss_seg: 0  aux_0.loss: 0.1439  cnt.cnt_loss: 1.174  loss: 1.305  time: 0.3737  data_time: 0.0049  lr: 9.5492e-05  max_mem: 3207M
[09/23 22:07:01] cvalgorithms INFO:  eta: 0:00:06  iter: 81  total_loss: 2.375  decode.loss_seg: 0  aux_0.loss: 0.1401  cnt.cnt_loss: 1.034  loss: 1.188  time: 0.3740  data_time: 0.0047  lr: 0.00090451  max_mem: 3207M
[09/23 22:07:01] cvalgorithms INFO:  eta: 0:00:06  iter: 83  total_loss: 2.111  decode.loss_seg: 0  aux_0.loss: 0.1401  cnt.cnt_loss: 0.8989  loss: 1.056  time: 0.3742  data_time: 0.0047  lr: 0.00034549  max_mem: 3207M
[09/23 22:07:02] cvalgorithms INFO:  eta: 0:00:05  iter: 85  total_loss: 2.154  decode.loss_seg: 0  aux_0.loss: 0.1352  cnt.cnt_loss: 0.9563  loss: 1.077  time: 0.3743  data_time: 0.0047  lr: 0.001  max_mem: 3207M
[09/23 22:07:03] cvalgorithms INFO:  eta: 0:00:04  iter: 87  total_loss: 2.375  decode.loss_seg: 0  aux_0.loss: 0.1267  cnt.cnt_loss: 1.065  loss: 1.188  time: 0.3743  data_time: 0.0047  lr: 0.00065451  max_mem: 3207M
[09/23 22:07:04] cvalgorithms INFO:  eta: 0:00:03  iter: 89  total_loss: 2.187  decode.loss_seg: 0  aux_0.loss: 0.1234  cnt.cnt_loss: 0.9868  loss: 1.094  time: 0.3747  data_time: 0.0047  lr: 9.5492e-05  max_mem: 3207M
[09/23 22:07:05] cvalgorithms INFO:  eta: 0:00:03  iter: 91  total_loss: 2.154  decode.loss_seg: 0  aux_0.loss: 0.1157  cnt.cnt_loss: 0.9563  loss: 1.077  time: 0.3748  data_time: 0.0047  lr: 0.00090451  max_mem: 3207M
[09/23 22:07:05] cvalgorithms INFO:  eta: 0:00:02  iter: 93  total_loss: 2.154  decode.loss_seg: 0  aux_0.loss: 0.1078  cnt.cnt_loss: 0.9563  loss: 1.077  time: 0.3750  data_time: 0.0047  lr: 0.00034549  max_mem: 3207M
[09/23 22:07:06] cvalgorithms INFO:  eta: 0:00:01  iter: 95  total_loss: 2.018  decode.loss_seg: 0  aux_0.loss: 0.1028  cnt.cnt_loss: 0.8785  loss: 1.009  time: 0.3751  data_time: 0.0048  lr: 0.001  max_mem: 3207M
[09/23 22:07:07] cvalgorithms INFO:  eta: 0:00:00  iter: 97  total_loss: 1.655  decode.loss_seg: 0  aux_0.loss: 0.09507  cnt.cnt_loss: 0.7442  loss: 0.8277  time: 0.3753  data_time: 0.0048  lr: 0.00065451  max_mem: 3207M
[09/23 22:07:08] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.655  decode.loss_seg: 0  aux_0.loss: 0.09507  cnt.cnt_loss: 0.7442  loss: 0.8277  time: 0.3755  data_time: 0.0048  lr: 9.5492e-05  max_mem: 3207M
[09/23 22:07:08] cvalgorithms INFO: Start inference on 216 batches
[09/23 22:07:54] cvalgorithms INFO: Total inference time: 0:00:13.276958 (0.062924 s / iter per device, on 1 devices)
[09/23 22:07:54] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.055453 s / iter per device, on 1 devices)
[09/23 22:07:54] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4966025142811409, 'acc': 0.9932050285622818, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/23 22:07:54] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.655  decode.loss_seg: 0  aux_0.loss: 0.09507  cnt.cnt_loss: 0.7442  loss: 0.8277  time: 0.3755  data_time: 0.0048  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:52:13] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/24 10:52:25] cvalgorithms INFO: Starting training from iteration 0
[09/24 10:52:28] cvalgorithms INFO:  iter: 1  total_loss: 372.4  decode.loss_seg: 0.001942  aux_0.loss: 0.6835  cnt.cnt_loss: 185.5  loss: 186.2  data_time: 0.0653  lr: 0.00090451  max_mem: 3207M
[09/24 10:52:29] cvalgorithms INFO:  eta: 9:29:23  iter: 3  total_loss: 250.4  decode.loss_seg: 0  aux_0.loss: 0.6641  cnt.cnt_loss: 124.5  loss: 125.2  time: 0.3417  data_time: 0.0348  lr: 0.00034549  max_mem: 3207M
[09/24 10:52:29] cvalgorithms INFO:  eta: 9:29:23  iter: 5  total_loss: 170.6  decode.loss_seg: 0  aux_0.loss: 0.6399  cnt.cnt_loss: 84.66  loss: 85.29  time: 0.3449  data_time: 0.0246  lr: 0.001  max_mem: 3207M
[09/24 10:52:30] cvalgorithms INFO:  eta: 9:41:22  iter: 7  total_loss: 151.9  decode.loss_seg: 0  aux_0.loss: 0.6264  cnt.cnt_loss: 75.35  loss: 75.97  time: 0.3712  data_time: 0.0201  lr: 0.00065451  max_mem: 3207M
[09/24 10:52:31] cvalgorithms INFO:  eta: 9:42:12  iter: 9  total_loss: 117.6  decode.loss_seg: 0  aux_0.loss: 0.625  cnt.cnt_loss: 58.23  loss: 58.82  time: 0.3659  data_time: 0.0170  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:52:32] cvalgorithms INFO:  eta: 9:42:00  iter: 11  total_loss: 117.6  decode.loss_seg: 0  aux_0.loss: 0.6152  cnt.cnt_loss: 58.23  loss: 58.82  time: 0.3625  data_time: 0.0150  lr: 0.00090451  max_mem: 3207M
[09/24 10:52:32] cvalgorithms INFO:  eta: 9:40:47  iter: 13  total_loss: 81.59  decode.loss_seg: 0  aux_0.loss: 0.5917  cnt.cnt_loss: 40.21  loss: 40.79  time: 0.3602  data_time: 0.0136  lr: 0.00034549  max_mem: 3207M
[09/24 10:52:33] cvalgorithms INFO:  eta: 9:37:15  iter: 15  total_loss: 69.28  decode.loss_seg: 0  aux_0.loss: 0.5765  cnt.cnt_loss: 34.08  loss: 34.64  time: 0.3578  data_time: 0.0125  lr: 0.001  max_mem: 3207M
[09/24 10:52:34] cvalgorithms INFO:  eta: 9:37:15  iter: 17  total_loss: 65.37  decode.loss_seg: 0  aux_0.loss: 0.5739  cnt.cnt_loss: 32.15  loss: 32.69  time: 0.3563  data_time: 0.0116  lr: 0.00065451  max_mem: 3207M
[09/24 10:52:35] cvalgorithms INFO: Start inference on 216 batches
[09/24 10:52:58] cvalgorithms INFO: Total inference time: 0:00:11.720907 (0.055549 s / iter per device, on 1 devices)
[09/24 10:52:58] cvalgorithms INFO: Total inference pure compute time: 0:00:10 (0.050956 s / iter per device, on 1 devices)
[09/24 10:52:58] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4959724896642781, 'acc': 0.9919449793285562, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 10:52:58] cvalgorithms INFO:  eta: 9:37:14  iter: 19  total_loss: 63.63  decode.loss_seg: 0  aux_0.loss: 0.5621  cnt.cnt_loss: 31.3  loss: 31.81  time: 0.3554  data_time: 0.0109  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:52:59] cvalgorithms INFO:  eta: 9:37:13  iter: 21  total_loss: 43.91  decode.loss_seg: 0  aux_0.loss: 0.5446  cnt.cnt_loss: 21.51  loss: 21.95  time: 0.3545  data_time: 0.0048  lr: 0.00090451  max_mem: 3207M
[09/24 10:53:00] cvalgorithms INFO:  eta: 9:38:08  iter: 23  total_loss: 39.05  decode.loss_seg: 0  aux_0.loss: 0.4931  cnt.cnt_loss: 19.01  loss: 19.53  time: 0.3544  data_time: 0.0048  lr: 0.00034549  max_mem: 3207M
[09/24 10:53:00] cvalgorithms INFO:  eta: 9:39:32  iter: 25  total_loss: 34.97  decode.loss_seg: 0  aux_0.loss: 0.4852  cnt.cnt_loss: 16.94  loss: 17.49  time: 0.3539  data_time: 0.0049  lr: 0.001  max_mem: 3207M
[09/24 10:53:01] cvalgorithms INFO:  eta: 9:39:37  iter: 27  total_loss: 34.07  decode.loss_seg: 0  aux_0.loss: 0.4711  cnt.cnt_loss: 16.6  loss: 17.03  time: 0.3535  data_time: 0.0047  lr: 0.00065451  max_mem: 3207M
[09/24 10:53:02] cvalgorithms INFO:  eta: 9:40:35  iter: 29  total_loss: 28.38  decode.loss_seg: 0  aux_0.loss: 0.4491  cnt.cnt_loss: 13.8  loss: 14.19  time: 0.3540  data_time: 0.0046  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:53:03] cvalgorithms INFO:  eta: 9:40:41  iter: 31  total_loss: 21.41  decode.loss_seg: 0  aux_0.loss: 0.4443  cnt.cnt_loss: 10.18  loss: 10.71  time: 0.3539  data_time: 0.0046  lr: 0.00090451  max_mem: 3207M
[09/24 10:53:03] cvalgorithms INFO:  eta: 9:41:04  iter: 33  total_loss: 17.27  decode.loss_seg: 0  aux_0.loss: 0.4204  cnt.cnt_loss: 8.272  loss: 8.636  time: 0.3548  data_time: 0.0045  lr: 0.00034549  max_mem: 3207M
[09/24 10:53:04] cvalgorithms INFO:  eta: 9:42:27  iter: 35  total_loss: 16.54  decode.loss_seg: 0  aux_0.loss: 0.3874  cnt.cnt_loss: 7.857  loss: 8.269  time: 0.3553  data_time: 0.0046  lr: 0.001  max_mem: 3207M
[09/24 10:53:05] cvalgorithms INFO:  eta: 9:44:32  iter: 37  total_loss: 13.24  decode.loss_seg: 0  aux_0.loss: 0.3798  cnt.cnt_loss: 6.266  loss: 6.62  time: 0.3558  data_time: 0.0046  lr: 0.00065451  max_mem: 3207M
[09/24 10:53:06] cvalgorithms INFO: Start inference on 216 batches
[09/24 10:53:31] cvalgorithms INFO: Total inference time: 0:00:12.799863 (0.060663 s / iter per device, on 1 devices)
[09/24 10:53:31] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.055206 s / iter per device, on 1 devices)
[09/24 10:53:31] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49814440054040615, 'acc': 0.9962888010808123, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 10:53:31] cvalgorithms INFO:  eta: 9:45:53  iter: 39  total_loss: 10.16  decode.loss_seg: 0  aux_0.loss: 0.3535  cnt.cnt_loss: 4.752  loss: 5.082  time: 0.3564  data_time: 0.0047  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:53:32] cvalgorithms INFO:  eta: 9:46:17  iter: 41  total_loss: 9.821  decode.loss_seg: 0  aux_0.loss: 0.3327  cnt.cnt_loss: 4.617  loss: 4.911  time: 0.3583  data_time: 0.0059  lr: 0.00090451  max_mem: 3207M
[09/24 10:53:32] cvalgorithms INFO:  eta: 9:46:44  iter: 43  total_loss: 8.366  decode.loss_seg: 0  aux_0.loss: 0.3181  cnt.cnt_loss: 3.769  loss: 4.183  time: 0.3600  data_time: 0.0061  lr: 0.00034549  max_mem: 3207M
[09/24 10:53:33] cvalgorithms INFO:  eta: 9:48:53  iter: 45  total_loss: 7.152  decode.loss_seg: 0  aux_0.loss: 0.312  cnt.cnt_loss: 3.24  loss: 3.576  time: 0.3605  data_time: 0.0062  lr: 0.001  max_mem: 3207M
[09/24 10:53:34] cvalgorithms INFO:  eta: 9:51:23  iter: 47  total_loss: 5.971  decode.loss_seg: 0  aux_0.loss: 0.291  cnt.cnt_loss: 2.7  loss: 2.986  time: 0.3611  data_time: 0.0062  lr: 0.00065451  max_mem: 3207M
[09/24 10:53:35] cvalgorithms INFO:  eta: 9:52:35  iter: 49  total_loss: 4.829  decode.loss_seg: 0  aux_0.loss: 0.2751  cnt.cnt_loss: 2.155  loss: 2.415  time: 0.3616  data_time: 0.0062  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:53:35] cvalgorithms INFO:  eta: 9:53:40  iter: 51  total_loss: 4.549  decode.loss_seg: 0  aux_0.loss: 0.2706  cnt.cnt_loss: 1.982  loss: 2.275  time: 0.3619  data_time: 0.0062  lr: 0.00090451  max_mem: 3207M
[09/24 10:53:36] cvalgorithms INFO:  eta: 9:55:58  iter: 53  total_loss: 3.994  decode.loss_seg: 0  aux_0.loss: 0.2615  cnt.cnt_loss: 1.78  loss: 1.997  time: 0.3623  data_time: 0.0062  lr: 0.00034549  max_mem: 3207M
[09/24 10:53:37] cvalgorithms INFO:  eta: 9:58:21  iter: 55  total_loss: 3.994  decode.loss_seg: 0  aux_0.loss: 0.2489  cnt.cnt_loss: 1.78  loss: 1.997  time: 0.3626  data_time: 0.0061  lr: 0.001  max_mem: 3207M
[09/24 10:53:38] cvalgorithms INFO:  eta: 9:59:53  iter: 57  total_loss: 3.994  decode.loss_seg: 0  aux_0.loss: 0.2277  cnt.cnt_loss: 1.78  loss: 1.997  time: 0.3630  data_time: 0.0061  lr: 0.00065451  max_mem: 3207M
[09/24 10:53:38] cvalgorithms INFO: Start inference on 216 batches
[09/24 10:54:05] cvalgorithms INFO: Total inference time: 0:00:12.662219 (0.060011 s / iter per device, on 1 devices)
[09/24 10:54:05] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.055411 s / iter per device, on 1 devices)
[09/24 10:54:05] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4985285161207157, 'acc': 0.9970570322414314, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 10:54:05] cvalgorithms INFO:  eta: 10:02:18  iter: 59  total_loss: 3.861  decode.loss_seg: 0  aux_0.loss: 0.2117  cnt.cnt_loss: 1.71  loss: 1.931  time: 0.3633  data_time: 0.0061  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:54:06] cvalgorithms INFO:  eta: 10:05:18  iter: 61  total_loss: 3.696  decode.loss_seg: 0  aux_0.loss: 0.2035  cnt.cnt_loss: 1.656  loss: 1.848  time: 0.3642  data_time: 0.0062  lr: 0.00090451  max_mem: 3207M
[09/24 10:54:06] cvalgorithms INFO:  eta: 10:07:00  iter: 63  total_loss: 3.654  decode.loss_seg: 0  aux_0.loss: 0.1902  cnt.cnt_loss: 1.648  loss: 1.827  time: 0.3646  data_time: 0.0065  lr: 0.00034549  max_mem: 3207M
[09/24 10:54:07] cvalgorithms INFO:  eta: 10:07:50  iter: 65  total_loss: 3.696  decode.loss_seg: 0  aux_0.loss: 0.1862  cnt.cnt_loss: 1.656  loss: 1.848  time: 0.3648  data_time: 0.0064  lr: 0.001  max_mem: 3207M
[09/24 10:54:08] cvalgorithms INFO:  eta: 10:10:38  iter: 67  total_loss: 3.696  decode.loss_seg: 0  aux_0.loss: 0.1854  cnt.cnt_loss: 1.656  loss: 1.848  time: 0.3652  data_time: 0.0065  lr: 0.00065451  max_mem: 3207M
[09/24 10:54:09] cvalgorithms INFO:  eta: 10:13:13  iter: 69  total_loss: 3.654  decode.loss_seg: 0  aux_0.loss: 0.1743  cnt.cnt_loss: 1.648  loss: 1.827  time: 0.3655  data_time: 0.0065  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:54:09] cvalgorithms INFO:  eta: 10:13:51  iter: 71  total_loss: 3.654  decode.loss_seg: 0  aux_0.loss: 0.1686  cnt.cnt_loss: 1.648  loss: 1.827  time: 0.3657  data_time: 0.0065  lr: 0.00090451  max_mem: 3207M
[09/24 10:54:10] cvalgorithms INFO:  eta: 10:14:39  iter: 73  total_loss: 3.654  decode.loss_seg: 0  aux_0.loss: 0.164  cnt.cnt_loss: 1.648  loss: 1.827  time: 0.3660  data_time: 0.0065  lr: 0.00034549  max_mem: 3207M
[09/24 10:54:11] cvalgorithms INFO:  eta: 10:14:39  iter: 75  total_loss: 3.578  decode.loss_seg: 0  aux_0.loss: 0.1617  cnt.cnt_loss: 1.611  loss: 1.789  time: 0.3661  data_time: 0.0065  lr: 0.001  max_mem: 3207M
[09/24 10:54:12] cvalgorithms INFO:  eta: 10:15:09  iter: 77  total_loss: 3.578  decode.loss_seg: 0  aux_0.loss: 0.1515  cnt.cnt_loss: 1.611  loss: 1.789  time: 0.3663  data_time: 0.0065  lr: 0.00065451  max_mem: 3207M
[09/24 10:54:12] cvalgorithms INFO: Start inference on 216 batches
[09/24 10:54:39] cvalgorithms INFO: Total inference time: 0:00:12.846529 (0.060884 s / iter per device, on 1 devices)
[09/24 10:54:39] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.055576 s / iter per device, on 1 devices)
[09/24 10:54:39] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4981187447307174, 'acc': 0.9962374894614348, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 10:54:39] cvalgorithms INFO:  eta: 10:15:31  iter: 79  total_loss: 3.256  decode.loss_seg: 0  aux_0.loss: 0.1424  cnt.cnt_loss: 1.477  loss: 1.628  time: 0.3665  data_time: 0.0065  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:54:39] cvalgorithms INFO:  eta: 10:16:14  iter: 81  total_loss: 3.168  decode.loss_seg: 0  aux_0.loss: 0.1404  cnt.cnt_loss: 1.455  loss: 1.584  time: 0.3668  data_time: 0.0052  lr: 0.00090451  max_mem: 3207M
[09/24 10:54:40] cvalgorithms INFO:  eta: 10:16:38  iter: 83  total_loss: 2.759  decode.loss_seg: 0  aux_0.loss: 0.1377  cnt.cnt_loss: 1.231  loss: 1.38  time: 0.3670  data_time: 0.0048  lr: 0.00034549  max_mem: 3207M
[09/24 10:54:41] cvalgorithms INFO:  eta: 10:17:06  iter: 85  total_loss: 2.085  decode.loss_seg: 0  aux_0.loss: 0.1297  cnt.cnt_loss: 0.8954  loss: 1.042  time: 0.3673  data_time: 0.0048  lr: 0.001  max_mem: 3207M
[09/24 10:54:42] cvalgorithms INFO:  eta: 10:18:06  iter: 87  total_loss: 1.571  decode.loss_seg: 0  aux_0.loss: 0.1263  cnt.cnt_loss: 0.658  loss: 0.7854  time: 0.3675  data_time: 0.0049  lr: 0.00065451  max_mem: 3207M
[09/24 10:54:42] cvalgorithms INFO:  eta: 10:18:44  iter: 89  total_loss: 1.092  decode.loss_seg: 0  aux_0.loss: 0.1175  cnt.cnt_loss: 0.4265  loss: 0.5459  time: 0.3677  data_time: 0.0049  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:54:43] cvalgorithms INFO:  eta: 10:19:17  iter: 91  total_loss: 1.061  decode.loss_seg: 0  aux_0.loss: 0.1087  cnt.cnt_loss: 0.4265  loss: 0.5307  time: 0.3679  data_time: 0.0049  lr: 0.00090451  max_mem: 3207M
[09/24 10:54:44] cvalgorithms INFO:  eta: 10:19:43  iter: 93  total_loss: 0.876  decode.loss_seg: 0  aux_0.loss: 0.1057  cnt.cnt_loss: 0.339  loss: 0.438  time: 0.3681  data_time: 0.0049  lr: 0.00034549  max_mem: 3207M
[09/24 10:54:45] cvalgorithms INFO:  eta: 10:19:56  iter: 95  total_loss: 0.876  decode.loss_seg: 0  aux_0.loss: 0.1041  cnt.cnt_loss: 0.339  loss: 0.438  time: 0.3684  data_time: 0.0049  lr: 0.001  max_mem: 3207M
[09/24 10:54:46] cvalgorithms INFO:  eta: 10:20:08  iter: 97  total_loss: 0.876  decode.loss_seg: 0  aux_0.loss: 0.1018  cnt.cnt_loss: 0.339  loss: 0.438  time: 0.3686  data_time: 0.0050  lr: 0.00065451  max_mem: 3207M
[09/24 10:54:46] cvalgorithms INFO: Start inference on 216 batches
[09/24 10:55:14] cvalgorithms INFO: Total inference time: 0:00:13.222453 (0.062666 s / iter per device, on 1 devices)
[09/24 10:55:14] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056635 s / iter per device, on 1 devices)
[09/24 10:55:14] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4983709901096769, 'acc': 0.9967419802193538, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 10:55:14] cvalgorithms INFO:  eta: 10:20:07  iter: 99  total_loss: 0.876  decode.loss_seg: 0  aux_0.loss: 0.1005  cnt.cnt_loss: 0.339  loss: 0.438  time: 0.3687  data_time: 0.0050  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:55:14] cvalgorithms INFO:  eta: 10:20:12  iter: 101  total_loss: 0.876  decode.loss_seg: 0  aux_0.loss: 0.1005  cnt.cnt_loss: 0.339  loss: 0.438  time: 0.3693  data_time: 0.0052  lr: 0.00090451  max_mem: 3207M
[09/24 10:55:15] cvalgorithms INFO:  eta: 10:20:44  iter: 103  total_loss: 1.123  decode.loss_seg: 0  aux_0.loss: 0.09454  cnt.cnt_loss: 0.4465  loss: 0.5614  time: 0.3701  data_time: 0.0054  lr: 0.00034549  max_mem: 3207M
[09/24 10:55:16] cvalgorithms INFO:  eta: 10:21:42  iter: 105  total_loss: 1.123  decode.loss_seg: 0  aux_0.loss: 0.09454  cnt.cnt_loss: 0.4465  loss: 0.5614  time: 0.3706  data_time: 0.0055  lr: 0.001  max_mem: 3207M
[09/24 10:55:17] cvalgorithms INFO:  eta: 10:22:17  iter: 107  total_loss: 1.194  decode.loss_seg: 0  aux_0.loss: 0.09454  cnt.cnt_loss: 0.5062  loss: 0.597  time: 0.3710  data_time: 0.0056  lr: 0.00065451  max_mem: 3207M
[09/24 10:55:18] cvalgorithms INFO:  eta: 10:22:21  iter: 109  total_loss: 1.583  decode.loss_seg: 0  aux_0.loss: 0.1003  cnt.cnt_loss: 0.6974  loss: 0.7915  time: 0.3716  data_time: 0.0057  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:55:18] cvalgorithms INFO:  eta: 10:22:30  iter: 111  total_loss: 2.089  decode.loss_seg: 0  aux_0.loss: 0.08777  cnt.cnt_loss: 0.9391  loss: 1.044  time: 0.3723  data_time: 0.0058  lr: 0.00090451  max_mem: 3207M
[09/24 10:55:19] cvalgorithms INFO:  eta: 10:22:42  iter: 113  total_loss: 2.296  decode.loss_seg: 0  aux_0.loss: 0.08441  cnt.cnt_loss: 1.06  loss: 1.148  time: 0.3729  data_time: 0.0060  lr: 0.00034549  max_mem: 3207M
[09/24 10:55:20] cvalgorithms INFO:  eta: 10:22:51  iter: 115  total_loss: 1.583  decode.loss_seg: 0  aux_0.loss: 0.07921  cnt.cnt_loss: 0.6974  loss: 0.7915  time: 0.3737  data_time: 0.0063  lr: 0.001  max_mem: 3207M
[09/24 10:55:21] cvalgorithms INFO:  eta: 10:23:11  iter: 117  total_loss: 2.087  decode.loss_seg: 0  aux_0.loss: 0.07867  cnt.cnt_loss: 0.9526  loss: 1.044  time: 0.3743  data_time: 0.0064  lr: 0.00065451  max_mem: 3207M
[09/24 10:55:22] cvalgorithms INFO: Start inference on 216 batches
[09/24 10:55:50] cvalgorithms INFO: Total inference time: 0:00:12.974698 (0.061491 s / iter per device, on 1 devices)
[09/24 10:55:50] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.055836 s / iter per device, on 1 devices)
[09/24 10:55:50] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4970868748192123, 'acc': 0.9941737496384246, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 10:55:50] cvalgorithms INFO:  eta: 10:23:24  iter: 119  total_loss: 2.087  decode.loss_seg: 0  aux_0.loss: 0.07623  cnt.cnt_loss: 0.9526  loss: 1.044  time: 0.3747  data_time: 0.0066  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:55:51] cvalgorithms INFO:  eta: 10:23:28  iter: 121  total_loss: 1.772  decode.loss_seg: 0  aux_0.loss: 0.0721  cnt.cnt_loss: 0.8179  loss: 0.8862  time: 0.3748  data_time: 0.0064  lr: 0.00090451  max_mem: 3207M
[09/24 10:55:52] cvalgorithms INFO:  eta: 10:23:35  iter: 123  total_loss: 1.772  decode.loss_seg: 0  aux_0.loss: 0.06867  cnt.cnt_loss: 0.8179  loss: 0.8862  time: 0.3749  data_time: 0.0062  lr: 0.00034549  max_mem: 3207M
[09/24 10:55:52] cvalgorithms INFO:  eta: 10:23:48  iter: 125  total_loss: 2.404  decode.loss_seg: 0  aux_0.loss: 0.06658  cnt.cnt_loss: 1.129  loss: 1.202  time: 0.3750  data_time: 0.0061  lr: 0.001  max_mem: 3207M
[09/24 10:55:53] cvalgorithms INFO:  eta: 10:24:02  iter: 127  total_loss: 2.404  decode.loss_seg: 0  aux_0.loss: 0.07092  cnt.cnt_loss: 1.129  loss: 1.202  time: 0.3751  data_time: 0.0061  lr: 0.00065451  max_mem: 3207M
[09/24 10:55:54] cvalgorithms INFO:  eta: 10:24:11  iter: 129  total_loss: 2.012  decode.loss_seg: 0  aux_0.loss: 0.07092  cnt.cnt_loss: 0.9184  loss: 1.006  time: 0.3753  data_time: 0.0061  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:55:55] cvalgorithms INFO:  eta: 10:24:21  iter: 131  total_loss: 1.81  decode.loss_seg: 0  aux_0.loss: 0.07092  cnt.cnt_loss: 0.8107  loss: 0.9052  time: 0.3755  data_time: 0.0060  lr: 0.00090451  max_mem: 3207M
[09/24 10:55:55] cvalgorithms INFO:  eta: 10:24:32  iter: 133  total_loss: 1.911  decode.loss_seg: 0  aux_0.loss: 0.07092  cnt.cnt_loss: 0.8856  loss: 0.9554  time: 0.3757  data_time: 0.0059  lr: 0.00034549  max_mem: 3207M
[09/24 10:55:56] cvalgorithms INFO:  eta: 10:24:54  iter: 135  total_loss: 2.138  decode.loss_seg: 0  aux_0.loss: 0.0718  cnt.cnt_loss: 1.012  loss: 1.069  time: 0.3759  data_time: 0.0058  lr: 0.001  max_mem: 3207M
[09/24 10:55:57] cvalgorithms INFO:  eta: 10:25:18  iter: 137  total_loss: 2.138  decode.loss_seg: 0  aux_0.loss: 0.0718  cnt.cnt_loss: 1.012  loss: 1.069  time: 0.3762  data_time: 0.0056  lr: 0.00065451  max_mem: 3207M
[09/24 10:55:58] cvalgorithms INFO: Start inference on 216 batches
[09/24 10:56:26] cvalgorithms INFO: Total inference time: 0:00:13.181065 (0.062470 s / iter per device, on 1 devices)
[09/24 10:56:26] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.055998 s / iter per device, on 1 devices)
[09/24 10:56:26] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4981116180814142, 'acc': 0.9962232361628284, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 10:56:26] cvalgorithms INFO:  eta: 10:25:31  iter: 139  total_loss: 1.911  decode.loss_seg: 0  aux_0.loss: 0.0716  cnt.cnt_loss: 0.8856  loss: 0.9554  time: 0.3764  data_time: 0.0055  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:56:27] cvalgorithms INFO:  eta: 10:25:37  iter: 141  total_loss: 2.138  decode.loss_seg: 0  aux_0.loss: 0.0716  cnt.cnt_loss: 1.012  loss: 1.069  time: 0.3765  data_time: 0.0057  lr: 0.00090451  max_mem: 3207M
[09/24 10:56:28] cvalgorithms INFO:  eta: 10:25:47  iter: 143  total_loss: 1.911  decode.loss_seg: 0  aux_0.loss: 0.0683  cnt.cnt_loss: 0.8856  loss: 0.9554  time: 0.3766  data_time: 0.0057  lr: 0.00034549  max_mem: 3207M
[09/24 10:56:28] cvalgorithms INFO:  eta: 10:25:56  iter: 145  total_loss: 1.736  decode.loss_seg: 0  aux_0.loss: 0.06389  cnt.cnt_loss: 0.7744  loss: 0.8681  time: 0.3767  data_time: 0.0058  lr: 0.001  max_mem: 3207M
[09/24 10:56:29] cvalgorithms INFO:  eta: 10:26:10  iter: 147  total_loss: 1.817  decode.loss_seg: 0  aux_0.loss: 0.05453  cnt.cnt_loss: 0.8212  loss: 0.9085  time: 0.3768  data_time: 0.0058  lr: 0.00065451  max_mem: 3207M
[09/24 10:56:30] cvalgorithms INFO:  eta: 10:26:59  iter: 149  total_loss: 1.817  decode.loss_seg: 0  aux_0.loss: 0.05453  cnt.cnt_loss: 0.8212  loss: 0.9085  time: 0.3770  data_time: 0.0057  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:56:31] cvalgorithms INFO:  eta: 10:27:33  iter: 151  total_loss: 1.574  decode.loss_seg: 0  aux_0.loss: 0.05097  cnt.cnt_loss: 0.6971  loss: 0.7871  time: 0.3770  data_time: 0.0056  lr: 0.00090451  max_mem: 3207M
[09/24 10:56:31] cvalgorithms INFO:  eta: 10:27:33  iter: 153  total_loss: 1.316  decode.loss_seg: 0  aux_0.loss: 0.05016  cnt.cnt_loss: 0.5897  loss: 0.6582  time: 0.3771  data_time: 0.0056  lr: 0.00034549  max_mem: 3207M
[09/24 10:56:32] cvalgorithms INFO:  eta: 10:27:34  iter: 155  total_loss: 1.316  decode.loss_seg: 0  aux_0.loss: 0.05016  cnt.cnt_loss: 0.5897  loss: 0.6582  time: 0.3772  data_time: 0.0055  lr: 0.001  max_mem: 3207M
[09/24 10:56:33] cvalgorithms INFO:  eta: 10:27:40  iter: 157  total_loss: 1.316  decode.loss_seg: 0  aux_0.loss: 0.05386  cnt.cnt_loss: 0.5897  loss: 0.6582  time: 0.3774  data_time: 0.0055  lr: 0.00065451  max_mem: 3207M
[09/24 10:56:34] cvalgorithms INFO: Start inference on 216 batches
[09/24 10:57:02] cvalgorithms INFO: Total inference time: 0:00:13.093209 (0.062053 s / iter per device, on 1 devices)
[09/24 10:57:02] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056126 s / iter per device, on 1 devices)
[09/24 10:57:02] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4985068874756943, 'acc': 0.9970137749513887, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 10:57:02] cvalgorithms INFO:  eta: 10:27:50  iter: 159  total_loss: 1.485  decode.loss_seg: 0  aux_0.loss: 0.04922  cnt.cnt_loss: 0.6614  loss: 0.7426  time: 0.3775  data_time: 0.0055  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:57:03] cvalgorithms INFO:  eta: 10:28:05  iter: 161  total_loss: 1.316  decode.loss_seg: 0  aux_0.loss: 0.04545  cnt.cnt_loss: 0.5897  loss: 0.6582  time: 0.3778  data_time: 0.0071  lr: 0.00090451  max_mem: 3207M
[09/24 10:57:04] cvalgorithms INFO:  eta: 10:28:27  iter: 163  total_loss: 1.316  decode.loss_seg: 0  aux_0.loss: 0.04465  cnt.cnt_loss: 0.5897  loss: 0.6582  time: 0.3781  data_time: 0.0087  lr: 0.00034549  max_mem: 3207M
[09/24 10:57:05] cvalgorithms INFO:  eta: 10:28:26  iter: 165  total_loss: 1.485  decode.loss_seg: 0  aux_0.loss: 0.04465  cnt.cnt_loss: 0.6614  loss: 0.7426  time: 0.3782  data_time: 0.0088  lr: 0.001  max_mem: 3207M
[09/24 10:57:05] cvalgorithms INFO:  eta: 10:28:41  iter: 167  total_loss: 1.485  decode.loss_seg: 0  aux_0.loss: 0.04465  cnt.cnt_loss: 0.6614  loss: 0.7426  time: 0.3784  data_time: 0.0087  lr: 0.00065451  max_mem: 3207M
[09/24 10:57:06] cvalgorithms INFO:  eta: 10:28:52  iter: 169  total_loss: 1.667  decode.loss_seg: 0  aux_0.loss: 0.0432  cnt.cnt_loss: 0.7616  loss: 0.8334  time: 0.3785  data_time: 0.0087  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:57:07] cvalgorithms INFO:  eta: 10:29:11  iter: 171  total_loss: 1.667  decode.loss_seg: 0  aux_0.loss: 0.0432  cnt.cnt_loss: 0.7616  loss: 0.8334  time: 0.3786  data_time: 0.0088  lr: 0.00090451  max_mem: 3207M
[09/24 10:57:08] cvalgorithms INFO:  eta: 10:29:34  iter: 173  total_loss: 1.667  decode.loss_seg: 0  aux_0.loss: 0.04297  cnt.cnt_loss: 0.7616  loss: 0.8334  time: 0.3788  data_time: 0.0089  lr: 0.00034549  max_mem: 3207M
[09/24 10:57:09] cvalgorithms INFO:  eta: 10:29:56  iter: 175  total_loss: 1.667  decode.loss_seg: 0  aux_0.loss: 0.04042  cnt.cnt_loss: 0.7616  loss: 0.8334  time: 0.3789  data_time: 0.0089  lr: 0.001  max_mem: 3207M
[09/24 10:57:09] cvalgorithms INFO:  eta: 10:30:27  iter: 177  total_loss: 1.656  decode.loss_seg: 0  aux_0.loss: 0.04042  cnt.cnt_loss: 0.7715  loss: 0.828  time: 0.3793  data_time: 0.0089  lr: 0.00065451  max_mem: 3207M
[09/24 10:57:10] cvalgorithms INFO: Start inference on 216 batches
[09/24 10:57:39] cvalgorithms INFO: Total inference time: 0:00:13.187717 (0.062501 s / iter per device, on 1 devices)
[09/24 10:57:39] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056241 s / iter per device, on 1 devices)
[09/24 10:57:39] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4981747404396856, 'acc': 0.9963494808793713, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 10:57:39] cvalgorithms INFO:  eta: 10:31:18  iter: 179  total_loss: 1.344  decode.loss_seg: 0  aux_0.loss: 0.03907  cnt.cnt_loss: 0.604  loss: 0.6722  time: 0.3796  data_time: 0.0089  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:57:40] cvalgorithms INFO:  eta: 10:32:05  iter: 181  total_loss: 1.656  decode.loss_seg: 0  aux_0.loss: 0.04042  cnt.cnt_loss: 0.6927  loss: 0.828  time: 0.3798  data_time: 0.0072  lr: 0.00090451  max_mem: 3207M
[09/24 10:57:41] cvalgorithms INFO:  eta: 10:32:32  iter: 183  total_loss: 1.656  decode.loss_seg: 0  aux_0.loss: 0.04193  cnt.cnt_loss: 0.6927  loss: 0.828  time: 0.3803  data_time: 0.0057  lr: 0.00034549  max_mem: 3207M
[09/24 10:57:42] cvalgorithms INFO:  eta: 10:32:53  iter: 185  total_loss: 1.681  decode.loss_seg: 0  aux_0.loss: 0.04182  cnt.cnt_loss: 0.6927  loss: 0.8404  time: 0.3805  data_time: 0.0058  lr: 0.001  max_mem: 3207M
[09/24 10:57:43] cvalgorithms INFO:  eta: 10:33:10  iter: 187  total_loss: 1.681  decode.loss_seg: 0  aux_0.loss: 0.03993  cnt.cnt_loss: 0.6927  loss: 0.8404  time: 0.3808  data_time: 0.0059  lr: 0.00065451  max_mem: 3207M
[09/24 10:57:43] cvalgorithms INFO:  eta: 10:33:27  iter: 189  total_loss: 1.681  decode.loss_seg: 0  aux_0.loss: 0.04279  cnt.cnt_loss: 0.6927  loss: 0.8404  time: 0.3810  data_time: 0.0059  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:57:44] cvalgorithms INFO:  eta: 10:33:56  iter: 191  total_loss: 1.461  decode.loss_seg: 0  aux_0.loss: 0.03993  cnt.cnt_loss: 0.6561  loss: 0.7306  time: 0.3812  data_time: 0.0059  lr: 0.00090451  max_mem: 3207M
[09/24 10:57:45] cvalgorithms INFO:  eta: 10:34:21  iter: 193  total_loss: 1.461  decode.loss_seg: 0  aux_0.loss: 0.03689  cnt.cnt_loss: 0.6561  loss: 0.7306  time: 0.3815  data_time: 0.0059  lr: 0.00034549  max_mem: 3207M
[09/24 10:57:46] cvalgorithms INFO:  eta: 10:34:29  iter: 195  total_loss: 1.499  decode.loss_seg: 0  aux_0.loss: 0.03785  cnt.cnt_loss: 0.6834  loss: 0.7497  time: 0.3818  data_time: 0.0059  lr: 0.001  max_mem: 3207M
[09/24 10:57:47] cvalgorithms INFO:  eta: 10:34:37  iter: 197  total_loss: 1.417  decode.loss_seg: 0  aux_0.loss: 0.03638  cnt.cnt_loss: 0.6561  loss: 0.7086  time: 0.3820  data_time: 0.0059  lr: 0.00065451  max_mem: 3207M
[09/24 10:57:47] cvalgorithms INFO: Start inference on 216 batches
[09/24 10:58:17] cvalgorithms INFO: Total inference time: 0:00:13.098273 (0.062077 s / iter per device, on 1 devices)
[09/24 10:58:17] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056272 s / iter per device, on 1 devices)
[09/24 10:58:17] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49937008679361355, 'acc': 0.9987401735872271, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 10:58:17] cvalgorithms INFO:  eta: 10:35:05  iter: 199  total_loss: 1.417  decode.loss_seg: 0  aux_0.loss: 0.0354  cnt.cnt_loss: 0.6721  loss: 0.7086  time: 0.3822  data_time: 0.0059  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:58:18] cvalgorithms INFO:  eta: 10:35:52  iter: 201  total_loss: 1.417  decode.loss_seg: 0  aux_0.loss: 0.03528  cnt.cnt_loss: 0.6721  loss: 0.7086  time: 0.3823  data_time: 0.0059  lr: 0.00090451  max_mem: 3207M
[09/24 10:58:18] cvalgorithms INFO:  eta: 10:36:26  iter: 203  total_loss: 1.583  decode.loss_seg: 0  aux_0.loss: 0.03499  cnt.cnt_loss: 0.7595  loss: 0.7913  time: 0.3824  data_time: 0.0057  lr: 0.00034549  max_mem: 3207M
[09/24 10:58:19] cvalgorithms INFO:  eta: 10:36:44  iter: 205  total_loss: 1.583  decode.loss_seg: 0  aux_0.loss: 0.03343  cnt.cnt_loss: 0.7595  loss: 0.7913  time: 0.3827  data_time: 0.0057  lr: 0.001  max_mem: 3207M
[09/24 10:58:20] cvalgorithms INFO:  eta: 10:37:00  iter: 207  total_loss: 1.583  decode.loss_seg: 0  aux_0.loss: 0.03141  cnt.cnt_loss: 0.7595  loss: 0.7913  time: 0.3829  data_time: 0.0056  lr: 0.00065451  max_mem: 3207M
[09/24 10:58:21] cvalgorithms INFO:  eta: 10:37:04  iter: 209  total_loss: 1.583  decode.loss_seg: 0  aux_0.loss: 0.03034  cnt.cnt_loss: 0.7589  loss: 0.7913  time: 0.3833  data_time: 0.0056  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:58:22] cvalgorithms INFO:  eta: 10:37:20  iter: 211  total_loss: 1.583  decode.loss_seg: 0  aux_0.loss: 0.02917  cnt.cnt_loss: 0.7589  loss: 0.7913  time: 0.3835  data_time: 0.0057  lr: 0.00090451  max_mem: 3207M
[09/24 10:58:23] cvalgorithms INFO:  eta: 10:37:53  iter: 213  total_loss: 1.717  decode.loss_seg: 0  aux_0.loss: 0.03169  cnt.cnt_loss: 0.8191  loss: 0.8587  time: 0.3837  data_time: 0.0057  lr: 0.00034549  max_mem: 3207M
[09/24 10:58:23] cvalgorithms INFO:  eta: 10:38:13  iter: 215  total_loss: 1.552  decode.loss_seg: 0  aux_0.loss: 0.02999  cnt.cnt_loss: 0.7402  loss: 0.776  time: 0.3840  data_time: 0.0058  lr: 0.001  max_mem: 3207M
[09/24 10:58:24] cvalgorithms INFO:  eta: 10:38:33  iter: 217  total_loss: 1.33  decode.loss_seg: 0  aux_0.loss: 0.02917  cnt.cnt_loss: 0.6343  loss: 0.6649  time: 0.3842  data_time: 0.0058  lr: 0.00065451  max_mem: 3207M
[09/24 10:58:25] cvalgorithms INFO: Start inference on 216 batches
[09/24 10:58:55] cvalgorithms INFO: Total inference time: 0:00:13.373536 (0.063382 s / iter per device, on 1 devices)
[09/24 10:58:55] cvalgorithms INFO: Total inference pure compute time: 0:00:11 (0.056870 s / iter per device, on 1 devices)
[09/24 10:58:55] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49867467904916873, 'acc': 0.9973493580983375, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 10:58:55] cvalgorithms INFO:  eta: 10:38:58  iter: 219  total_loss: 1.33  decode.loss_seg: 0  aux_0.loss: 0.02959  cnt.cnt_loss: 0.5919  loss: 0.6649  time: 0.3844  data_time: 0.0058  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:58:56] cvalgorithms INFO:  eta: 10:39:09  iter: 221  total_loss: 1.196  decode.loss_seg: 0  aux_0.loss: 0.02848  cnt.cnt_loss: 0.5561  loss: 0.5981  time: 0.3845  data_time: 0.0058  lr: 0.00090451  max_mem: 3207M
[09/24 10:58:57] cvalgorithms INFO:  eta: 10:39:14  iter: 223  total_loss: 1.33  decode.loss_seg: 0  aux_0.loss: 0.02848  cnt.cnt_loss: 0.5919  loss: 0.6649  time: 0.3847  data_time: 0.0059  lr: 0.00034549  max_mem: 3207M
[09/24 10:58:58] cvalgorithms INFO:  eta: 10:39:35  iter: 225  total_loss: 1.196  decode.loss_seg: 0  aux_0.loss: 0.0283  cnt.cnt_loss: 0.5561  loss: 0.5981  time: 0.3850  data_time: 0.0059  lr: 0.001  max_mem: 3207M
[09/24 10:58:58] cvalgorithms INFO:  eta: 10:39:58  iter: 227  total_loss: 1.196  decode.loss_seg: 0  aux_0.loss: 0.0283  cnt.cnt_loss: 0.5561  loss: 0.5981  time: 0.3851  data_time: 0.0059  lr: 0.00065451  max_mem: 3207M
[09/24 10:58:59] cvalgorithms INFO:  eta: 10:40:17  iter: 229  total_loss: 1.196  decode.loss_seg: 0  aux_0.loss: 0.0283  cnt.cnt_loss: 0.5561  loss: 0.5981  time: 0.3853  data_time: 0.0059  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:59:00] cvalgorithms INFO:  eta: 10:40:35  iter: 231  total_loss: 1.07  decode.loss_seg: 0  aux_0.loss: 0.0283  cnt.cnt_loss: 0.5081  loss: 0.5349  time: 0.3855  data_time: 0.0059  lr: 0.00090451  max_mem: 3207M
[09/24 10:59:01] cvalgorithms INFO:  eta: 10:40:45  iter: 233  total_loss: 1.07  decode.loss_seg: 0  aux_0.loss: 0.0283  cnt.cnt_loss: 0.5081  loss: 0.5349  time: 0.3857  data_time: 0.0058  lr: 0.00034549  max_mem: 3207M
[09/24 10:59:02] cvalgorithms INFO:  eta: 10:41:08  iter: 235  total_loss: 1.847  decode.loss_seg: 0  aux_0.loss: 0.02925  cnt.cnt_loss: 0.7644  loss: 0.9234  time: 0.3860  data_time: 0.0059  lr: 0.001  max_mem: 3207M
[09/24 10:59:03] cvalgorithms INFO:  eta: 10:41:32  iter: 237  total_loss: 2.267  decode.loss_seg: 0  aux_0.loss: 0.02925  cnt.cnt_loss: 1.029  loss: 1.134  time: 0.3878  data_time: 0.0060  lr: 0.00065451  max_mem: 3207M
[09/24 10:59:04] cvalgorithms INFO: Start inference on 216 batches
[09/24 10:59:35] cvalgorithms INFO: Total inference time: 0:00:13.522103 (0.064086 s / iter per device, on 1 devices)
[09/24 10:59:35] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.057528 s / iter per device, on 1 devices)
[09/24 10:59:35] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4986690728241099, 'acc': 0.9973381456482198, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 10:59:35] cvalgorithms INFO:  eta: 10:42:00  iter: 239  total_loss: 2.267  decode.loss_seg: 0  aux_0.loss: 0.02854  cnt.cnt_loss: 1.029  loss: 1.134  time: 0.3882  data_time: 0.0060  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:59:35] cvalgorithms INFO:  eta: 10:42:31  iter: 241  total_loss: 1.94  decode.loss_seg: 0  aux_0.loss: 0.02854  cnt.cnt_loss: 0.8546  loss: 0.9701  time: 0.3883  data_time: 0.0060  lr: 0.00090451  max_mem: 3207M
[09/24 10:59:36] cvalgorithms INFO:  eta: 10:42:50  iter: 243  total_loss: 1.43  decode.loss_seg: 0  aux_0.loss: 0.02687  cnt.cnt_loss: 0.6863  loss: 0.7151  time: 0.3886  data_time: 0.0060  lr: 0.00034549  max_mem: 3207M
[09/24 10:59:37] cvalgorithms INFO:  eta: 10:43:19  iter: 245  total_loss: 1.57  decode.loss_seg: 0  aux_0.loss: 0.02651  cnt.cnt_loss: 0.7481  loss: 0.7851  time: 0.3889  data_time: 0.0060  lr: 0.001  max_mem: 3207M
[09/24 10:59:38] cvalgorithms INFO:  eta: 10:43:55  iter: 247  total_loss: 1.573  decode.loss_seg: 0  aux_0.loss: 0.0266  cnt.cnt_loss: 0.7481  loss: 0.7865  time: 0.3891  data_time: 0.0061  lr: 0.00065451  max_mem: 3207M
[09/24 10:59:39] cvalgorithms INFO:  eta: 10:44:17  iter: 249  total_loss: 1.626  decode.loss_seg: 0  aux_0.loss: 0.0266  cnt.cnt_loss: 0.7589  loss: 0.8132  time: 0.3893  data_time: 0.0062  lr: 9.5492e-05  max_mem: 3207M
[09/24 10:59:40] cvalgorithms INFO:  eta: 10:44:27  iter: 251  total_loss: 1.847  decode.loss_seg: 0  aux_0.loss: 0.02689  cnt.cnt_loss: 0.8562  loss: 0.9236  time: 0.3895  data_time: 0.0062  lr: 0.00090451  max_mem: 3207M
[09/24 10:59:40] cvalgorithms INFO:  eta: 10:44:44  iter: 253  total_loss: 1.626  decode.loss_seg: 0  aux_0.loss: 0.0266  cnt.cnt_loss: 0.7589  loss: 0.8132  time: 0.3898  data_time: 0.0063  lr: 0.00034549  max_mem: 3207M
[09/24 10:59:41] cvalgorithms INFO:  eta: 10:45:05  iter: 255  total_loss: 1.626  decode.loss_seg: 0  aux_0.loss: 0.02651  cnt.cnt_loss: 0.7589  loss: 0.8132  time: 0.3903  data_time: 0.0062  lr: 0.001  max_mem: 3207M
[09/24 10:59:42] cvalgorithms INFO:  eta: 10:45:16  iter: 257  total_loss: 1.761  decode.loss_seg: 0  aux_0.loss: 0.02651  cnt.cnt_loss: 0.8314  loss: 0.8805  time: 0.3907  data_time: 0.0062  lr: 0.00065451  max_mem: 3207M
[09/24 10:59:43] cvalgorithms INFO: Start inference on 216 batches
[09/24 11:00:14] cvalgorithms INFO: Total inference time: 0:00:13.551362 (0.064224 s / iter per device, on 1 devices)
[09/24 11:00:14] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.057900 s / iter per device, on 1 devices)
[09/24 11:00:14] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4985658830484723, 'acc': 0.9971317660969446, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 11:00:14] cvalgorithms INFO:  eta: 10:45:32  iter: 259  total_loss: 1.94  decode.loss_seg: 0  aux_0.loss: 0.02834  cnt.cnt_loss: 0.9446  loss: 0.9702  time: 0.3910  data_time: 0.0063  lr: 9.5492e-05  max_mem: 3207M
[09/24 11:00:15] cvalgorithms INFO:  eta: 10:45:43  iter: 261  total_loss: 2.313  decode.loss_seg: 0  aux_0.loss: 0.03075  cnt.cnt_loss: 1.131  loss: 1.156  time: 0.3913  data_time: 0.0063  lr: 0.00090451  max_mem: 3207M
[09/24 11:00:16] cvalgorithms INFO:  eta: 10:46:07  iter: 263  total_loss: 2.313  decode.loss_seg: 0  aux_0.loss: 0.03127  cnt.cnt_loss: 1.131  loss: 1.156  time: 0.3914  data_time: 0.0062  lr: 0.00034549  max_mem: 3207M
[09/24 11:00:17] cvalgorithms INFO:  eta: 10:46:06  iter: 265  total_loss: 2.582  decode.loss_seg: 0  aux_0.loss: 0.03127  cnt.cnt_loss: 1.258  loss: 1.291  time: 0.3915  data_time: 0.0063  lr: 0.001  max_mem: 3207M
[09/24 11:00:17] cvalgorithms INFO:  eta: 10:46:36  iter: 267  total_loss: 3.28  decode.loss_seg: 0  aux_0.loss: 0.03354  cnt.cnt_loss: 1.496  loss: 1.64  time: 0.3920  data_time: 0.0063  lr: 0.00065451  max_mem: 3207M
[09/24 11:00:18] cvalgorithms INFO:  eta: 10:47:46  iter: 269  total_loss: 3.388  decode.loss_seg: 0  aux_0.loss: 0.04216  cnt.cnt_loss: 1.603  loss: 1.694  time: 0.3923  data_time: 0.0062  lr: 9.5492e-05  max_mem: 3207M
[09/24 11:00:19] cvalgorithms INFO:  eta: 10:49:08  iter: 271  total_loss: 3.486  decode.loss_seg: 0  aux_0.loss: 0.04216  cnt.cnt_loss: 1.635  loss: 1.743  time: 0.3928  data_time: 0.0062  lr: 0.00090451  max_mem: 3207M
[09/24 11:00:20] cvalgorithms INFO:  eta: 10:50:07  iter: 273  total_loss: 3.322  decode.loss_seg: 0  aux_0.loss: 0.0376  cnt.cnt_loss: 1.635  loss: 1.661  time: 0.3932  data_time: 0.0062  lr: 0.00034549  max_mem: 3207M
[09/24 11:00:21] cvalgorithms INFO:  eta: 10:50:50  iter: 275  total_loss: 2.948  decode.loss_seg: 0  aux_0.loss: 0.04216  cnt.cnt_loss: 1.44  loss: 1.474  time: 0.3939  data_time: 0.0061  lr: 0.001  max_mem: 3207M
[09/24 11:00:22] cvalgorithms INFO:  eta: 10:50:58  iter: 277  total_loss: 3.272  decode.loss_seg: 0  aux_0.loss: 0.04216  cnt.cnt_loss: 1.587  loss: 1.636  time: 0.3943  data_time: 0.0062  lr: 0.00065451  max_mem: 3207M
[09/24 11:00:23] cvalgorithms INFO: Start inference on 216 batches
[09/24 11:00:54] cvalgorithms INFO: Total inference time: 0:00:13.567204 (0.064300 s / iter per device, on 1 devices)
[09/24 11:00:54] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.057969 s / iter per device, on 1 devices)
[09/24 11:00:54] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49765547013021677, 'acc': 0.9953109402604335, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 11:00:54] cvalgorithms INFO:  eta: 10:51:05  iter: 279  total_loss: 3.056  decode.loss_seg: 0  aux_0.loss: 0.03549  cnt.cnt_loss: 1.5  loss: 1.528  time: 0.3947  data_time: 0.0062  lr: 9.5492e-05  max_mem: 3207M
[09/24 11:00:55] cvalgorithms INFO:  eta: 10:51:15  iter: 281  total_loss: 2.509  decode.loss_seg: 0  aux_0.loss: 0.03117  cnt.cnt_loss: 1.225  loss: 1.254  time: 0.3949  data_time: 0.0062  lr: 0.00090451  max_mem: 3207M
[09/24 11:00:56] cvalgorithms INFO:  eta: 10:51:42  iter: 283  total_loss: 3.056  decode.loss_seg: 0  aux_0.loss: 0.03132  cnt.cnt_loss: 1.5  loss: 1.528  time: 0.3952  data_time: 0.0061  lr: 0.00034549  max_mem: 3207M
[09/24 11:00:56] cvalgorithms INFO:  eta: 10:52:01  iter: 285  total_loss: 3.114  decode.loss_seg: 0  aux_0.loss: 0.03132  cnt.cnt_loss: 1.508  loss: 1.557  time: 0.3953  data_time: 0.0061  lr: 0.001  max_mem: 3207M
[09/24 11:00:57] cvalgorithms INFO:  eta: 10:52:20  iter: 287  total_loss: 2.438  decode.loss_seg: 0  aux_0.loss: 0.02869  cnt.cnt_loss: 1.19  loss: 1.219  time: 0.3956  data_time: 0.0061  lr: 0.00065451  max_mem: 3207M
[09/24 11:00:58] cvalgorithms INFO:  eta: 10:52:44  iter: 289  total_loss: 1.953  decode.loss_seg: 0  aux_0.loss: 0.02741  cnt.cnt_loss: 0.916  loss: 0.9763  time: 0.3964  data_time: 0.0061  lr: 9.5492e-05  max_mem: 3207M
[09/24 11:00:59] cvalgorithms INFO:  eta: 10:52:51  iter: 291  total_loss: 1.751  decode.loss_seg: 0  aux_0.loss: 0.02679  cnt.cnt_loss: 0.8196  loss: 0.8757  time: 0.3968  data_time: 0.0061  lr: 0.00090451  max_mem: 3207M
[09/24 11:01:00] cvalgorithms INFO:  eta: 10:53:00  iter: 293  total_loss: 1.751  decode.loss_seg: 0  aux_0.loss: 0.02679  cnt.cnt_loss: 0.8196  loss: 0.8757  time: 0.3971  data_time: 0.0060  lr: 0.00034549  max_mem: 3207M
[09/24 11:01:01] cvalgorithms INFO:  eta: 10:53:16  iter: 295  total_loss: 1.751  decode.loss_seg: 0  aux_0.loss: 0.02581  cnt.cnt_loss: 0.8196  loss: 0.8757  time: 0.3973  data_time: 0.0061  lr: 0.001  max_mem: 3207M
[09/24 11:01:02] cvalgorithms INFO:  eta: 10:54:02  iter: 297  total_loss: 1.751  decode.loss_seg: 0  aux_0.loss: 0.02581  cnt.cnt_loss: 0.8196  loss: 0.8757  time: 0.3981  data_time: 0.0060  lr: 0.00065451  max_mem: 3207M
[09/24 11:01:03] cvalgorithms INFO: Start inference on 216 batches
[09/24 11:01:34] cvalgorithms INFO: Total inference time: 0:00:13.684572 (0.064856 s / iter per device, on 1 devices)
[09/24 11:01:34] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.058340 s / iter per device, on 1 devices)
[09/24 11:01:34] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49751515339063945, 'acc': 0.9950303067812789, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 11:01:34] cvalgorithms INFO:  eta: 10:54:45  iter: 299  total_loss: 1.751  decode.loss_seg: 0  aux_0.loss: 0.02581  cnt.cnt_loss: 0.8196  loss: 0.8757  time: 0.3988  data_time: 0.0059  lr: 9.5492e-05  max_mem: 3207M
[09/24 11:01:35] cvalgorithms INFO:  eta: 10:55:23  iter: 301  total_loss: 1.966  decode.loss_seg: 0  aux_0.loss: 0.02581  cnt.cnt_loss: 0.8924  loss: 0.9831  time: 0.3992  data_time: 0.0059  lr: 0.00090451  max_mem: 3207M
[09/24 11:01:36] cvalgorithms INFO:  eta: 10:56:00  iter: 303  total_loss: 1.527  decode.loss_seg: 0  aux_0.loss: 0.02177  cnt.cnt_loss: 0.7066  loss: 0.7634  time: 0.3995  data_time: 0.0060  lr: 0.00034549  max_mem: 3207M
[09/24 11:01:37] cvalgorithms INFO:  eta: 10:56:06  iter: 305  total_loss: 1.873  decode.loss_seg: 0  aux_0.loss: 0.01999  cnt.cnt_loss: 0.8828  loss: 0.9365  time: 0.3999  data_time: 0.0060  lr: 0.001  max_mem: 3207M
[09/24 11:01:38] cvalgorithms INFO:  eta: 10:56:09  iter: 307  total_loss: 1.873  decode.loss_seg: 0  aux_0.loss: 0.01999  cnt.cnt_loss: 0.8828  loss: 0.9365  time: 0.3999  data_time: 0.0060  lr: 0.00065451  max_mem: 3207M
[09/24 11:01:39] cvalgorithms INFO:  eta: 10:56:13  iter: 309  total_loss: 1.873  decode.loss_seg: 0  aux_0.loss: 0.01999  cnt.cnt_loss: 0.8828  loss: 0.9365  time: 0.4003  data_time: 0.0060  lr: 9.5492e-05  max_mem: 3207M
[09/24 11:01:40] cvalgorithms INFO:  eta: 10:56:16  iter: 311  total_loss: 2.008  decode.loss_seg: 0  aux_0.loss: 0.02583  cnt.cnt_loss: 0.9488  loss: 1.004  time: 0.4007  data_time: 0.0060  lr: 0.00090451  max_mem: 3207M
[09/24 11:01:41] cvalgorithms INFO:  eta: 10:56:25  iter: 313  total_loss: 2.008  decode.loss_seg: 0  aux_0.loss: 0.02583  cnt.cnt_loss: 0.9488  loss: 1.004  time: 0.4009  data_time: 0.0061  lr: 0.00034549  max_mem: 3207M
[09/24 11:01:42] cvalgorithms INFO:  eta: 10:56:48  iter: 315  total_loss: 2.008  decode.loss_seg: 0  aux_0.loss: 0.03762  cnt.cnt_loss: 0.9488  loss: 1.004  time: 0.4013  data_time: 0.0060  lr: 0.001  max_mem: 3207M
[09/24 11:01:43] cvalgorithms INFO:  eta: 10:57:23  iter: 317  total_loss: 2.031  decode.loss_seg: 0  aux_0.loss: 0.02981  cnt.cnt_loss: 0.9969  loss: 1.015  time: 0.4017  data_time: 0.0061  lr: 0.00065451  max_mem: 3207M
[09/24 11:01:43] cvalgorithms INFO: Start inference on 216 batches
[09/24 11:02:15] cvalgorithms INFO: Total inference time: 0:00:13.731556 (0.065078 s / iter per device, on 1 devices)
[09/24 11:02:15] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.058996 s / iter per device, on 1 devices)
[09/24 11:02:15] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4982172357963554, 'acc': 0.9964344715927108, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 11:02:15] cvalgorithms INFO:  eta: 10:58:00  iter: 319  total_loss: 2.031  decode.loss_seg: 0  aux_0.loss: 0.02981  cnt.cnt_loss: 0.9593  loss: 1.015  time: 0.4020  data_time: 0.0061  lr: 9.5492e-05  max_mem: 3207M
[09/24 11:02:16] cvalgorithms INFO:  eta: 10:58:45  iter: 321  total_loss: 2.816  decode.loss_seg: 0  aux_0.loss: 0.04582  cnt.cnt_loss: 1.142  loss: 1.408  time: 0.4021  data_time: 0.0062  lr: 0.00090451  max_mem: 3207M
[09/24 11:02:17] cvalgorithms INFO:  eta: 10:59:20  iter: 323  total_loss: 2.458  decode.loss_seg: 0  aux_0.loss: 0.04668  cnt.cnt_loss: 0.9713  loss: 1.229  time: 0.4023  data_time: 0.0063  lr: 0.00034549  max_mem: 3207M
[09/24 11:02:18] cvalgorithms INFO:  eta: 10:59:29  iter: 325  total_loss: 2.19  decode.loss_seg: 0  aux_0.loss: 0.04668  cnt.cnt_loss: 0.8811  loss: 1.095  time: 0.4026  data_time: 0.0063  lr: 0.001  max_mem: 3207M
[09/24 11:02:19] cvalgorithms INFO:  eta: 10:59:45  iter: 327  total_loss: 2.683  decode.loss_seg: 0  aux_0.loss: 0.05053  cnt.cnt_loss: 0.9713  loss: 1.341  time: 0.4030  data_time: 0.0063  lr: 0.00065451  max_mem: 3207M
[09/24 11:02:19] cvalgorithms INFO:  eta: 11:00:03  iter: 329  total_loss: 2.19  decode.loss_seg: 0  aux_0.loss: 0.04172  cnt.cnt_loss: 0.8811  loss: 1.095  time: 0.4034  data_time: 0.0063  lr: 9.5492e-05  max_mem: 3207M
[09/24 11:02:20] cvalgorithms INFO:  eta: 11:00:13  iter: 331  total_loss: 1.986  decode.loss_seg: 0  aux_0.loss: 0.03919  cnt.cnt_loss: 0.8164  loss: 0.9929  time: 0.4037  data_time: 0.0064  lr: 0.00090451  max_mem: 3207M
[09/24 11:02:21] cvalgorithms INFO:  eta: 11:00:46  iter: 333  total_loss: 1.618  decode.loss_seg: 0  aux_0.loss: 0.03753  cnt.cnt_loss: 0.7846  loss: 0.8088  time: 0.4040  data_time: 0.0064  lr: 0.00034549  max_mem: 3207M
[09/24 11:02:22] cvalgorithms INFO:  eta: 11:01:15  iter: 335  total_loss: 1.564  decode.loss_seg: 0  aux_0.loss: 0.03587  cnt.cnt_loss: 0.7471  loss: 0.782  time: 0.4044  data_time: 0.0064  lr: 0.001  max_mem: 3207M
[09/24 11:02:23] cvalgorithms INFO:  eta: 11:01:21  iter: 337  total_loss: 0.648  decode.loss_seg: 0  aux_0.loss: 0.03158  cnt.cnt_loss: 0.2934  loss: 0.324  time: 0.4048  data_time: 0.0064  lr: 0.00065451  max_mem: 3207M
[09/24 11:02:24] cvalgorithms INFO: Start inference on 216 batches
[09/24 11:02:56] cvalgorithms INFO: Total inference time: 0:00:14.001181 (0.066356 s / iter per device, on 1 devices)
[09/24 11:02:56] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.059296 s / iter per device, on 1 devices)
[09/24 11:02:56] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4990149318271683, 'acc': 0.9980298636543365, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 11:02:56] cvalgorithms INFO:  eta: 11:01:29  iter: 339  total_loss: 0.575  decode.loss_seg: 0  aux_0.loss: 0.03158  cnt.cnt_loss: 0.2633  loss: 0.2875  time: 0.4050  data_time: 0.0065  lr: 9.5492e-05  max_mem: 3207M
[09/24 11:02:57] cvalgorithms INFO:  eta: 11:01:44  iter: 341  total_loss: 0.5483  decode.loss_seg: 0  aux_0.loss: 0.02985  cnt.cnt_loss: 0.254  loss: 0.2742  time: 0.4051  data_time: 0.0064  lr: 0.00090451  max_mem: 3207M
[09/24 11:02:58] cvalgorithms INFO:  eta: 11:02:32  iter: 343  total_loss: 0.5221  decode.loss_seg: 0  aux_0.loss: 0.0282  cnt.cnt_loss: 0.2476  loss: 0.261  time: 0.4051  data_time: 0.0064  lr: 0.00034549  max_mem: 3207M
[09/24 11:02:59] cvalgorithms INFO:  eta: 11:03:48  iter: 345  total_loss: 0.575  decode.loss_seg: 0  aux_0.loss: 0.02768  cnt.cnt_loss: 0.2633  loss: 0.2875  time: 0.4053  data_time: 0.0063  lr: 0.001  max_mem: 3207M
[09/24 11:02:59] cvalgorithms INFO:  eta: 11:04:27  iter: 347  total_loss: 0.575  decode.loss_seg: 0  aux_0.loss: 0.02485  cnt.cnt_loss: 0.2633  loss: 0.2875  time: 0.4056  data_time: 0.0063  lr: 0.00065451  max_mem: 3207M
[09/24 11:03:00] cvalgorithms INFO:  eta: 11:04:34  iter: 349  total_loss: 0.575  decode.loss_seg: 0  aux_0.loss: 0.02279  cnt.cnt_loss: 0.2633  loss: 0.2875  time: 0.4060  data_time: 0.0064  lr: 9.5492e-05  max_mem: 3207M
[09/24 11:03:01] cvalgorithms INFO:  eta: 11:04:39  iter: 351  total_loss: 0.6844  decode.loss_seg: 0  aux_0.loss: 0.01819  cnt.cnt_loss: 0.3244  loss: 0.3422  time: 0.4064  data_time: 0.0063  lr: 0.00090451  max_mem: 3207M
[09/24 11:03:02] cvalgorithms INFO:  eta: 11:05:08  iter: 353  total_loss: 0.8731  decode.loss_seg: 0  aux_0.loss: 0.01752  cnt.cnt_loss: 0.4236  loss: 0.4365  time: 0.4068  data_time: 0.0063  lr: 0.00034549  max_mem: 3207M
[09/24 11:03:03] cvalgorithms INFO:  eta: 11:05:36  iter: 355  total_loss: 1.479  decode.loss_seg: 0  aux_0.loss: 0.01613  cnt.cnt_loss: 0.6366  loss: 0.7395  time: 0.4074  data_time: 0.0063  lr: 0.001  max_mem: 3207M
[09/24 11:03:04] cvalgorithms INFO:  eta: 11:05:41  iter: 357  total_loss: 2.151  decode.loss_seg: 0  aux_0.loss: 0.01915  cnt.cnt_loss: 0.9119  loss: 1.076  time: 0.4077  data_time: 0.0062  lr: 0.00065451  max_mem: 3207M
[09/24 11:03:05] cvalgorithms INFO: Start inference on 216 batches
[09/24 11:03:37] cvalgorithms INFO: Total inference time: 0:00:14.207095 (0.067332 s / iter per device, on 1 devices)
[09/24 11:03:37] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.060676 s / iter per device, on 1 devices)
[09/24 11:03:37] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.4977982117506051, 'acc': 0.9955964235012102, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 11:03:37] cvalgorithms INFO:  eta: 11:05:52  iter: 359  total_loss: 2.151  decode.loss_seg: 0  aux_0.loss: 0.01838  cnt.cnt_loss: 0.9119  loss: 1.076  time: 0.4083  data_time: 0.0062  lr: 9.5492e-05  max_mem: 3207M
[09/24 11:03:38] cvalgorithms INFO:  eta: 11:06:34  iter: 361  total_loss: 1.524  decode.loss_seg: 0  aux_0.loss: 0.01495  cnt.cnt_loss: 0.6589  loss: 0.7621  time: 0.4086  data_time: 0.0062  lr: 0.00090451  max_mem: 3207M
[09/24 11:03:39] cvalgorithms INFO:  eta: 11:07:11  iter: 363  total_loss: 1.396  decode.loss_seg: 0  aux_0.loss: 0.0159  cnt.cnt_loss: 0.6589  loss: 0.6981  time: 0.4089  data_time: 0.0061  lr: 0.00034549  max_mem: 3207M
[09/24 11:03:40] cvalgorithms INFO:  eta: 11:07:20  iter: 365  total_loss: 1.02  decode.loss_seg: 0  aux_0.loss: 0.01531  cnt.cnt_loss: 0.4966  loss: 0.51  time: 0.4092  data_time: 0.0062  lr: 0.001  max_mem: 3207M
[09/24 11:03:41] cvalgorithms INFO:  eta: 11:07:30  iter: 367  total_loss: 0.8731  decode.loss_seg: 0  aux_0.loss: 0.01492  cnt.cnt_loss: 0.4236  loss: 0.4365  time: 0.4096  data_time: 0.0062  lr: 0.00065451  max_mem: 3207M
[09/24 11:03:42] cvalgorithms INFO:  eta: 11:07:41  iter: 369  total_loss: 1.02  decode.loss_seg: 0  aux_0.loss: 0.01536  cnt.cnt_loss: 0.4966  loss: 0.51  time: 0.4099  data_time: 0.0062  lr: 9.5492e-05  max_mem: 3207M
[09/24 11:03:43] cvalgorithms INFO:  eta: 11:08:08  iter: 371  total_loss: 1.276  decode.loss_seg: 0  aux_0.loss: 0.01592  cnt.cnt_loss: 0.5759  loss: 0.6382  time: 0.4102  data_time: 0.0062  lr: 0.00090451  max_mem: 3207M
[09/24 11:03:44] cvalgorithms INFO:  eta: 11:08:28  iter: 373  total_loss: 1.081  decode.loss_seg: 0  aux_0.loss: 0.01592  cnt.cnt_loss: 0.5261  loss: 0.5406  time: 0.4105  data_time: 0.0062  lr: 0.00034549  max_mem: 3207M
[09/24 11:03:45] cvalgorithms INFO:  eta: 11:09:03  iter: 375  total_loss: 1.081  decode.loss_seg: 0  aux_0.loss: 0.01592  cnt.cnt_loss: 0.5261  loss: 0.5406  time: 0.4107  data_time: 0.0063  lr: 0.001  max_mem: 3207M
[09/24 11:03:46] cvalgorithms INFO:  eta: 11:09:42  iter: 377  total_loss: 1.276  decode.loss_seg: 0  aux_0.loss: 0.01721  cnt.cnt_loss: 0.5759  loss: 0.6382  time: 0.4113  data_time: 0.0063  lr: 0.00065451  max_mem: 3207M
[09/24 11:03:47] cvalgorithms INFO: Start inference on 216 batches
[09/24 11:04:19] cvalgorithms INFO: Total inference time: 0:00:14.261154 (0.067588 s / iter per device, on 1 devices)
[09/24 11:04:19] cvalgorithms INFO: Total inference pure compute time: 0:00:12 (0.060923 s / iter per device, on 1 devices)
[09/24 11:04:19] cvalgorithms INFO: OrderedDict([('levir', {'miou': 0.49741860719055625, 'acc': 0.9948372143811125, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0})])
[09/24 11:04:19] cvalgorithms INFO:  eta: 11:09:53  iter: 379  total_loss: 1.276  decode.loss_seg: 0  aux_0.loss: 0.01721  cnt.cnt_loss: 0.5759  loss: 0.6382  time: 0.4117  data_time: 0.0063  lr: 9.5492e-05  max_mem: 3207M
[09/24 11:04:20] cvalgorithms INFO:  eta: 11:10:03  iter: 381  total_loss: 1.57  decode.loss_seg: 0  aux_0.loss: 0.01913  cnt.cnt_loss: 0.6503  loss: 0.7849  time: 0.4118  data_time: 0.0062  lr: 0.00090451  max_mem: 3207M
[09/24 11:04:21] cvalgorithms INFO:  eta: 11:10:07  iter: 383  total_loss: 1.57  decode.loss_seg: 0  aux_0.loss: 0.02066  cnt.cnt_loss: 0.6503  loss: 0.7849  time: 0.4120  data_time: 0.0062  lr: 0.00034549  max_mem: 3207M
[09/24 11:04:22] cvalgorithms INFO:  eta: 11:10:11  iter: 385  total_loss: 1.513  decode.loss_seg: 0  aux_0.loss: 0.02437  cnt.cnt_loss: 0.6503  loss: 0.7563  time: 0.4123  data_time: 0.0063  lr: 0.001  max_mem: 3207M
[09/24 11:04:23] cvalgorithms INFO:  eta: 11:10:26  iter: 387  total_loss: 1.895  decode.loss_seg: 0  aux_0.loss: 0.03028  cnt.cnt_loss: 0.7442  loss: 0.9477  time: 0.4130  data_time: 0.0063  lr: 0.00065451  max_mem: 3207M
[09/24 11:04:24] cvalgorithms INFO:  eta: 11:10:43  iter: 389  total_loss: 2.221  decode.loss_seg: 0  aux_0.loss: 0.03153  cnt.cnt_loss: 0.8973  loss: 1.11  time: 0.4134  data_time: 0.0068  lr: 9.5492e-05  max_mem: 3207M
[09/24 11:04:25] cvalgorithms INFO:  eta: 11:11:09  iter: 391  total_loss: 2.363  decode.loss_seg: 0  aux_0.loss: 0.04118  cnt.cnt_loss: 1.081  loss: 1.181  time: 0.4138  data_time: 0.0068  lr: 0.00090451  max_mem: 3207M
[09/24 11:04:26] cvalgorithms INFO:  eta: 11:11:31  iter: 393  total_loss: 2.221  decode.loss_seg: 0  aux_0.loss: 0.04118  cnt.cnt_loss: 0.8769  loss: 1.11  time: 0.4142  data_time: 0.0068  lr: 0.00034549  max_mem: 3207M
[09/24 11:04:27] cvalgorithms INFO:  eta: 11:11:48  iter: 395  total_loss: 1.838  decode.loss_seg: 0  aux_0.loss: 0.03192  cnt.cnt_loss: 0.705  loss: 0.9192  time: 0.4145  data_time: 0.0068  lr: 0.001  max_mem: 3207M
[09/24 11:04:28] cvalgorithms INFO:  eta: 11:12:16  iter: 397  total_loss: 1.373  decode.loss_seg: 0  aux_0.loss: 0.0347  cnt.cnt_loss: 0.6018  loss: 0.6865  time: 0.4149  data_time: 0.0068  lr: 0.00065451  max_mem: 3207M
[09/24 11:04:29] cvalgorithms INFO: Start inference on 216 batches
[09/26 15:44:05] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/26 15:44:33] cvalgorithms INFO: Starting training from iteration 0
[09/26 15:44:39] cvalgorithms INFO:  iter: 1  total_loss: 244.6  decode.loss_seg: 0  aux_0.loss: 0.6812  cnt.cnt_loss: 121.6  loss: 122.3  data_time: 0.0539  lr: 0.00090451  max_mem: 3207M
[09/26 15:44:39] cvalgorithms INFO:  eta: 9:37:35  iter: 3  total_loss: 108.5  decode.loss_seg: 0  aux_0.loss: 0.6613  cnt.cnt_loss: 53.59  loss: 54.25  time: 0.3466  data_time: 0.0290  lr: 0.00034549  max_mem: 3207M
[09/26 15:44:40] cvalgorithms INFO:  eta: 9:37:34  iter: 5  total_loss: 108.5  decode.loss_seg: 0  aux_0.loss: 0.6462  cnt.cnt_loss: 53.59  loss: 54.25  time: 0.3489  data_time: 0.0208  lr: 0.001  max_mem: 3207M
[09/26 15:44:41] cvalgorithms INFO:  eta: 9:38:46  iter: 7  total_loss: 108.5  decode.loss_seg: 0  aux_0.loss: 0.633  cnt.cnt_loss: 53.59  loss: 54.25  time: 0.3488  data_time: 0.0166  lr: 0.00065451  max_mem: 3207M
[09/26 15:44:41] cvalgorithms INFO:  eta: 9:38:17  iter: 9  total_loss: 100.5  decode.loss_seg: 0  aux_0.loss: 0.6237  cnt.cnt_loss: 49.63  loss: 50.27  time: 0.3482  data_time: 0.0141  lr: 9.5492e-05  max_mem: 3207M
[09/26 15:44:42] cvalgorithms INFO:  eta: 9:38:18  iter: 11  total_loss: 92.02  decode.loss_seg: 0  aux_0.loss: 0.6108  cnt.cnt_loss: 45.42  loss: 46.01  time: 0.3480  data_time: 0.0125  lr: 0.00090451  max_mem: 3207M
[09/26 15:44:43] cvalgorithms INFO:  eta: 9:38:45  iter: 13  total_loss: 86.06  decode.loss_seg: 0  aux_0.loss: 0.5911  cnt.cnt_loss: 42.49  loss: 43.03  time: 0.3480  data_time: 0.0113  lr: 0.00034549  max_mem: 3207M
[09/26 15:44:43] cvalgorithms INFO:  eta: 9:39:24  iter: 15  total_loss: 87.42  decode.loss_seg: 0  aux_0.loss: 0.5788  cnt.cnt_loss: 43.19  loss: 43.71  time: 0.3482  data_time: 0.0105  lr: 0.001  max_mem: 3207M
[09/26 15:44:44] cvalgorithms INFO:  eta: 9:39:53  iter: 17  total_loss: 84.43  decode.loss_seg: 0  aux_0.loss: 0.5671  cnt.cnt_loss: 41.71  loss: 42.22  time: 0.3490  data_time: 0.0099  lr: 0.00065451  max_mem: 3207M
[09/26 15:44:45] cvalgorithms INFO: Start inference on 216 batches
[09/26 15:45:25] cvalgorithms INFO: Total inference time: 0:00:11.866941 (0.056241 s / iter per device, on 1 devices)
[09/26 15:45:25] cvalgorithms INFO: Total inference pure compute time: 0:00:10 (0.050570 s / iter per device, on 1 devices)
[09/26 21:01:38] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[09/26 21:02:07] cvalgorithms INFO: Starting training from iteration 0
[09/26 21:02:10] cvalgorithms INFO:  iter: 1  total_loss: 63.55  decode.loss_seg: -0.0001423  aux_0.loss: 0.6836  cnt.cnt_loss: 31.09  loss: 31.77  data_time: 0.0546  lr: 0.00090451  max_mem: 3207M
[09/26 21:02:11] cvalgorithms INFO:  eta: 9:38:13  iter: 3  total_loss: 63.55  decode.loss_seg: -6.079e-10  aux_0.loss: 0.6682  cnt.cnt_loss: 31.09  loss: 31.77  time: 0.3470  data_time: 0.0296  lr: 0.00034549  max_mem: 3207M
[09/26 21:02:12] cvalgorithms INFO:  eta: 9:38:13  iter: 5  total_loss: 64.28  decode.loss_seg: 0  aux_0.loss: 0.6461  cnt.cnt_loss: 31.48  loss: 32.14  time: 0.3487  data_time: 0.0212  lr: 0.001  max_mem: 3207M
[09/26 21:02:12] cvalgorithms INFO:  eta: 9:38:12  iter: 7  total_loss: 54.65  decode.loss_seg: 0  aux_0.loss: 0.6251  cnt.cnt_loss: 26.68  loss: 27.32  time: 0.3482  data_time: 0.0169  lr: 0.00065451  max_mem: 3207M
[09/26 21:02:13] cvalgorithms INFO:  eta: 9:39:30  iter: 9  total_loss: 64.28  decode.loss_seg: 0  aux_0.loss: 0.6205  cnt.cnt_loss: 31.48  loss: 32.14  time: 0.3488  data_time: 0.0144  lr: 9.5492e-05  max_mem: 3207M
[09/26 21:02:14] cvalgorithms INFO:  eta: 9:40:50  iter: 11  total_loss: 68.83  decode.loss_seg: 0  aux_0.loss: 0.6102  cnt.cnt_loss: 33.8  loss: 34.41  time: 0.3490  data_time: 0.0128  lr: 0.00090451  max_mem: 3207M
[09/26 21:02:14] cvalgorithms INFO:  eta: 9:40:55  iter: 13  total_loss: 68.83  decode.loss_seg: 0  aux_0.loss: 0.5904  cnt.cnt_loss: 33.8  loss: 34.41  time: 0.3494  data_time: 0.0116  lr: 0.00034549  max_mem: 3207M
[09/26 21:02:15] cvalgorithms INFO:  eta: 9:41:02  iter: 15  total_loss: 61.63  decode.loss_seg: 0  aux_0.loss: 0.5797  cnt.cnt_loss: 30.3  loss: 30.82  time: 0.3494  data_time: 0.0107  lr: 0.001  max_mem: 3207M
[09/26 21:02:16] cvalgorithms INFO:  eta: 9:41:21  iter: 17  total_loss: 57.09  decode.loss_seg: 0  aux_0.loss: 0.5676  cnt.cnt_loss: 27.98  loss: 28.54  time: 0.3494  data_time: 0.0100  lr: 0.00065451  max_mem: 3207M
[09/26 21:02:16] cvalgorithms INFO: Start inference on 216 batches
[11/03 14:24:31] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[11/03 14:25:02] cvalgorithms INFO: Starting training from iteration 0
