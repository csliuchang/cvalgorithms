[06/27 17:58:19] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[06/27 17:58:19] cvalgorithms INFO: pretrained checkpoint is loaded.
[06/27 17:58:25] cvalgorithms INFO: Starting training from iteration 0
[06/27 17:58:29] cvalgorithms INFO:  iter: 0  total_loss: 118.6  decode.loss_seg: -5.333e-06  aux_0.loss: 1.415e-06  cnt.cnt_loss: 59.3  loss: 59.3  data_time: 0.0816  lr: N/A  max_mem: 3221M
[06/27 17:58:30] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 345, in _get_eta
    eta_seconds = storage.history("time").median(1000) * (self._max_iter - iteration - 1)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 207, in history
    raise KeyError("No history metric available for {}!".format(name))
KeyError: 'No history metric available for time!'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 122, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 144, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 301, in after_step
    writer.write()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 378, in write
    eta_string = self._get_eta(storage)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 353, in _get_eta
    iteration - self._last_write[0]
ZeroDivisionError: float division by zero
[06/27 18:56:52] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[06/27 18:56:52] cvalgorithms INFO: pretrained checkpoint is loaded.
[06/27 18:57:13] cvalgorithms INFO: Starting training from iteration 0
[06/28 18:41:40] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[06/28 18:41:41] cvalgorithms INFO: pretrained checkpoint is loaded.
[06/30 17:43:03] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[06/30 17:43:03] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 14:44:14] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/01 14:44:14] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 14:49:39] cvalgorithms INFO: Starting training from iteration 0
[07/01 16:18:02] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/01 16:18:02] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 16:18:46] cvalgorithms INFO: Starting training from iteration 0
[07/01 16:19:06] cvalgorithms INFO: Starting training from iteration 0
[07/01 16:40:45] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/01 16:40:45] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 16:40:55] cvalgorithms INFO: Starting training from iteration 0
[07/01 17:01:10] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/01 17:01:10] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 17:04:01] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/01 17:04:01] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 17:04:02] cvalgorithms INFO: Starting training from iteration 0
[07/01 17:04:06] cvalgorithms INFO:  iter: 0  total_loss: 259.1  decode.loss_seg: 8.504e-06  aux_0.loss: -6.991e-06  cnt.cnt_loss: 129.6  loss: 129.6  data_time: 0.0964  lr: N/A  max_mem: 3221M
[07/01 17:04:06] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 345, in _get_eta
    eta_seconds = storage.history("time").median(1000) * (self._max_iter - iteration - 1)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 207, in history
    raise KeyError("No history metric available for {}!".format(name))
KeyError: 'No history metric available for time!'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 122, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 144, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 301, in after_step
    writer.write()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 378, in write
    eta_string = self._get_eta(storage)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 353, in _get_eta
    iteration - self._last_write[0]
ZeroDivisionError: float division by zero
[07/01 17:05:09] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/01 17:05:09] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/01 17:05:10] cvalgorithms INFO: Starting training from iteration 0
[07/01 17:08:07] cvalgorithms INFO:  iter: 0  total_loss: 337.1  decode.loss_seg: -0.001191  aux_0.loss: 4.829e-06  cnt.cnt_loss: 168.6  loss: 168.6  data_time: 0.0845  lr: N/A  max_mem: 3221M
[07/05 10:26:48] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 10:26:48] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 10:26:50] cvalgorithms INFO: Starting training from iteration 0
[07/05 10:27:49] cvalgorithms INFO:  iter: 0  total_loss: 151.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 75.9  loss: 75.9  data_time: 0.0901  lr: N/A  max_mem: 3221M
[07/05 10:36:53] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 10:36:53] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 10:36:54] cvalgorithms INFO: Starting training from iteration 0
[07/05 10:39:40] cvalgorithms INFO:  iter: 0  total_loss: 311  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 155.5  loss: 155.5  data_time: 0.0870  lr: N/A  max_mem: 3221M
[07/05 10:39:41] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 345, in _get_eta
    eta_seconds = storage.history("time").median(1000) * (self._max_iter - iteration - 1)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 207, in history
    raise KeyError("No history metric available for {}!".format(name))
KeyError: 'No history metric available for time!'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 122, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 144, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 303, in after_step
    writer.write()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 378, in write
    eta_string = self._get_eta(storage)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 353, in _get_eta
    iteration - self._last_write[0]
ZeroDivisionError: float division by zero
[07/05 10:46:03] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 10:46:03] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 11:05:42] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 11:05:42] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 11:05:42] cvalgorithms INFO: Starting training from iteration 0
[07/05 11:05:45] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 118, in train
    self.before_train()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 132, in before_train
    h.before_train()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 319, in before_train
    self._optimizer = self._optimizer or self.trainer.optimizer
AttributeError: 'TrainerContainer' object has no attribute 'optimizer'
[07/05 11:05:45] cvalgorithms INFO:  iter: 0    lr: N/A  max_mem: 0M
[07/05 11:07:46] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 11:07:47] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 11:07:47] cvalgorithms INFO: Starting training from iteration 0
[07/05 11:07:51] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 121, in train
    self.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 133, in run_step
    self._trainer.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 208, in run_step
    loss_dict = self.model(_img, ground_truth=_ground_truth, return_metrics=True)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 305, in forward
    metrics = self.forward_train(inputs, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 211, in forward_train
    x = self.extract_feat(inputs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\seg\segmentors\siamese_encoder_decoder.py", line 57, in extract_feat
    features_n, features_g = self.backbone(inputs_switch), self.backbone(inputs_g)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\models\base\backbone\convnext.py", line 83, in forward
    x = self.downsample_layers[i](x)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\container.py", line 119, in forward
    input = module(input)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\module.py", line 889, in _call_impl
    result = self.forward(*input, **kwargs)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\conv.py", line 399, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\nn\modules\conv.py", line 396, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same
[07/05 11:07:51] cvalgorithms INFO:  iter: 0    lr: N/A  max_mem: 17M
[07/05 11:09:03] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 11:09:03] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 11:09:04] cvalgorithms INFO: Starting training from iteration 0
[07/05 11:09:10] cvalgorithms INFO:  iter: 0  total_loss: 135.5  decode.loss_seg: -0.002456  aux_0.loss: -1.628e-05  cnt.cnt_loss: 67.74  loss: 67.73  data_time: 0.0854  lr: 0.00090451  max_mem: 3221M
[07/05 11:09:11] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 345, in _get_eta
    eta_seconds = storage.history("time").median(1000) * (self._max_iter - iteration - 1)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 207, in history
    raise KeyError("No history metric available for {}!".format(name))
KeyError: 'No history metric available for time!'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 122, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 144, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 303, in after_step
    writer.write()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 378, in write
    eta_string = self._get_eta(storage)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 353, in _get_eta
    iteration - self._last_write[0]
ZeroDivisionError: float division by zero
[07/05 11:14:09] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 11:14:09] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 11:14:10] cvalgorithms INFO: Starting training from iteration 0
[07/05 11:43:56] cvalgorithms INFO:  iter: 0  total_loss: 486.3  decode.loss_seg: 0.0006568  aux_0.loss: 1.233e-06  cnt.cnt_loss: 243.1  loss: 243.1  data_time: 0.1017  lr: 0.00090451  max_mem: 3221M
[07/05 11:44:11] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 345, in _get_eta
    eta_seconds = storage.history("time").median(1000) * (self._max_iter - iteration - 1)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 207, in history
    raise KeyError("No history metric available for {}!".format(name))
KeyError: 'No history metric available for time!'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 122, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 144, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 303, in after_step
    writer.write()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 378, in write
    eta_string = self._get_eta(storage)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 353, in _get_eta
    iteration - self._last_write[0]
ZeroDivisionError: float division by zero
[07/05 12:19:02] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 12:19:02] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 12:19:03] cvalgorithms INFO: Starting training from iteration 0
[07/05 13:15:18] cvalgorithms INFO:  iter: 0  total_loss: 238.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 119.3  loss: 119.3  data_time: 0.1068  lr: 0.00090451  max_mem: 3221M
[07/05 13:22:25] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 13:22:25] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 13:22:26] cvalgorithms INFO: Starting training from iteration 0
[07/05 13:23:44] cvalgorithms INFO:  iter: 0  total_loss: 220.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 110.1  loss: 110.1  data_time: 0.0851  lr: 0.00090451  max_mem: 3221M
[07/05 13:23:51] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 345, in _get_eta
    eta_seconds = storage.history("time").median(1000) * (self._max_iter - iteration - 1)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 207, in history
    raise KeyError("No history metric available for {}!".format(name))
KeyError: 'No history metric available for time!'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 122, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 144, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 303, in after_step
    writer.write()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 378, in write
    eta_string = self._get_eta(storage)
  File "C:\Users\user1\PycharmProjects\cvalgorithms\utils\events.py", line 353, in _get_eta
    iteration - self._last_write[0]
ZeroDivisionError: float division by zero
[07/05 13:35:37] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 13:35:37] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 13:35:38] cvalgorithms INFO: Starting training from iteration 0
[07/05 13:40:17] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 13:40:17] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 13:40:18] cvalgorithms INFO: Starting training from iteration 0
[07/05 13:40:47] cvalgorithms INFO:  iter: 1  total_loss: 459.5  decode.loss_seg: 0.0008303  aux_0.loss: 4.342e-06  cnt.cnt_loss: 229.7  loss: 229.8  data_time: 0.1050  lr: 0.00090451  max_mem: 3221M
[07/05 13:40:52] cvalgorithms INFO:  eta: 0:01:01  iter: 3  total_loss: 284.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 142.1  loss: 142.1  time: 0.6388  data_time: 0.0899  lr: 0.00034549  max_mem: 3221M
[07/05 13:40:53] cvalgorithms INFO:  eta: 0:00:49  iter: 5  total_loss: 145.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.76  loss: 72.76  time: 0.5316  data_time: 0.0832  lr: 0.001  max_mem: 3221M
[07/05 13:40:53] cvalgorithms INFO:  eta: 0:00:39  iter: 7  total_loss: 111.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 55.7  loss: 55.7  time: 0.4963  data_time: 0.0804  lr: 0.00065451  max_mem: 3221M
[07/05 13:40:54] cvalgorithms INFO:  eta: 0:00:38  iter: 9  total_loss: 88.96  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 44.48  loss: 44.48  time: 0.4782  data_time: 0.0791  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:40:55] cvalgorithms INFO:  eta: 0:00:37  iter: 11  total_loss: 88.96  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 44.48  loss: 44.48  time: 0.4650  data_time: 0.0767  lr: 0.00090451  max_mem: 3221M
[07/05 13:40:56] cvalgorithms INFO:  eta: 0:00:36  iter: 13  total_loss: 71.86  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.93  loss: 35.93  time: 0.4566  data_time: 0.0751  lr: 0.00034549  max_mem: 3221M
[07/05 13:40:57] cvalgorithms INFO:  eta: 0:00:35  iter: 15  total_loss: 70.47  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.24  loss: 35.24  time: 0.4500  data_time: 0.0736  lr: 0.001  max_mem: 3221M
[07/05 13:40:58] cvalgorithms INFO:  eta: 0:00:34  iter: 17  total_loss: 66.16  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 33.08  loss: 33.08  time: 0.4455  data_time: 0.0728  lr: 0.00065451  max_mem: 3221M
[07/05 13:40:58] cvalgorithms INFO:  eta: 0:00:33  iter: 19  total_loss: 65.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.92  loss: 32.92  time: 0.4440  data_time: 0.0736  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:40:59] cvalgorithms INFO:  eta: 0:00:32  iter: 21  total_loss: 53.66  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 26.83  loss: 26.83  time: 0.4411  data_time: 0.0698  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:00] cvalgorithms INFO:  eta: 0:00:31  iter: 23  total_loss: 38.56  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 19.28  loss: 19.28  time: 0.4401  data_time: 0.0703  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:01] cvalgorithms INFO:  eta: 0:00:30  iter: 25  total_loss: 35.45  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.73  loss: 17.73  time: 0.4382  data_time: 0.0701  lr: 0.001  max_mem: 3221M
[07/05 13:41:02] cvalgorithms INFO:  eta: 0:00:29  iter: 27  total_loss: 30.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 15.15  loss: 15.15  time: 0.4369  data_time: 0.0702  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:03] cvalgorithms INFO:  eta: 0:00:29  iter: 29  total_loss: 27.34  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 13.67  loss: 13.67  time: 0.4359  data_time: 0.0699  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:03] cvalgorithms INFO:  eta: 0:00:28  iter: 31  total_loss: 24.31  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.16  loss: 12.16  time: 0.4347  data_time: 0.0702  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:04] cvalgorithms INFO:  eta: 0:00:27  iter: 33  total_loss: 22.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 11.1  loss: 11.1  time: 0.4341  data_time: 0.0712  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:05] cvalgorithms INFO:  eta: 0:00:26  iter: 35  total_loss: 18.89  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 9.447  loss: 9.447  time: 0.4330  data_time: 0.0714  lr: 0.001  max_mem: 3221M
[07/05 13:41:06] cvalgorithms INFO:  eta: 0:00:25  iter: 37  total_loss: 15.22  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.611  loss: 7.611  time: 0.4322  data_time: 0.0715  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:07] cvalgorithms INFO:  eta: 0:00:25  iter: 39  total_loss: 14.29  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.143  loss: 7.143  time: 0.4320  data_time: 0.0707  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:08] cvalgorithms INFO:  eta: 0:00:24  iter: 41  total_loss: 11.99  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.995  loss: 5.995  time: 0.4320  data_time: 0.0719  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:09] cvalgorithms INFO:  eta: 0:00:23  iter: 43  total_loss: 11.13  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.566  loss: 5.566  time: 0.4315  data_time: 0.0708  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:09] cvalgorithms INFO:  eta: 0:00:22  iter: 45  total_loss: 8.259  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.13  loss: 4.13  time: 0.4314  data_time: 0.0709  lr: 0.001  max_mem: 3221M
[07/05 13:41:10] cvalgorithms INFO:  eta: 0:00:21  iter: 47  total_loss: 6.297  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.148  loss: 3.148  time: 0.4313  data_time: 0.0707  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:11] cvalgorithms INFO:  eta: 0:00:20  iter: 49  total_loss: 5.63  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.815  loss: 2.815  time: 0.4312  data_time: 0.0710  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:12] cvalgorithms INFO:  eta: 0:00:20  iter: 51  total_loss: 4.95  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.475  loss: 2.475  time: 0.4309  data_time: 0.0714  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:13] cvalgorithms INFO:  eta: 0:00:19  iter: 53  total_loss: 4.61  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.305  loss: 2.305  time: 0.4309  data_time: 0.0715  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:14] cvalgorithms INFO:  eta: 0:00:18  iter: 55  total_loss: 4.215  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.108  loss: 2.108  time: 0.4311  data_time: 0.0729  lr: 0.001  max_mem: 3221M
[07/05 13:41:15] cvalgorithms INFO:  eta: 0:00:17  iter: 57  total_loss: 4.214  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.107  loss: 2.107  time: 0.4309  data_time: 0.0734  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:16] cvalgorithms INFO:  eta: 0:00:16  iter: 59  total_loss: 3.629  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.814  loss: 1.814  time: 0.4313  data_time: 0.0733  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:16] cvalgorithms INFO:  eta: 0:00:15  iter: 61  total_loss: 3.466  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.733  loss: 1.733  time: 0.4320  data_time: 0.0734  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:17] cvalgorithms INFO:  eta: 0:00:15  iter: 63  total_loss: 3.26  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.63  loss: 1.63  time: 0.4333  data_time: 0.0752  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:18] cvalgorithms INFO:  eta: 0:00:14  iter: 65  total_loss: 2.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.415  loss: 1.415  time: 0.4332  data_time: 0.0754  lr: 0.001  max_mem: 3221M
[07/05 13:41:19] cvalgorithms INFO:  eta: 0:00:13  iter: 67  total_loss: 2.461  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.231  loss: 1.231  time: 0.4331  data_time: 0.0749  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:20] cvalgorithms INFO:  eta: 0:00:12  iter: 69  total_loss: 2.461  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.231  loss: 1.231  time: 0.4330  data_time: 0.0745  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:21] cvalgorithms INFO:  eta: 0:00:11  iter: 71  total_loss: 1.452  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.726  loss: 0.726  time: 0.4329  data_time: 0.0742  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:22] cvalgorithms INFO:  eta: 0:00:11  iter: 73  total_loss: 1.43  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7149  loss: 0.7149  time: 0.4332  data_time: 0.0749  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:23] cvalgorithms INFO:  eta: 0:00:10  iter: 75  total_loss: 1.187  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5937  loss: 0.5937  time: 0.4331  data_time: 0.0740  lr: 0.001  max_mem: 3221M
[07/05 13:41:24] cvalgorithms INFO:  eta: 0:00:09  iter: 77  total_loss: 1.187  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5937  loss: 0.5937  time: 0.4334  data_time: 0.0748  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:24] cvalgorithms INFO:  eta: 0:00:08  iter: 79  total_loss: 2.12  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.06  loss: 1.06  time: 0.4334  data_time: 0.0748  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:25] cvalgorithms INFO:  eta: 0:00:07  iter: 81  total_loss: 2.12  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.06  loss: 1.06  time: 0.4336  data_time: 0.0739  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:26] cvalgorithms INFO:  eta: 0:00:06  iter: 83  total_loss: 1.43  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7149  loss: 0.7149  time: 0.4338  data_time: 0.0722  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:27] cvalgorithms INFO:  eta: 0:00:05  iter: 85  total_loss: 1.187  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5937  loss: 0.5937  time: 0.4341  data_time: 0.0726  lr: 0.001  max_mem: 3221M
[07/05 13:41:28] cvalgorithms INFO:  eta: 0:00:05  iter: 87  total_loss: 1.187  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5937  loss: 0.5937  time: 0.4345  data_time: 0.0732  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:29] cvalgorithms INFO:  eta: 0:00:04  iter: 89  total_loss: 1.121  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5606  loss: 0.5606  time: 0.4347  data_time: 0.0732  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:30] cvalgorithms INFO:  eta: 0:00:03  iter: 91  total_loss: 1.367  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6835  loss: 0.6835  time: 0.4351  data_time: 0.0736  lr: 0.00090451  max_mem: 3221M
[07/05 13:41:31] cvalgorithms INFO:  eta: 0:00:02  iter: 93  total_loss: 1.703  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8517  loss: 0.8517  time: 0.4362  data_time: 0.0747  lr: 0.00034549  max_mem: 3221M
[07/05 13:41:32] cvalgorithms INFO:  eta: 0:00:01  iter: 95  total_loss: 1.703  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8517  loss: 0.8517  time: 0.4370  data_time: 0.0767  lr: 0.001  max_mem: 3221M
[07/05 13:41:33] cvalgorithms INFO:  eta: 0:00:00  iter: 97  total_loss: 1.611  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8055  loss: 0.8055  time: 0.4375  data_time: 0.0759  lr: 0.00065451  max_mem: 3221M
[07/05 13:41:34] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.09  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5449  loss: 0.5449  time: 0.4379  data_time: 0.0767  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:41:34] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.09  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5449  loss: 0.5449  time: 0.4379  data_time: 0.0767  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:12] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 13:43:12] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 13:43:13] cvalgorithms INFO: Starting training from iteration 0
[07/05 13:43:16] cvalgorithms INFO:  iter: 1  total_loss: 442  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 221  loss: 221  data_time: 0.0733  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:17] cvalgorithms INFO:  eta: 0:00:40  iter: 3  total_loss: 264.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 132.3  loss: 132.3  time: 0.4224  data_time: 0.0703  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:18] cvalgorithms INFO:  eta: 0:00:39  iter: 5  total_loss: 192.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 96.25  loss: 96.25  time: 0.4211  data_time: 0.0680  lr: 0.001  max_mem: 3221M
[07/05 13:43:19] cvalgorithms INFO:  eta: 0:00:38  iter: 7  total_loss: 177  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 88.49  loss: 88.49  time: 0.4222  data_time: 0.0681  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:20] cvalgorithms INFO:  eta: 0:00:37  iter: 9  total_loss: 160.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 80.45  loss: 80.45  time: 0.4210  data_time: 0.0673  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:20] cvalgorithms INFO:  eta: 0:00:37  iter: 11  total_loss: 160.9  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 80.45  loss: 80.45  time: 0.4222  data_time: 0.0682  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:21] cvalgorithms INFO:  eta: 0:00:35  iter: 13  total_loss: 152.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 76.1  loss: 76.1  time: 0.4209  data_time: 0.0669  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:22] cvalgorithms INFO:  eta: 0:00:35  iter: 15  total_loss: 144.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 72.4  loss: 72.4  time: 0.4215  data_time: 0.0655  lr: 0.001  max_mem: 3221M
[07/05 13:43:23] cvalgorithms INFO:  eta: 0:00:34  iter: 17  total_loss: 140.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 70.38  loss: 70.38  time: 0.4220  data_time: 0.0652  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:24] cvalgorithms INFO:  eta: 0:00:33  iter: 19  total_loss: 137  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 68.51  loss: 68.51  time: 0.4228  data_time: 0.0658  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:25] cvalgorithms INFO:  eta: 0:00:32  iter: 21  total_loss: 71.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 35.92  loss: 35.92  time: 0.4228  data_time: 0.0641  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:26] cvalgorithms INFO:  eta: 0:00:32  iter: 23  total_loss: 60.87  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 30.44  loss: 30.44  time: 0.4253  data_time: 0.0645  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:26] cvalgorithms INFO:  eta: 0:00:31  iter: 25  total_loss: 56.48  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 28.24  loss: 28.24  time: 0.4264  data_time: 0.0645  lr: 0.001  max_mem: 3221M
[07/05 13:43:27] cvalgorithms INFO:  eta: 0:00:30  iter: 27  total_loss: 44.49  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 22.24  loss: 22.24  time: 0.4281  data_time: 0.0649  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:28] cvalgorithms INFO:  eta: 0:00:29  iter: 29  total_loss: 33.24  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.62  loss: 16.62  time: 0.4296  data_time: 0.0657  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:29] cvalgorithms INFO:  eta: 0:00:29  iter: 31  total_loss: 24.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.15  loss: 12.15  time: 0.4310  data_time: 0.0652  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:30] cvalgorithms INFO:  eta: 0:00:28  iter: 33  total_loss: 20.39  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 10.19  loss: 10.19  time: 0.4323  data_time: 0.0661  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:31] cvalgorithms INFO:  eta: 0:00:27  iter: 35  total_loss: 17.71  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 8.853  loss: 8.853  time: 0.4348  data_time: 0.0685  lr: 0.001  max_mem: 3221M
[07/05 13:43:32] cvalgorithms INFO:  eta: 0:00:26  iter: 37  total_loss: 15.56  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.779  loss: 7.779  time: 0.4355  data_time: 0.0693  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:33] cvalgorithms INFO:  eta: 0:00:26  iter: 39  total_loss: 13.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.605  loss: 6.605  time: 0.4362  data_time: 0.0686  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:34] cvalgorithms INFO:  eta: 0:00:25  iter: 41  total_loss: 10.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.406  loss: 5.406  time: 0.4366  data_time: 0.0693  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:35] cvalgorithms INFO:  eta: 0:00:24  iter: 43  total_loss: 9.898  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.949  loss: 4.949  time: 0.4381  data_time: 0.0703  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:36] cvalgorithms INFO:  eta: 0:00:23  iter: 45  total_loss: 7.13  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.565  loss: 3.565  time: 0.4388  data_time: 0.0710  lr: 0.001  max_mem: 3221M
[07/05 13:43:37] cvalgorithms INFO:  eta: 0:00:22  iter: 47  total_loss: 5.412  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.706  loss: 2.706  time: 0.4396  data_time: 0.0706  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:37] cvalgorithms INFO:  eta: 0:00:22  iter: 49  total_loss: 4.628  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.314  loss: 2.314  time: 0.4403  data_time: 0.0705  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:38] cvalgorithms INFO:  eta: 0:00:21  iter: 51  total_loss: 4.048  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.024  loss: 2.024  time: 0.4411  data_time: 0.0710  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:39] cvalgorithms INFO:  eta: 0:00:20  iter: 53  total_loss: 3.775  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.887  loss: 1.887  time: 0.4419  data_time: 0.0710  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:40] cvalgorithms INFO:  eta: 0:00:19  iter: 55  total_loss: 3.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.8  loss: 1.8  time: 0.4423  data_time: 0.0693  lr: 0.001  max_mem: 3221M
[07/05 13:43:41] cvalgorithms INFO:  eta: 0:00:18  iter: 57  total_loss: 3.161  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.581  loss: 1.581  time: 0.4427  data_time: 0.0692  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:42] cvalgorithms INFO:  eta: 0:00:17  iter: 59  total_loss: 3.419  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.71  loss: 1.71  time: 0.4434  data_time: 0.0703  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:43] cvalgorithms INFO:  eta: 0:00:16  iter: 61  total_loss: 2.944  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.472  loss: 1.472  time: 0.4435  data_time: 0.0710  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:44] cvalgorithms INFO:  eta: 0:00:16  iter: 63  total_loss: 2.754  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.377  loss: 1.377  time: 0.4441  data_time: 0.0707  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:45] cvalgorithms INFO:  eta: 0:00:15  iter: 65  total_loss: 2.05  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.025  loss: 1.025  time: 0.4451  data_time: 0.0717  lr: 0.001  max_mem: 3221M
[07/05 13:43:46] cvalgorithms INFO:  eta: 0:00:14  iter: 67  total_loss: 1.675  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8376  loss: 0.8376  time: 0.4461  data_time: 0.0736  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:47] cvalgorithms INFO:  eta: 0:00:13  iter: 69  total_loss: 1.675  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8376  loss: 0.8376  time: 0.4471  data_time: 0.0755  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:48] cvalgorithms INFO:  eta: 0:00:12  iter: 71  total_loss: 1.413  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7065  loss: 0.7065  time: 0.4474  data_time: 0.0754  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:49] cvalgorithms INFO:  eta: 0:00:11  iter: 73  total_loss: 2.085  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.043  loss: 1.043  time: 0.4482  data_time: 0.0769  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:50] cvalgorithms INFO:  eta: 0:00:10  iter: 75  total_loss: 2.862  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.431  loss: 1.431  time: 0.4487  data_time: 0.0781  lr: 0.001  max_mem: 3221M
[07/05 13:43:51] cvalgorithms INFO:  eta: 0:00:09  iter: 77  total_loss: 3.105  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.553  loss: 1.553  time: 0.4491  data_time: 0.0784  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:51] cvalgorithms INFO:  eta: 0:00:09  iter: 79  total_loss: 2.231  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.115  loss: 1.115  time: 0.4495  data_time: 0.0782  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:52] cvalgorithms INFO:  eta: 0:00:08  iter: 81  total_loss: 2.22  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.11  loss: 1.11  time: 0.4497  data_time: 0.0781  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:53] cvalgorithms INFO:  eta: 0:00:07  iter: 83  total_loss: 2.45  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.225  loss: 1.225  time: 0.4507  data_time: 0.0797  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:54] cvalgorithms INFO:  eta: 0:00:06  iter: 85  total_loss: 3.105  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.553  loss: 1.553  time: 0.4511  data_time: 0.0799  lr: 0.001  max_mem: 3221M
[07/05 13:43:55] cvalgorithms INFO:  eta: 0:00:05  iter: 87  total_loss: 3.116  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.558  loss: 1.558  time: 0.4516  data_time: 0.0792  lr: 0.00065451  max_mem: 3221M
[07/05 13:43:56] cvalgorithms INFO:  eta: 0:00:04  iter: 89  total_loss: 2.45  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.225  loss: 1.225  time: 0.4526  data_time: 0.0794  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:43:57] cvalgorithms INFO:  eta: 0:00:03  iter: 91  total_loss: 2.45  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.225  loss: 1.225  time: 0.4527  data_time: 0.0794  lr: 0.00090451  max_mem: 3221M
[07/05 13:43:58] cvalgorithms INFO:  eta: 0:00:02  iter: 93  total_loss: 1.504  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7518  loss: 0.7518  time: 0.4531  data_time: 0.0784  lr: 0.00034549  max_mem: 3221M
[07/05 13:43:59] cvalgorithms INFO:  eta: 0:00:01  iter: 95  total_loss: 1.504  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7518  loss: 0.7518  time: 0.4537  data_time: 0.0787  lr: 0.001  max_mem: 3221M
[07/05 13:44:00] cvalgorithms INFO:  eta: 0:00:00  iter: 97  total_loss: 1.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9152  loss: 0.9152  time: 0.4541  data_time: 0.0799  lr: 0.00065451  max_mem: 3221M
[07/05 13:44:01] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9152  loss: 0.9152  time: 0.4543  data_time: 0.0805  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:44:01] cvalgorithms INFO:  eta: 0:00:00  iter: 99  total_loss: 1.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9152  loss: 0.9152  time: 0.4543  data_time: 0.0805  lr: 9.5492e-05  max_mem: 3221M
[07/05 13:48:03] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 13:48:03] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 13:48:04] cvalgorithms INFO: Starting training from iteration 0
[07/05 14:00:06] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 14:00:06] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 14:00:08] cvalgorithms INFO: Starting training from iteration 0
[07/05 14:04:21] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 14:04:21] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 14:04:23] cvalgorithms INFO: Starting training from iteration 0
[07/05 14:12:58] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 14:12:58] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 14:13:00] cvalgorithms INFO: Starting training from iteration 0
[07/05 14:13:26] cvalgorithms INFO:  iter: 1  total_loss: 200.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 100.2  loss: 100.2  data_time: 0.0677  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:27] cvalgorithms INFO:  eta: 22:14:18  iter: 3  total_loss: 158.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 79.23  loss: 79.23  time: 0.4003  data_time: 0.0597  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:28] cvalgorithms INFO:  eta: 22:29:54  iter: 5  total_loss: 161.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 80.82  loss: 80.82  time: 0.4059  data_time: 0.0609  lr: 0.001  max_mem: 3221M
[07/05 14:13:29] cvalgorithms INFO:  eta: 22:29:24  iter: 7  total_loss: 146.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 73.16  loss: 73.16  time: 0.4042  data_time: 0.0594  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:30] cvalgorithms INFO:  eta: 22:29:23  iter: 9  total_loss: 110  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 54.99  loss: 54.99  time: 0.4032  data_time: 0.0579  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:31] cvalgorithms INFO:  eta: 22:34:41  iter: 11  total_loss: 64.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.41  loss: 32.41  time: 0.4052  data_time: 0.0591  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:31] cvalgorithms INFO:  eta: 22:30:02  iter: 13  total_loss: 79.92  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 39.96  loss: 39.96  time: 0.4042  data_time: 0.0582  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:32] cvalgorithms INFO:  eta: 22:33:37  iter: 15  total_loss: 64.83  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 32.41  loss: 32.41  time: 0.4056  data_time: 0.0591  lr: 0.001  max_mem: 3221M
[07/05 14:13:33] cvalgorithms INFO:  eta: 22:33:37  iter: 17  total_loss: 52.7  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 26.35  loss: 26.35  time: 0.4064  data_time: 0.0589  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:34] cvalgorithms INFO:  eta: 22:34:38  iter: 19  total_loss: 47.75  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 23.87  loss: 23.87  time: 0.4098  data_time: 0.0606  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:35] cvalgorithms INFO:  eta: 22:37:13  iter: 21  total_loss: 37.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 18.55  loss: 18.55  time: 0.4121  data_time: 0.0609  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:36] cvalgorithms INFO:  eta: 22:43:48  iter: 23  total_loss: 24.74  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.37  loss: 12.37  time: 0.4129  data_time: 0.0616  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:36] cvalgorithms INFO:  eta: 22:54:13  iter: 25  total_loss: 21.2  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 10.6  loss: 10.6  time: 0.4132  data_time: 0.0614  lr: 0.001  max_mem: 3221M
[07/05 14:13:37] cvalgorithms INFO:  eta: 22:58:51  iter: 27  total_loss: 19.15  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 9.574  loss: 9.574  time: 0.4132  data_time: 0.0622  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:38] cvalgorithms INFO:  eta: 23:00:18  iter: 29  total_loss: 16.4  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 8.201  loss: 8.201  time: 0.4136  data_time: 0.0632  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:39] cvalgorithms INFO:  eta: 22:58:49  iter: 31  total_loss: 16.15  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 8.076  loss: 8.076  time: 0.4125  data_time: 0.0613  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:40] cvalgorithms INFO:  eta: 22:54:00  iter: 33  total_loss: 15.45  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.728  loss: 7.727  time: 0.4122  data_time: 0.0614  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:41] cvalgorithms INFO:  eta: 22:55:48  iter: 35  total_loss: 13.17  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.586  loss: 6.586  time: 0.4123  data_time: 0.0605  lr: 0.001  max_mem: 3221M
[07/05 14:13:41] cvalgorithms INFO:  eta: 22:58:47  iter: 37  total_loss: 12.02  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.012  loss: 6.012  time: 0.4126  data_time: 0.0610  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:42] cvalgorithms INFO:  eta: 23:00:13  iter: 39  total_loss: 11.79  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.897  loss: 5.897  time: 0.4140  data_time: 0.0616  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:43] cvalgorithms INFO:  eta: 23:03:12  iter: 41  total_loss: 8.557  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.278  loss: 4.278  time: 0.4145  data_time: 0.0601  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:44] cvalgorithms INFO:  eta: 23:06:30  iter: 43  total_loss: 8.097  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.048  loss: 4.048  time: 0.4152  data_time: 0.0610  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:45] cvalgorithms INFO:  eta: 23:07:12  iter: 45  total_loss: 7.98  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.99  loss: 3.99  time: 0.4165  data_time: 0.0631  lr: 0.001  max_mem: 3221M
[07/05 14:13:46] cvalgorithms INFO:  eta: 23:07:44  iter: 47  total_loss: 7.158  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.579  loss: 3.579  time: 0.4174  data_time: 0.0645  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:47] cvalgorithms INFO:  eta: 23:08:41  iter: 49  total_loss: 5.558  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.779  loss: 2.779  time: 0.4178  data_time: 0.0648  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:48] cvalgorithms INFO:  eta: 23:09:47  iter: 51  total_loss: 4.833  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.416  loss: 2.416  time: 0.4181  data_time: 0.0663  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:48] cvalgorithms INFO:  eta: 23:10:23  iter: 53  total_loss: 4.691  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.345  loss: 2.345  time: 0.4187  data_time: 0.0681  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:49] cvalgorithms INFO:  eta: 23:10:22  iter: 55  total_loss: 4.178  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.089  loss: 2.089  time: 0.4185  data_time: 0.0684  lr: 0.001  max_mem: 3221M
[07/05 14:13:50] cvalgorithms INFO:  eta: 23:09:44  iter: 57  total_loss: 2.736  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.368  loss: 1.368  time: 0.4182  data_time: 0.0679  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:51] cvalgorithms INFO:  eta: 23:08:37  iter: 59  total_loss: 2.552  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.276  loss: 1.276  time: 0.4181  data_time: 0.0656  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:52] cvalgorithms INFO:  eta: 23:09:42  iter: 61  total_loss: 2.426  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.213  loss: 1.213  time: 0.4187  data_time: 0.0683  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:53] cvalgorithms INFO:  eta: 23:10:19  iter: 63  total_loss: 2.254  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.127  loss: 1.127  time: 0.4189  data_time: 0.0677  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:53] cvalgorithms INFO:  eta: 23:09:41  iter: 65  total_loss: 1.953  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9767  loss: 0.9767  time: 0.4184  data_time: 0.0645  lr: 0.001  max_mem: 3221M
[07/05 14:13:54] cvalgorithms INFO:  eta: 23:10:17  iter: 67  total_loss: 2.254  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.127  loss: 1.127  time: 0.4185  data_time: 0.0633  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:55] cvalgorithms INFO:  eta: 23:10:17  iter: 69  total_loss: 2.297  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.148  loss: 1.148  time: 0.4185  data_time: 0.0624  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:13:56] cvalgorithms INFO:  eta: 23:11:08  iter: 71  total_loss: 1.802  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9009  loss: 0.9009  time: 0.4187  data_time: 0.0625  lr: 0.00090451  max_mem: 3221M
[07/05 14:13:57] cvalgorithms INFO:  eta: 23:10:15  iter: 73  total_loss: 1.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6052  loss: 0.6052  time: 0.4184  data_time: 0.0604  lr: 0.00034549  max_mem: 3221M
[07/05 14:13:58] cvalgorithms INFO:  eta: 23:10:14  iter: 75  total_loss: 1.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6052  loss: 0.6052  time: 0.4184  data_time: 0.0602  lr: 0.001  max_mem: 3221M
[07/05 14:13:58] cvalgorithms INFO:  eta: 23:11:05  iter: 77  total_loss: 1.568  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.784  loss: 0.784  time: 0.4186  data_time: 0.0611  lr: 0.00065451  max_mem: 3221M
[07/05 14:13:59] cvalgorithms INFO:  eta: 23:12:53  iter: 79  total_loss: 1.987  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9934  loss: 0.9934  time: 0.4188  data_time: 0.0616  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:00] cvalgorithms INFO:  eta: 23:12:53  iter: 81  total_loss: 2.136  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.068  loss: 1.068  time: 0.4187  data_time: 0.0590  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:01] cvalgorithms INFO:  eta: 23:14:00  iter: 83  total_loss: 1.757  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8786  loss: 0.8786  time: 0.4189  data_time: 0.0588  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:02] cvalgorithms INFO:  eta: 23:13:59  iter: 85  total_loss: 1.917  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9583  loss: 0.9583  time: 0.4190  data_time: 0.0596  lr: 0.001  max_mem: 3221M
[07/05 14:14:03] cvalgorithms INFO:  eta: 23:13:58  iter: 87  total_loss: 1.741  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8706  loss: 0.8706  time: 0.4190  data_time: 0.0585  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:04] cvalgorithms INFO:  eta: 23:13:57  iter: 89  total_loss: 1.552  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7761  loss: 0.7761  time: 0.4191  data_time: 0.0592  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:04] cvalgorithms INFO:  eta: 23:13:56  iter: 91  total_loss: 1.757  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8786  loss: 0.8786  time: 0.4193  data_time: 0.0593  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:05] cvalgorithms INFO:  eta: 23:14:03  iter: 93  total_loss: 2.136  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.068  loss: 1.068  time: 0.4200  data_time: 0.0633  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:06] cvalgorithms INFO:  eta: 23:15:20  iter: 95  total_loss: 2.136  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.068  loss: 1.068  time: 0.4202  data_time: 0.0637  lr: 0.001  max_mem: 3221M
[07/05 14:14:07] cvalgorithms INFO:  eta: 23:16:52  iter: 97  total_loss: 2.099  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.05  loss: 1.05  time: 0.4206  data_time: 0.0638  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:08] cvalgorithms INFO:  eta: 23:16:51  iter: 99  total_loss: 1.906  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.953  loss: 0.953  time: 0.4206  data_time: 0.0632  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:09] cvalgorithms INFO:  eta: 23:19:21  iter: 101  total_loss: 1.741  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8706  loss: 0.8706  time: 0.4211  data_time: 0.0651  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:10] cvalgorithms INFO:  eta: 23:19:20  iter: 103  total_loss: 1.923  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9613  loss: 0.9613  time: 0.4212  data_time: 0.0647  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:11] cvalgorithms INFO:  eta: 23:22:55  iter: 105  total_loss: 1.923  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9613  loss: 0.9613  time: 0.4216  data_time: 0.0649  lr: 0.001  max_mem: 3221M
[07/05 14:14:11] cvalgorithms INFO:  eta: 23:24:22  iter: 107  total_loss: 2.028  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.014  loss: 1.014  time: 0.4218  data_time: 0.0664  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:12] cvalgorithms INFO:  eta: 23:24:31  iter: 109  total_loss: 2.028  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.014  loss: 1.014  time: 0.4220  data_time: 0.0662  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:13] cvalgorithms INFO:  eta: 23:24:38  iter: 111  total_loss: 1.897  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9486  loss: 0.9486  time: 0.4221  data_time: 0.0651  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:14] cvalgorithms INFO:  eta: 23:24:50  iter: 113  total_loss: 1.897  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9486  loss: 0.9486  time: 0.4224  data_time: 0.0626  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:15] cvalgorithms INFO:  eta: 23:25:16  iter: 115  total_loss: 1.897  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9486  loss: 0.9486  time: 0.4226  data_time: 0.0621  lr: 0.001  max_mem: 3221M
[07/05 14:14:16] cvalgorithms INFO:  eta: 23:25:31  iter: 117  total_loss: 1.897  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9486  loss: 0.9486  time: 0.4232  data_time: 0.0632  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:17] cvalgorithms INFO:  eta: 23:25:37  iter: 119  total_loss: 2.07  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.035  loss: 1.035  time: 0.4233  data_time: 0.0631  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:18] cvalgorithms INFO:  eta: 23:25:51  iter: 121  total_loss: 2.07  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.035  loss: 1.035  time: 0.4235  data_time: 0.0621  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:19] cvalgorithms INFO:  eta: 23:26:40  iter: 123  total_loss: 2.41  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.205  loss: 1.205  time: 0.4241  data_time: 0.0642  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:19] cvalgorithms INFO:  eta: 23:27:49  iter: 125  total_loss: 2.41  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.205  loss: 1.205  time: 0.4246  data_time: 0.0646  lr: 0.001  max_mem: 3221M
[07/05 14:14:20] cvalgorithms INFO:  eta: 23:30:30  iter: 127  total_loss: 2.704  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.352  loss: 1.352  time: 0.4256  data_time: 0.0654  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:21] cvalgorithms INFO:  eta: 23:32:55  iter: 129  total_loss: 2.952  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.476  loss: 1.476  time: 0.4267  data_time: 0.0680  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:22] cvalgorithms INFO:  eta: 23:33:11  iter: 131  total_loss: 2.733  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.367  loss: 1.367  time: 0.4274  data_time: 0.0703  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:23] cvalgorithms INFO:  eta: 23:33:36  iter: 133  total_loss: 2.504  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.252  loss: 1.252  time: 0.4280  data_time: 0.0698  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:24] cvalgorithms INFO:  eta: 23:33:57  iter: 135  total_loss: 2.504  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.252  loss: 1.252  time: 0.4288  data_time: 0.0710  lr: 0.001  max_mem: 3221M
[07/05 14:14:25] cvalgorithms INFO:  eta: 23:35:04  iter: 137  total_loss: 2.619  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.31  loss: 1.31  time: 0.4298  data_time: 0.0717  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:26] cvalgorithms INFO:  eta: 23:36:31  iter: 139  total_loss: 2.296  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.148  loss: 1.148  time: 0.4304  data_time: 0.0729  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:27] cvalgorithms INFO:  eta: 23:37:15  iter: 141  total_loss: 2.296  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.148  loss: 1.148  time: 0.4308  data_time: 0.0736  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:28] cvalgorithms INFO:  eta: 23:37:53  iter: 143  total_loss: 2.07  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.035  loss: 1.035  time: 0.4314  data_time: 0.0740  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:29] cvalgorithms INFO:  eta: 23:38:23  iter: 145  total_loss: 2.07  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.035  loss: 1.035  time: 0.4321  data_time: 0.0753  lr: 0.001  max_mem: 3221M
[07/05 14:14:30] cvalgorithms INFO:  eta: 23:39:03  iter: 147  total_loss: 1.789  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8943  loss: 0.8943  time: 0.4325  data_time: 0.0748  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:31] cvalgorithms INFO:  eta: 23:39:33  iter: 149  total_loss: 1.665  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8324  loss: 0.8324  time: 0.4330  data_time: 0.0729  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:32] cvalgorithms INFO:  eta: 23:39:57  iter: 151  total_loss: 1.358  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6791  loss: 0.6791  time: 0.4335  data_time: 0.0728  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:33] cvalgorithms INFO:  eta: 23:40:22  iter: 153  total_loss: 1.358  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6791  loss: 0.6791  time: 0.4343  data_time: 0.0753  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:34] cvalgorithms INFO:  eta: 23:41:03  iter: 155  total_loss: 1.358  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6791  loss: 0.6791  time: 0.4352  data_time: 0.0778  lr: 0.001  max_mem: 3221M
[07/05 14:14:35] cvalgorithms INFO:  eta: 23:42:25  iter: 157  total_loss: 1.355  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6773  loss: 0.6773  time: 0.4357  data_time: 0.0779  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:36] cvalgorithms INFO:  eta: 23:44:19  iter: 159  total_loss: 1.034  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5172  loss: 0.5172  time: 0.4362  data_time: 0.0788  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:37] cvalgorithms INFO:  eta: 23:47:06  iter: 161  total_loss: 0.8461  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.423  loss: 0.423  time: 0.4371  data_time: 0.0801  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:38] cvalgorithms INFO:  eta: 23:48:50  iter: 163  total_loss: 0.9006  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4503  loss: 0.4503  time: 0.4379  data_time: 0.0820  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:39] cvalgorithms INFO:  eta: 23:49:50  iter: 165  total_loss: 0.8461  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.423  loss: 0.423  time: 0.4382  data_time: 0.0817  lr: 0.001  max_mem: 3221M
[07/05 14:14:40] cvalgorithms INFO:  eta: 23:51:04  iter: 167  total_loss: 0.8443  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4221  loss: 0.4221  time: 0.4384  data_time: 0.0815  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:41] cvalgorithms INFO:  eta: 23:51:42  iter: 169  total_loss: 0.9809  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4904  loss: 0.4904  time: 0.4390  data_time: 0.0813  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:42] cvalgorithms INFO:  eta: 23:52:56  iter: 171  total_loss: 1.376  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6878  loss: 0.6878  time: 0.4393  data_time: 0.0816  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:43] cvalgorithms INFO:  eta: 23:55:26  iter: 173  total_loss: 1.376  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6878  loss: 0.6878  time: 0.4396  data_time: 0.0803  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:44] cvalgorithms INFO:  eta: 23:58:23  iter: 175  total_loss: 0.8669  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4334  loss: 0.4334  time: 0.4403  data_time: 0.0786  lr: 0.001  max_mem: 3221M
[07/05 14:14:45] cvalgorithms INFO:  eta: 1 day, 0:01:40  iter: 177  total_loss: 0.9472  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4736  loss: 0.4736  time: 0.4414  data_time: 0.0802  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:46] cvalgorithms INFO:  eta: 1 day, 0:04:50  iter: 179  total_loss: 1.145  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5724  loss: 0.5724  time: 0.4419  data_time: 0.0812  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:47] cvalgorithms INFO:  eta: 1 day, 0:06:21  iter: 181  total_loss: 1.512  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7562  loss: 0.7562  time: 0.4420  data_time: 0.0789  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:47] cvalgorithms INFO:  eta: 1 day, 0:06:58  iter: 183  total_loss: 1.17  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.585  loss: 0.585  time: 0.4424  data_time: 0.0763  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:48] cvalgorithms INFO:  eta: 1 day, 0:08:53  iter: 185  total_loss: 1.401  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7003  loss: 0.7003  time: 0.4429  data_time: 0.0763  lr: 0.001  max_mem: 3221M
[07/05 14:14:49] cvalgorithms INFO:  eta: 1 day, 0:10:43  iter: 187  total_loss: 1.17  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.585  loss: 0.585  time: 0.4430  data_time: 0.0761  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:50] cvalgorithms INFO:  eta: 1 day, 0:11:08  iter: 189  total_loss: 1.04  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5198  loss: 0.5198  time: 0.4432  data_time: 0.0770  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:51] cvalgorithms INFO:  eta: 1 day, 0:11:29  iter: 191  total_loss: 1.17  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.585  loss: 0.585  time: 0.4434  data_time: 0.0765  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:52] cvalgorithms INFO:  eta: 1 day, 0:12:35  iter: 193  total_loss: 1.17  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.585  loss: 0.585  time: 0.4437  data_time: 0.0777  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:53] cvalgorithms INFO:  eta: 1 day, 0:14:19  iter: 195  total_loss: 1.739  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8695  loss: 0.8695  time: 0.4440  data_time: 0.0765  lr: 0.001  max_mem: 3221M
[07/05 14:14:54] cvalgorithms INFO:  eta: 1 day, 0:15:19  iter: 197  total_loss: 1.623  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8117  loss: 0.8117  time: 0.4442  data_time: 0.0731  lr: 0.00065451  max_mem: 3221M
[07/05 14:14:55] cvalgorithms INFO:  eta: 1 day, 0:17:44  iter: 199  total_loss: 1.623  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8117  loss: 0.8117  time: 0.4446  data_time: 0.0718  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:14:56] cvalgorithms INFO:  eta: 1 day, 0:20:07  iter: 201  total_loss: 1.79  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8951  loss: 0.8951  time: 0.4449  data_time: 0.0738  lr: 0.00090451  max_mem: 3221M
[07/05 14:14:57] cvalgorithms INFO:  eta: 1 day, 0:22:41  iter: 203  total_loss: 1.79  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8951  loss: 0.8951  time: 0.4450  data_time: 0.0734  lr: 0.00034549  max_mem: 3221M
[07/05 14:14:58] cvalgorithms INFO:  eta: 1 day, 0:25:16  iter: 205  total_loss: 1.791  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8953  loss: 0.8953  time: 0.4456  data_time: 0.0748  lr: 0.001  max_mem: 3221M
[07/05 14:14:59] cvalgorithms INFO:  eta: 1 day, 0:26:01  iter: 207  total_loss: 1.791  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8953  loss: 0.8953  time: 0.4458  data_time: 0.0759  lr: 0.00065451  max_mem: 3221M
[07/05 14:15:00] cvalgorithms INFO:  eta: 1 day, 0:26:38  iter: 209  total_loss: 1.791  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8953  loss: 0.8953  time: 0.4460  data_time: 0.0755  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:15:01] cvalgorithms INFO:  eta: 1 day, 0:27:39  iter: 211  total_loss: 1.727  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8637  loss: 0.8637  time: 0.4465  data_time: 0.0771  lr: 0.00090451  max_mem: 3221M
[07/05 14:15:02] cvalgorithms INFO:  eta: 1 day, 0:28:35  iter: 213  total_loss: 1.727  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8637  loss: 0.8637  time: 0.4467  data_time: 0.0760  lr: 0.00034549  max_mem: 3221M
[07/05 14:15:03] cvalgorithms INFO:  eta: 1 day, 0:30:02  iter: 215  total_loss: 1.727  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8637  loss: 0.8637  time: 0.4467  data_time: 0.0762  lr: 0.001  max_mem: 3221M
[07/05 14:15:04] cvalgorithms INFO:  eta: 1 day, 0:31:38  iter: 217  total_loss: 1.697  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8484  loss: 0.8484  time: 0.4468  data_time: 0.0759  lr: 0.00065451  max_mem: 3221M
[07/05 14:15:05] cvalgorithms INFO:  eta: 1 day, 0:33:38  iter: 219  total_loss: 1.565  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7826  loss: 0.7826  time: 0.4469  data_time: 0.0761  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:15:05] cvalgorithms INFO:  eta: 1 day, 0:36:10  iter: 221  total_loss: 1.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.605  loss: 0.605  time: 0.4471  data_time: 0.0759  lr: 0.00090451  max_mem: 3221M
[07/05 14:15:06] cvalgorithms INFO:  eta: 1 day, 0:36:10  iter: 223  total_loss: 1.351  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6757  loss: 0.6757  time: 0.4473  data_time: 0.0772  lr: 0.00034549  max_mem: 3221M
[07/05 14:15:07] cvalgorithms INFO:  eta: 1 day, 0:38:34  iter: 225  total_loss: 1.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.605  loss: 0.605  time: 0.4474  data_time: 0.0745  lr: 0.001  max_mem: 3221M
[07/05 14:15:08] cvalgorithms INFO:  eta: 1 day, 0:40:36  iter: 227  total_loss: 1.118  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.559  loss: 0.559  time: 0.4476  data_time: 0.0738  lr: 0.00065451  max_mem: 3221M
[07/05 14:15:09] cvalgorithms INFO:  eta: 1 day, 0:41:20  iter: 229  total_loss: 1.118  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.559  loss: 0.559  time: 0.4478  data_time: 0.0753  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:15:10] cvalgorithms INFO:  eta: 1 day, 0:43:22  iter: 231  total_loss: 0.9972  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4986  loss: 0.4986  time: 0.4479  data_time: 0.0729  lr: 0.00090451  max_mem: 3221M
[07/05 14:15:11] cvalgorithms INFO:  eta: 1 day, 0:45:27  iter: 233  total_loss: 1.045  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5223  loss: 0.5223  time: 0.4480  data_time: 0.0727  lr: 0.00034549  max_mem: 3221M
[07/05 14:15:12] cvalgorithms INFO:  eta: 1 day, 0:46:23  iter: 235  total_loss: 0.9972  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4986  loss: 0.4986  time: 0.4480  data_time: 0.0725  lr: 0.001  max_mem: 3221M
[07/05 14:15:13] cvalgorithms INFO:  eta: 1 day, 0:47:11  iter: 237  total_loss: 0.9705  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4852  loss: 0.4852  time: 0.4482  data_time: 0.0736  lr: 0.00065451  max_mem: 3221M
[07/05 14:15:14] cvalgorithms INFO:  eta: 1 day, 0:48:25  iter: 239  total_loss: 1.116  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5582  loss: 0.5582  time: 0.4484  data_time: 0.0736  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:15:15] cvalgorithms INFO:  eta: 1 day, 0:48:24  iter: 241  total_loss: 1.116  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5582  loss: 0.5582  time: 0.4484  data_time: 0.0723  lr: 0.00090451  max_mem: 3221M
[07/05 14:15:16] cvalgorithms INFO:  eta: 1 day, 0:49:28  iter: 243  total_loss: 1.116  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5582  loss: 0.5582  time: 0.4485  data_time: 0.0718  lr: 0.00034549  max_mem: 3221M
[07/05 14:15:17] cvalgorithms INFO:  eta: 1 day, 0:49:27  iter: 245  total_loss: 1.08  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5398  loss: 0.5398  time: 0.4485  data_time: 0.0717  lr: 0.001  max_mem: 3221M
[07/05 14:15:18] cvalgorithms INFO:  eta: 1 day, 0:50:02  iter: 247  total_loss: 1.417  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7083  loss: 0.7083  time: 0.4489  data_time: 0.0724  lr: 0.00065451  max_mem: 3221M
[07/05 14:15:19] cvalgorithms INFO:  eta: 1 day, 0:50:44  iter: 249  total_loss: 1.417  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7083  loss: 0.7083  time: 0.4493  data_time: 0.0735  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:15:20] cvalgorithms INFO:  eta: 1 day, 0:51:21  iter: 251  total_loss: 1.711  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8556  loss: 0.8556  time: 0.4496  data_time: 0.0752  lr: 0.00090451  max_mem: 3221M
[07/05 14:15:21] cvalgorithms INFO:  eta: 1 day, 0:52:01  iter: 253  total_loss: 1.473  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7364  loss: 0.7364  time: 0.4498  data_time: 0.0762  lr: 0.00034549  max_mem: 3221M
[07/05 14:15:21] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 123, in train
    self.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\trainer.py", line 133, in run_step
    self._trainer.run_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 204, in run_step
    data = next(self._data_loader_iter)
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\utils\data\dataloader.py", line 517, in __next__
    data = self._next_data()
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\utils\data\dataloader.py", line 556, in _next_data
    index = self._next_index()  # may raise StopIteration
  File "C:\ProgramData\Anaconda3\envs\deepcv\lib\site-packages\torch\utils\data\dataloader.py", line 508, in _next_index
    return next(self._sampler_iter)  # may raise StopIteration
StopIteration
[07/05 14:15:21] cvalgorithms INFO:  eta: 1 day, 0:52:00  iter: 254  total_loss: 1.473  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7364  loss: 0.7364  time: 0.4498  data_time: 0.0762  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:06] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 14:56:07] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 14:56:08] cvalgorithms INFO: Starting training from iteration 0
[07/05 14:56:11] cvalgorithms INFO:  iter: 1  total_loss: 34.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.1  loss: 17.1  data_time: 0.0554  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:12] cvalgorithms INFO:  eta: 22:53:32  iter: 3  total_loss: 35.38  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.69  loss: 17.69  time: 0.4121  data_time: 0.0606  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:13] cvalgorithms INFO:  eta: 22:24:58  iter: 5  total_loss: 35.44  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.72  loss: 17.72  time: 0.4060  data_time: 0.0581  lr: 0.001  max_mem: 3221M
[07/05 14:56:13] cvalgorithms INFO:  eta: 22:24:57  iter: 7  total_loss: 35.44  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.72  loss: 17.72  time: 0.4045  data_time: 0.0575  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:14] cvalgorithms INFO:  eta: 22:15:45  iter: 9  total_loss: 35.44  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.72  loss: 17.72  time: 0.4028  data_time: 0.0560  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:15] cvalgorithms INFO:  eta: 22:15:44  iter: 11  total_loss: 34.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.4  loss: 17.4  time: 0.4028  data_time: 0.0559  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:16] cvalgorithms INFO:  eta: 22:15:43  iter: 13  total_loss: 35.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.55  loss: 17.55  time: 0.4028  data_time: 0.0556  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:17] cvalgorithms INFO:  eta: 22:15:42  iter: 15  total_loss: 35.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.55  loss: 17.55  time: 0.4028  data_time: 0.0556  lr: 0.001  max_mem: 3221M
[07/05 14:56:18] cvalgorithms INFO:  eta: 22:11:37  iter: 17  total_loss: 35.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.55  loss: 17.55  time: 0.4022  data_time: 0.0547  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:18] cvalgorithms INFO:  eta: 22:10:19  iter: 19  total_loss: 34.81  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 17.4  loss: 17.4  time: 0.4015  data_time: 0.0541  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:19] cvalgorithms INFO:  eta: 22:10:18  iter: 21  total_loss: 33.63  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.81  loss: 16.81  time: 0.4018  data_time: 0.0539  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:20] cvalgorithms INFO:  eta: 22:11:34  iter: 23  total_loss: 28.61  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 14.31  loss: 14.31  time: 0.4032  data_time: 0.0543  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:21] cvalgorithms INFO:  eta: 22:10:16  iter: 25  total_loss: 24.1  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.05  loss: 12.05  time: 0.4028  data_time: 0.0540  lr: 0.001  max_mem: 3221M
[07/05 14:56:22] cvalgorithms INFO:  eta: 22:11:33  iter: 27  total_loss: 19.57  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 9.786  loss: 9.786  time: 0.4032  data_time: 0.0544  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:22] cvalgorithms INFO:  eta: 22:10:15  iter: 29  total_loss: 13.59  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.797  loss: 6.797  time: 0.4028  data_time: 0.0544  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:23] cvalgorithms INFO:  eta: 22:11:31  iter: 31  total_loss: 11.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.919  loss: 5.919  time: 0.4032  data_time: 0.0545  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:24] cvalgorithms INFO:  eta: 22:13:33  iter: 33  total_loss: 9.939  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.97  loss: 4.97  time: 0.4032  data_time: 0.0538  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:25] cvalgorithms INFO:  eta: 22:16:46  iter: 35  total_loss: 7.695  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.848  loss: 3.848  time: 0.4034  data_time: 0.0537  lr: 0.001  max_mem: 3221M
[07/05 14:56:26] cvalgorithms INFO:  eta: 22:16:45  iter: 37  total_loss: 6.557  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 3.279  loss: 3.279  time: 0.4033  data_time: 0.0541  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:26] cvalgorithms INFO:  eta: 22:18:46  iter: 39  total_loss: 5.221  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.61  loss: 2.61  time: 0.4036  data_time: 0.0549  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:27] cvalgorithms INFO:  eta: 22:19:53  iter: 41  total_loss: 4.31  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.155  loss: 2.155  time: 0.4039  data_time: 0.0554  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:28] cvalgorithms INFO:  eta: 22:21:58  iter: 43  total_loss: 2.69  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.345  loss: 1.345  time: 0.4042  data_time: 0.0542  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:29] cvalgorithms INFO:  eta: 22:23:00  iter: 45  total_loss: 2.672  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.336  loss: 1.336  time: 0.4044  data_time: 0.0549  lr: 0.001  max_mem: 3221M
[07/05 14:56:30] cvalgorithms INFO:  eta: 22:22:59  iter: 47  total_loss: 2.451  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.226  loss: 1.226  time: 0.4044  data_time: 0.0541  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:31] cvalgorithms INFO:  eta: 22:24:34  iter: 49  total_loss: 2.277  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.139  loss: 1.139  time: 0.4050  data_time: 0.0558  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:31] cvalgorithms INFO:  eta: 22:24:34  iter: 51  total_loss: 2.277  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.139  loss: 1.139  time: 0.4054  data_time: 0.0559  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:32] cvalgorithms INFO:  eta: 22:26:09  iter: 53  total_loss: 2.277  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.139  loss: 1.139  time: 0.4056  data_time: 0.0566  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:33] cvalgorithms INFO:  eta: 22:26:45  iter: 55  total_loss: 2.137  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.069  loss: 1.069  time: 0.4056  data_time: 0.0565  lr: 0.001  max_mem: 3221M
[07/05 14:56:34] cvalgorithms INFO:  eta: 22:28:33  iter: 57  total_loss: 1.885  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9427  loss: 0.9427  time: 0.4060  data_time: 0.0571  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:35] cvalgorithms INFO:  eta: 22:28:32  iter: 59  total_loss: 1.64  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8199  loss: 0.8199  time: 0.4059  data_time: 0.0567  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:36] cvalgorithms INFO:  eta: 22:29:51  iter: 61  total_loss: 2.128  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.064  loss: 1.064  time: 0.4067  data_time: 0.0583  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:36] cvalgorithms INFO:  eta: 22:30:13  iter: 63  total_loss: 2.128  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.064  loss: 1.064  time: 0.4069  data_time: 0.0585  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:37] cvalgorithms INFO:  eta: 22:31:01  iter: 65  total_loss: 1.64  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8199  loss: 0.8199  time: 0.4074  data_time: 0.0598  lr: 0.001  max_mem: 3221M
[07/05 14:56:38] cvalgorithms INFO:  eta: 22:31:45  iter: 67  total_loss: 1.64  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8199  loss: 0.8199  time: 0.4083  data_time: 0.0607  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:39] cvalgorithms INFO:  eta: 22:33:10  iter: 69  total_loss: 1.794  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.897  loss: 0.897  time: 0.4086  data_time: 0.0600  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:40] cvalgorithms INFO:  eta: 22:34:31  iter: 71  total_loss: 1.508  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7539  loss: 0.7539  time: 0.4097  data_time: 0.0600  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:41] cvalgorithms INFO:  eta: 22:36:18  iter: 73  total_loss: 1.508  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7539  loss: 0.7539  time: 0.4110  data_time: 0.0624  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:42] cvalgorithms INFO:  eta: 22:37:58  iter: 75  total_loss: 1.794  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.897  loss: 0.897  time: 0.4118  data_time: 0.0637  lr: 0.001  max_mem: 3221M
[07/05 14:56:43] cvalgorithms INFO:  eta: 22:38:09  iter: 77  total_loss: 1.794  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.897  loss: 0.897  time: 0.4122  data_time: 0.0641  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:43] cvalgorithms INFO:  eta: 22:38:44  iter: 79  total_loss: 1.662  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.831  loss: 0.831  time: 0.4129  data_time: 0.0651  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:44] cvalgorithms INFO:  eta: 22:39:23  iter: 81  total_loss: 1.662  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.831  loss: 0.831  time: 0.4133  data_time: 0.0640  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:45] cvalgorithms INFO:  eta: 22:40:46  iter: 83  total_loss: 1.662  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.831  loss: 0.831  time: 0.4136  data_time: 0.0640  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:46] cvalgorithms INFO:  eta: 22:43:46  iter: 85  total_loss: 1.662  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.831  loss: 0.831  time: 0.4146  data_time: 0.0641  lr: 0.001  max_mem: 3221M
[07/05 14:56:47] cvalgorithms INFO:  eta: 22:46:06  iter: 87  total_loss: 1.662  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.831  loss: 0.831  time: 0.4151  data_time: 0.0636  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:48] cvalgorithms INFO:  eta: 22:47:42  iter: 89  total_loss: 1.822  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9111  loss: 0.9111  time: 0.4154  data_time: 0.0638  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:49] cvalgorithms INFO:  eta: 22:50:45  iter: 91  total_loss: 1.961  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9803  loss: 0.9803  time: 0.4161  data_time: 0.0649  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:50] cvalgorithms INFO:  eta: 22:54:05  iter: 93  total_loss: 1.822  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9111  loss: 0.9111  time: 0.4167  data_time: 0.0634  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:50] cvalgorithms INFO:  eta: 22:57:05  iter: 95  total_loss: 1.649  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8244  loss: 0.8244  time: 0.4172  data_time: 0.0630  lr: 0.001  max_mem: 3221M
[07/05 14:56:51] cvalgorithms INFO:  eta: 22:58:55  iter: 97  total_loss: 1.649  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8244  loss: 0.8244  time: 0.4179  data_time: 0.0633  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:52] cvalgorithms INFO:  eta: 22:59:32  iter: 99  total_loss: 1.822  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9111  loss: 0.9111  time: 0.4187  data_time: 0.0639  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:53] cvalgorithms INFO:  eta: 23:00:03  iter: 101  total_loss: 1.649  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8244  loss: 0.8244  time: 0.4194  data_time: 0.0635  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:54] cvalgorithms INFO:  eta: 23:01:48  iter: 103  total_loss: 1.822  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9111  loss: 0.9111  time: 0.4200  data_time: 0.0646  lr: 0.00034549  max_mem: 3221M
[07/05 14:56:55] cvalgorithms INFO:  eta: 23:05:00  iter: 105  total_loss: 1.717  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8583  loss: 0.8583  time: 0.4205  data_time: 0.0634  lr: 0.001  max_mem: 3221M
[07/05 14:56:56] cvalgorithms INFO:  eta: 23:06:34  iter: 107  total_loss: 1.649  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8244  loss: 0.8244  time: 0.4211  data_time: 0.0645  lr: 0.00065451  max_mem: 3221M
[07/05 14:56:57] cvalgorithms INFO:  eta: 23:08:57  iter: 109  total_loss: 1.532  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7659  loss: 0.7659  time: 0.4215  data_time: 0.0648  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:56:58] cvalgorithms INFO:  eta: 23:11:45  iter: 111  total_loss: 1.6  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7998  loss: 0.7998  time: 0.4222  data_time: 0.0648  lr: 0.00090451  max_mem: 3221M
[07/05 14:56:59] cvalgorithms INFO:  eta: 23:13:57  iter: 113  total_loss: 1.803  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9013  loss: 0.9013  time: 0.4229  data_time: 0.0654  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:00] cvalgorithms INFO:  eta: 23:15:50  iter: 115  total_loss: 1.931  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9653  loss: 0.9653  time: 0.4235  data_time: 0.0658  lr: 0.001  max_mem: 3221M
[07/05 14:57:01] cvalgorithms INFO:  eta: 23:15:59  iter: 117  total_loss: 1.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9851  loss: 0.9851  time: 0.4238  data_time: 0.0653  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:01] cvalgorithms INFO:  eta: 23:19:41  iter: 119  total_loss: 1.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9851  loss: 0.9851  time: 0.4243  data_time: 0.0648  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:02] cvalgorithms INFO:  eta: 23:23:26  iter: 121  total_loss: 1.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9851  loss: 0.9851  time: 0.4247  data_time: 0.0655  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:03] cvalgorithms INFO:  eta: 23:23:39  iter: 123  total_loss: 1.803  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9013  loss: 0.9013  time: 0.4252  data_time: 0.0650  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:04] cvalgorithms INFO:  eta: 23:23:58  iter: 125  total_loss: 1.912  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9559  loss: 0.9559  time: 0.4258  data_time: 0.0667  lr: 0.001  max_mem: 3221M
[07/05 14:57:05] cvalgorithms INFO:  eta: 23:24:17  iter: 127  total_loss: 1.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9851  loss: 0.9851  time: 0.4263  data_time: 0.0669  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:06] cvalgorithms INFO:  eta: 23:24:33  iter: 129  total_loss: 2.184  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.092  loss: 1.092  time: 0.4267  data_time: 0.0674  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:07] cvalgorithms INFO:  eta: 23:25:53  iter: 131  total_loss: 1.97  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9851  loss: 0.9851  time: 0.4272  data_time: 0.0681  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:08] cvalgorithms INFO:  eta: 23:31:23  iter: 133  total_loss: 2.071  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.035  loss: 1.035  time: 0.4277  data_time: 0.0680  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:09] cvalgorithms INFO:  eta: 23:36:49  iter: 135  total_loss: 1.422  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7109  loss: 0.7109  time: 0.4282  data_time: 0.0684  lr: 0.001  max_mem: 3221M
[07/05 14:57:10] cvalgorithms INFO:  eta: 23:39:44  iter: 137  total_loss: 0.8319  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.416  loss: 0.416  time: 0.4286  data_time: 0.0693  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:11] cvalgorithms INFO:  eta: 23:47:20  iter: 139  total_loss: 0.7416  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.3708  loss: 0.3708  time: 0.4288  data_time: 0.0694  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:11] cvalgorithms INFO:  eta: 23:53:26  iter: 141  total_loss: 0.7416  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.3708  loss: 0.3708  time: 0.4292  data_time: 0.0689  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:12] cvalgorithms INFO:  eta: 23:57:25  iter: 143  total_loss: 0.9877  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4938  loss: 0.4938  time: 0.4297  data_time: 0.0701  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:13] cvalgorithms INFO:  eta: 1 day, 0:02:11  iter: 145  total_loss: 0.9877  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4938  loss: 0.4938  time: 0.4300  data_time: 0.0688  lr: 0.001  max_mem: 3221M
[07/05 14:57:14] cvalgorithms INFO:  eta: 1 day, 0:03:44  iter: 147  total_loss: 0.7543  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.3772  loss: 0.3772  time: 0.4304  data_time: 0.0684  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:15] cvalgorithms INFO:  eta: 1 day, 0:04:37  iter: 149  total_loss: 0.6161  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.308  loss: 0.308  time: 0.4308  data_time: 0.0682  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:16] cvalgorithms INFO:  eta: 1 day, 0:05:44  iter: 151  total_loss: 0.772  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.386  loss: 0.386  time: 0.4311  data_time: 0.0674  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:17] cvalgorithms INFO:  eta: 1 day, 0:07:14  iter: 153  total_loss: 0.9041  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4521  loss: 0.4521  time: 0.4317  data_time: 0.0688  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:18] cvalgorithms INFO:  eta: 1 day, 0:08:33  iter: 155  total_loss: 0.9041  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4521  loss: 0.4521  time: 0.4321  data_time: 0.0689  lr: 0.001  max_mem: 3221M
[07/05 14:57:19] cvalgorithms INFO:  eta: 1 day, 0:09:26  iter: 157  total_loss: 0.976  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.488  loss: 0.488  time: 0.4325  data_time: 0.0700  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:20] cvalgorithms INFO:  eta: 1 day, 0:10:11  iter: 159  total_loss: 0.9812  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4906  loss: 0.4906  time: 0.4328  data_time: 0.0705  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:21] cvalgorithms INFO:  eta: 1 day, 0:11:24  iter: 161  total_loss: 0.9283  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4641  loss: 0.4641  time: 0.4331  data_time: 0.0705  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:22] cvalgorithms INFO:  eta: 1 day, 0:15:27  iter: 163  total_loss: 0.9088  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4544  loss: 0.4544  time: 0.4333  data_time: 0.0699  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:23] cvalgorithms INFO:  eta: 1 day, 0:19:21  iter: 165  total_loss: 0.9088  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4544  loss: 0.4544  time: 0.4337  data_time: 0.0713  lr: 0.001  max_mem: 3221M
[07/05 14:57:24] cvalgorithms INFO:  eta: 1 day, 0:20:51  iter: 167  total_loss: 0.9812  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4906  loss: 0.4906  time: 0.4340  data_time: 0.0719  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:24] cvalgorithms INFO:  eta: 1 day, 0:22:34  iter: 169  total_loss: 1.262  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6311  loss: 0.6311  time: 0.4343  data_time: 0.0719  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:25] cvalgorithms INFO:  eta: 1 day, 0:23:35  iter: 171  total_loss: 1.262  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6311  loss: 0.6311  time: 0.4345  data_time: 0.0717  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:26] cvalgorithms INFO:  eta: 1 day, 0:25:04  iter: 173  total_loss: 1.013  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5063  loss: 0.5063  time: 0.4347  data_time: 0.0698  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:27] cvalgorithms INFO:  eta: 1 day, 0:27:51  iter: 175  total_loss: 0.914  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.457  loss: 0.457  time: 0.4349  data_time: 0.0693  lr: 0.001  max_mem: 3221M
[07/05 14:57:28] cvalgorithms INFO:  eta: 1 day, 0:30:18  iter: 177  total_loss: 0.8884  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.4442  loss: 0.4442  time: 0.4351  data_time: 0.0678  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:29] cvalgorithms INFO:  eta: 1 day, 0:31:17  iter: 179  total_loss: 0.7602  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.3801  loss: 0.3801  time: 0.4354  data_time: 0.0682  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:30] cvalgorithms INFO:  eta: 1 day, 0:32:10  iter: 181  total_loss: 0.5918  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.2959  loss: 0.2959  time: 0.4357  data_time: 0.0683  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:31] cvalgorithms INFO:  eta: 1 day, 0:33:40  iter: 183  total_loss: 0.5797  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.2898  loss: 0.2898  time: 0.4360  data_time: 0.0684  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:32] cvalgorithms INFO:  eta: 1 day, 0:34:56  iter: 185  total_loss: 0.5595  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.2797  loss: 0.2797  time: 0.4364  data_time: 0.0676  lr: 0.001  max_mem: 3221M
[07/05 14:57:33] cvalgorithms INFO:  eta: 1 day, 0:37:24  iter: 187  total_loss: 0.5595  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.2797  loss: 0.2797  time: 0.4367  data_time: 0.0674  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:34] cvalgorithms INFO:  eta: 1 day, 0:40:10  iter: 189  total_loss: 0.5506  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.2753  loss: 0.2753  time: 0.4368  data_time: 0.0672  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:35] cvalgorithms INFO:  eta: 1 day, 0:41:35  iter: 191  total_loss: 0.5506  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.2753  loss: 0.2753  time: 0.4371  data_time: 0.0676  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:36] cvalgorithms INFO:  eta: 1 day, 0:43:21  iter: 193  total_loss: 0.5761  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.288  loss: 0.288  time: 0.4376  data_time: 0.0703  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:37] cvalgorithms INFO:  eta: 1 day, 0:44:38  iter: 195  total_loss: 0.7816  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.3908  loss: 0.3908  time: 0.4378  data_time: 0.0709  lr: 0.001  max_mem: 3221M
[07/05 14:57:37] cvalgorithms INFO:  eta: 1 day, 0:46:16  iter: 197  total_loss: 1.492  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7461  loss: 0.7461  time: 0.4380  data_time: 0.0715  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:38] cvalgorithms INFO:  eta: 1 day, 0:48:27  iter: 199  total_loss: 1.848  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.924  loss: 0.924  time: 0.4382  data_time: 0.0713  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:39] cvalgorithms INFO:  eta: 1 day, 0:49:10  iter: 201  total_loss: 1.995  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9974  loss: 0.9974  time: 0.4383  data_time: 0.0708  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:40] cvalgorithms INFO:  eta: 1 day, 0:49:46  iter: 203  total_loss: 1.848  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.924  loss: 0.924  time: 0.4385  data_time: 0.0695  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:41] cvalgorithms INFO:  eta: 1 day, 0:49:45  iter: 205  total_loss: 1.995  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9974  loss: 0.9974  time: 0.4386  data_time: 0.0690  lr: 0.001  max_mem: 3221M
[07/05 14:57:42] cvalgorithms INFO:  eta: 1 day, 0:50:27  iter: 207  total_loss: 1.848  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.924  loss: 0.924  time: 0.4388  data_time: 0.0690  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:43] cvalgorithms INFO:  eta: 1 day, 0:50:54  iter: 209  total_loss: 1.995  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9974  loss: 0.9974  time: 0.4390  data_time: 0.0692  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:44] cvalgorithms INFO:  eta: 1 day, 0:51:14  iter: 211  total_loss: 2.009  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.005  loss: 1.005  time: 0.4394  data_time: 0.0698  lr: 0.00090451  max_mem: 3221M
[07/05 14:57:45] cvalgorithms INFO:  eta: 1 day, 0:51:33  iter: 213  total_loss: 1.847  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9235  loss: 0.9235  time: 0.4397  data_time: 0.0678  lr: 0.00034549  max_mem: 3221M
[07/05 14:57:46] cvalgorithms INFO:  eta: 1 day, 0:51:32  iter: 215  total_loss: 1.688  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.844  loss: 0.844  time: 0.4399  data_time: 0.0679  lr: 0.001  max_mem: 3221M
[07/05 14:57:47] cvalgorithms INFO:  eta: 1 day, 0:51:53  iter: 217  total_loss: 1.358  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6791  loss: 0.6791  time: 0.4402  data_time: 0.0685  lr: 0.00065451  max_mem: 3221M
[07/05 14:57:48] cvalgorithms INFO:  eta: 1 day, 0:51:58  iter: 219  total_loss: 1.358  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6791  loss: 0.6791  time: 0.4404  data_time: 0.0681  lr: 9.5492e-05  max_mem: 3221M
[07/05 14:57:49] cvalgorithms INFO:  eta: 1 day, 0:52:04  iter: 221  total_loss: 1.314  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.6569  loss: 0.6569  time: 0.4407  data_time: 0.0698  lr: 0.00090451  max_mem: 3221M
[07/05 15:55:36] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 15:55:36] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 15:56:05] cvalgorithms INFO: Starting training from iteration 0
[07/05 15:56:09] cvalgorithms INFO:  iter: 1  total_loss: 180.8  decode.loss_seg: 0.0004736  aux_0.loss: -8.928e-07  cnt.cnt_loss: 90.38  loss: 90.38  data_time: 0.0535  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:09] cvalgorithms INFO:  eta: 19:34:01  iter: 3  total_loss: 124.8  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 62.4  loss: 62.4  time: 0.3522  data_time: 0.0293  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:10] cvalgorithms INFO:  eta: 19:34:00  iter: 5  total_loss: 87.05  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.53  loss: 43.53  time: 0.3521  data_time: 0.0212  lr: 0.001  max_mem: 3221M
[07/05 15:56:11] cvalgorithms INFO:  eta: 19:34:00  iter: 7  total_loss: 87.05  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.53  loss: 43.53  time: 0.3520  data_time: 0.0170  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:12] cvalgorithms INFO:  eta: 19:32:51  iter: 9  total_loss: 87.05  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 43.53  loss: 43.53  time: 0.3516  data_time: 0.0145  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:12] cvalgorithms INFO:  eta: 19:33:30  iter: 11  total_loss: 75.08  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 37.54  loss: 37.54  time: 0.3518  data_time: 0.0128  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:13] cvalgorithms INFO:  eta: 19:33:30  iter: 13  total_loss: 62.39  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 31.19  loss: 31.19  time: 0.3517  data_time: 0.0115  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:14] cvalgorithms INFO:  eta: 19:33:32  iter: 15  total_loss: 49.21  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 24.6  loss: 24.6  time: 0.3518  data_time: 0.0106  lr: 0.001  max_mem: 3221M
[07/05 15:56:14] cvalgorithms INFO:  eta: 19:33:56  iter: 17  total_loss: 45.06  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 22.53  loss: 22.53  time: 0.3524  data_time: 0.0099  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:15] cvalgorithms INFO:  eta: 19:34:11  iter: 19  total_loss: 41.33  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 20.67  loss: 20.67  time: 0.3526  data_time: 0.0094  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:16] cvalgorithms INFO:  eta: 19:34:16  iter: 21  total_loss: 32.46  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 16.23  loss: 16.23  time: 0.3527  data_time: 0.0045  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:17] cvalgorithms INFO:  eta: 19:34:15  iter: 23  total_loss: 25.34  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 12.67  loss: 12.67  time: 0.3527  data_time: 0.0044  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:17] cvalgorithms INFO:  eta: 19:34:15  iter: 25  total_loss: 22.69  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 11.34  loss: 11.34  time: 0.3527  data_time: 0.0044  lr: 0.001  max_mem: 3221M
[07/05 15:56:18] cvalgorithms INFO:  eta: 19:34:48  iter: 27  total_loss: 19.19  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 9.597  loss: 9.597  time: 0.3529  data_time: 0.0044  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:19] cvalgorithms INFO:  eta: 19:35:36  iter: 29  total_loss: 15.3  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 7.649  loss: 7.649  time: 0.3532  data_time: 0.0044  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:19] cvalgorithms INFO:  eta: 19:35:53  iter: 31  total_loss: 13.63  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 6.813  loss: 6.813  time: 0.3540  data_time: 0.0044  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:20] cvalgorithms INFO:  eta: 19:36:05  iter: 33  total_loss: 10.14  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 5.07  loss: 5.07  time: 0.3543  data_time: 0.0045  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:21] cvalgorithms INFO:  eta: 19:36:19  iter: 35  total_loss: 8.058  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 4.029  loss: 4.029  time: 0.3546  data_time: 0.0045  lr: 0.001  max_mem: 3221M
[07/05 15:56:22] cvalgorithms INFO:  eta: 19:36:31  iter: 37  total_loss: 5.769  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.885  loss: 2.885  time: 0.3547  data_time: 0.0045  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:22] cvalgorithms INFO:  eta: 19:37:14  iter: 39  total_loss: 4.631  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.316  loss: 2.316  time: 0.3550  data_time: 0.0045  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:23] cvalgorithms INFO:  eta: 19:37:19  iter: 41  total_loss: 4.116  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 2.058  loss: 2.058  time: 0.3550  data_time: 0.0044  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:24] cvalgorithms INFO:  eta: 19:38:20  iter: 43  total_loss: 3.716  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.858  loss: 1.858  time: 0.3550  data_time: 0.0044  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:24] cvalgorithms INFO:  eta: 19:39:04  iter: 45  total_loss: 3.487  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.744  loss: 1.744  time: 0.3551  data_time: 0.0044  lr: 0.001  max_mem: 3221M
[07/05 15:56:25] cvalgorithms INFO:  eta: 19:39:58  iter: 47  total_loss: 3.171  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.586  loss: 1.586  time: 0.3552  data_time: 0.0044  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:26] cvalgorithms INFO:  eta: 19:40:49  iter: 49  total_loss: 3.171  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.586  loss: 1.586  time: 0.3553  data_time: 0.0044  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:27] cvalgorithms INFO:  eta: 19:41:39  iter: 51  total_loss: 3.171  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.586  loss: 1.586  time: 0.3554  data_time: 0.0044  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:27] cvalgorithms INFO:  eta: 19:42:34  iter: 53  total_loss: 3.038  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.519  loss: 1.519  time: 0.3555  data_time: 0.0044  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:28] cvalgorithms INFO:  eta: 19:43:04  iter: 55  total_loss: 2.708  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.354  loss: 1.354  time: 0.3555  data_time: 0.0045  lr: 0.001  max_mem: 3221M
[07/05 15:56:29] cvalgorithms INFO:  eta: 19:44:02  iter: 57  total_loss: 1.608  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8042  loss: 0.8042  time: 0.3557  data_time: 0.0045  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:30] cvalgorithms INFO:  eta: 19:44:58  iter: 59  total_loss: 1.608  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8042  loss: 0.8042  time: 0.3557  data_time: 0.0045  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:30] cvalgorithms INFO:  eta: 19:45:15  iter: 61  total_loss: 2.883  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.442  loss: 1.442  time: 0.3559  data_time: 0.0046  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:31] cvalgorithms INFO:  eta: 19:45:57  iter: 63  total_loss: 2.483  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.242  loss: 1.242  time: 0.3559  data_time: 0.0046  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:32] cvalgorithms INFO:  eta: 19:46:37  iter: 65  total_loss: 1.894  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9472  loss: 0.9472  time: 0.3561  data_time: 0.0046  lr: 0.001  max_mem: 3221M
[07/05 15:56:32] cvalgorithms INFO:  eta: 19:47:10  iter: 67  total_loss: 2.847  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.423  loss: 1.423  time: 0.3562  data_time: 0.0046  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:33] cvalgorithms INFO:  eta: 19:47:40  iter: 69  total_loss: 2.847  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.423  loss: 1.423  time: 0.3572  data_time: 0.0046  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:34] cvalgorithms INFO:  eta: 19:47:55  iter: 71  total_loss: 2.847  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.423  loss: 1.423  time: 0.3574  data_time: 0.0047  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:35] cvalgorithms INFO:  eta: 19:48:16  iter: 73  total_loss: 2.589  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.295  loss: 1.295  time: 0.3575  data_time: 0.0046  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:35] cvalgorithms INFO:  eta: 19:48:31  iter: 75  total_loss: 2.306  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.153  loss: 1.153  time: 0.3576  data_time: 0.0046  lr: 0.001  max_mem: 3221M
[07/05 15:56:36] cvalgorithms INFO:  eta: 19:48:41  iter: 77  total_loss: 2.589  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.295  loss: 1.295  time: 0.3577  data_time: 0.0045  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:37] cvalgorithms INFO:  eta: 19:49:08  iter: 79  total_loss: 2.306  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.153  loss: 1.153  time: 0.3582  data_time: 0.0045  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:38] cvalgorithms INFO:  eta: 19:49:52  iter: 81  total_loss: 2.306  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.153  loss: 1.153  time: 0.3586  data_time: 0.0045  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:38] cvalgorithms INFO:  eta: 19:50:34  iter: 83  total_loss: 2.122  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.061  loss: 1.061  time: 0.3590  data_time: 0.0045  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:39] cvalgorithms INFO:  eta: 19:50:57  iter: 85  total_loss: 2.122  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 1.061  loss: 1.061  time: 0.3596  data_time: 0.0046  lr: 0.001  max_mem: 3221M
[07/05 15:56:40] cvalgorithms INFO:  eta: 19:51:04  iter: 87  total_loss: 1.793  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8967  loss: 0.8967  time: 0.3601  data_time: 0.0047  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:41] cvalgorithms INFO:  eta: 19:51:39  iter: 89  total_loss: 1.156  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5781  loss: 0.5781  time: 0.3606  data_time: 0.0047  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:41] cvalgorithms INFO:  eta: 19:52:08  iter: 91  total_loss: 1.156  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.5781  loss: 0.5781  time: 0.3611  data_time: 0.0047  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:42] cvalgorithms INFO:  eta: 19:52:33  iter: 93  total_loss: 1.483  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7414  loss: 0.7414  time: 0.3614  data_time: 0.0048  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:43] cvalgorithms INFO:  eta: 19:53:03  iter: 95  total_loss: 1.741  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8703  loss: 0.8703  time: 0.3622  data_time: 0.0048  lr: 0.001  max_mem: 3221M
[07/05 15:56:44] cvalgorithms INFO:  eta: 19:53:20  iter: 97  total_loss: 1.799  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.8993  loss: 0.8993  time: 0.3626  data_time: 0.0048  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:45] cvalgorithms INFO:  eta: 19:53:32  iter: 99  total_loss: 1.782  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.891  loss: 0.891  time: 0.3628  data_time: 0.0048  lr: 9.5492e-05  max_mem: 3221M
[07/05 15:56:45] cvalgorithms INFO:  eta: 19:53:40  iter: 101  total_loss: 1.469  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.7343  loss: 0.7343  time: 0.3631  data_time: 0.0048  lr: 0.00090451  max_mem: 3221M
[07/05 15:56:46] cvalgorithms INFO:  eta: 19:54:05  iter: 103  total_loss: 1.84  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9199  loss: 0.9199  time: 0.3635  data_time: 0.0049  lr: 0.00034549  max_mem: 3221M
[07/05 15:56:47] cvalgorithms INFO:  eta: 19:54:25  iter: 105  total_loss: 1.853  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9265  loss: 0.9265  time: 0.3638  data_time: 0.0047  lr: 0.001  max_mem: 3221M
[07/05 15:56:48] cvalgorithms INFO:  eta: 19:54:54  iter: 107  total_loss: 1.941  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9704  loss: 0.9704  time: 0.3642  data_time: 0.0048  lr: 0.00065451  max_mem: 3221M
[07/05 15:56:48] cvalgorithms INFO:  eta: 19:55:44  iter: 109  total_loss: 1.941  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 0.9704  loss: 0.9704  time: 0.3646  data_time: 0.0047  lr: 9.5492e-05  max_mem: 3221M
[07/05 16:11:10] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 16:11:10] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 16:13:12] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 16:13:12] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 16:14:43] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 16:14:43] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 16:16:10] cvalgorithms INFO: SiameseEncoderDecoder(
  (backbone): ConvNeXt(
    (downsample_layers): ModuleList(
      (0): Sequential(
        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
        (1): LayerNorm()
      )
      (1): Sequential(
        (0): LayerNorm()
        (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
      )
      (2): Sequential(
        (0): LayerNorm()
        (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
      )
      (3): Sequential(
        (0): LayerNorm()
        (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=384, out_features=96, bias=True)
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=768, out_features=192, bias=True)
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (3): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (4): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (5): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (6): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (7): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
        (8): Block(
          (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (1): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
        (2): Block(
          (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
          (norm): LayerNorm()
          (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU()
          (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  )
  (decode_head): UPerHead(
    (loss): CrossEntropyLoss()
    (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
    (dropout): Dropout2d(p=0.1, inplace=False)
    (psp_modules): PPM(
      (ppm_blocks): ModuleList(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (2): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (3): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    (bottleneck): ConvModule(
      (conv): Conv2d(1024, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
      (1): ConvModule(
        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
    (fpn_bottleneck): ConvModule(
      (conv): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activate): ReLU(inplace=True)
    )
  )
  (auxiliary_head): ModuleList(
    (0): FCNHead(
      (loss): CrossEntropyLoss()
      (conv_seg): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (convs): Sequential(
        (0): ConvModule(
          (conv): Conv2d(768, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
      (conv_cat): ConvModule(
        (conv): Conv2d(832, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activate): ReLU(inplace=True)
      )
    )
  )
  (constant_loss): BatchContrastiveLoss()
  (sig): Sigmoid()
  (sft): Softmax(dim=1)
  (siamese_layer): ModuleList(
    (0): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))
    )
    (1): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))
    )
    (2): PixelSub(
      (conv_modules): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): BasicConv2d(
          (conv): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (final_conv): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[07/05 16:16:10] cvalgorithms INFO: pretrained checkpoint is loaded.
[07/05 16:17:21] cvalgorithms INFO: Starting training from iteration 0
[07/05 16:17:24] cvalgorithms ERROR: Exception during training:
Traceback (most recent call last):
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 124, in train
    self.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\tools\runner.py", line 148, in after_step
    h.after_step()
  File "C:\Users\user1\PycharmProjects\cvalgorithms\trainer\hooks\hooks.py", line 114, in after_step
    next_epoch = self.trainer.epoch + 1
AttributeError: 'TrainerContainer' object has no attribute 'epoch'
[07/05 16:17:24] cvalgorithms INFO:  iter: 0  total_loss: 139.5  decode.loss_seg: 0  aux_0.loss: 0  cnt.cnt_loss: 69.76  loss: 69.76  data_time: 0.0119  lr: 0.001  max_mem: 3221M
